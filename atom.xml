<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jackeyzhe&#39;s Blog</title>
  
  <subtitle>靠脸吃饭</subtitle>
  <link href="https://jackeyzhe.github.io/atom.xml" rel="self"/>
  
  <link href="https://jackeyzhe.github.io/"/>
  <updated>2025-12-23T13:04:01.933Z</updated>
  <id>https://jackeyzhe.github.io/</id>
  
  <author>
    <name>Jackey Wang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Flink源码阅读：窗口</title>
    <link href="https://jackeyzhe.github.io/2025/12/22/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E7%AA%97%E5%8F%A3/"/>
    <id>https://jackeyzhe.github.io/2025/12/22/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E7%AA%97%E5%8F%A3/</id>
    <published>2025-12-22T02:49:15.000Z</published>
    <updated>2025-12-23T13:04:01.933Z</updated>
    
    <content type="html"><![CDATA[<p>前文我们梳理了 Watermark 相关的源码，Watermark 的作用就是用来触发窗口，本文我们就一起看一下窗口相关的源码。<span id="more"></span></p><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>在<a href="https://jackeyzhe.github.io/2025/07/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%AA%97%E5%8F%A3/">Flink学习笔记：窗口</a>一文中，我们介绍了窗口的分类以及基本的用法。按照处理数据流的类型划分，Flink 可以分为 Keyed Window 和 Non-Keyed Window，它们的用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">       .keyBy(...)               &lt;-  仅 keyed 窗口需要</span><br><span class="line">       .window(...)              &lt;-  必填项：<span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  可选项：<span class="string">&quot;trigger&quot;</span> (省略则使用默认 trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  可选项：<span class="string">&quot;evictor&quot;</span> (省略则不使用 evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  可选项：<span class="string">&quot;lateness&quot;</span> (省略则为 <span class="number">0</span>)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  可选项：<span class="string">&quot;output tag&quot;</span> (省略则不对迟到数据使用 side output)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  必填项：<span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  可选项：<span class="string">&quot;output tag&quot;</span></span><br><span class="line"></span><br><span class="line">stream</span><br><span class="line">       .windowAll(...)           &lt;-  必填项：<span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  可选项：<span class="string">&quot;trigger&quot;</span> (<span class="keyword">else</span> <span class="keyword">default</span> trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  可选项：<span class="string">&quot;evictor&quot;</span> (<span class="keyword">else</span> no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  可选项：<span class="string">&quot;lateness&quot;</span> (<span class="keyword">else</span> zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  可选项：<span class="string">&quot;output tag&quot;</span> (<span class="keyword">else</span> no side output <span class="keyword">for</span> late data)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  必填项：<span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  可选项：<span class="string">&quot;output tag&quot;</span></span><br></pre></td></tr></table></figure><p>下面我们根据用法，分别来看两种窗口的源码。</p><h3 id="Keyed-Window"><a href="#Keyed-Window" class="headerlink" title="Keyed Window"></a>Keyed Window</h3><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766394316/Blog/flink/16/KeyedWindow.png" alt="KeyedWindow"></p><h4 id="WindowAssigner"><a href="#WindowAssigner" class="headerlink" title="WindowAssigner"></a>WindowAssigner</h4><p>在示例代码中，数据流类型流转过程如图。我们聚焦于 WindowedStream，它是在调用 <code>KeyedStream.window</code> 方法之后生成的。window 方法需要传入一个 WindowAssigner，用来确定一条消息属于哪几个窗口，各个类型的窗口都有不同的实现。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766472754/Blog/flink/16/windowAssigner.png" alt="windowAssigner"></p><p>我们以 TumblingEventTimeWindows 为例，看一下它具体的分配逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> Collection&lt;TimeWindow&gt; <span class="title function_">assignWindows</span><span class="params">(</span></span><br><span class="line"><span class="params">        Object element, <span class="type">long</span> timestamp, WindowAssignerContext context)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (timestamp &gt; Long.MIN_VALUE) &#123;</span><br><span class="line">        <span class="keyword">if</span> (staggerOffset == <span class="literal">null</span>) &#123;</span><br><span class="line">            staggerOffset =</span><br><span class="line">                    windowStagger.getStaggerOffset(context.getCurrentProcessingTime(), size);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Long.MIN_VALUE is currently assigned when no timestamp is present</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span></span><br><span class="line">                TimeWindow.getWindowStartWithOffset(</span><br><span class="line">                        timestamp, (globalOffset + staggerOffset) % size, size);</span><br><span class="line">        <span class="keyword">return</span> Collections.singletonList(<span class="keyword">new</span> <span class="title class_">TimeWindow</span>(start, start + size));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(</span><br><span class="line">                <span class="string">&quot;Record has Long.MIN_VALUE timestamp (= no timestamp marker). &quot;</span></span><br><span class="line">                        + <span class="string">&quot;Did you forget to call &#x27;DataStream.assignTimestampsAndWatermarks(...)&#x27;?&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里就是根据消息的 timestamp 来确定窗口的开始和结束时间，然后返回消息所属的窗口。这里还有个 windowStagger 变量，它是窗口触发是否错峰的配置，如果你的任务有成千上万个子任务，同时触发窗口计算带来的瞬时流量可能会对服务器本身和下游造成稳定性的影响，这时就可以通过修改 WindowStagger 配置将流量打散。</p><p>将我们自己定义好的 WindowAssigner 传入 window 方法后，会创建一个 WindowOperatorBuilder，它负责创建一个 WindowOperator 对象，WindowOperator 来执行窗口具体的计算逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="title function_">WindowedStream</span><span class="params">(KeyedStream&lt;T, K&gt; input, WindowAssigner&lt;? <span class="built_in">super</span> T, W&gt; windowAssigner)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.input = input;</span><br><span class="line">    <span class="built_in">this</span>.isEnableAsyncState = input.isEnableAsyncState();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.builder =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WindowOperatorBuilder</span>&lt;&gt;(</span><br><span class="line">                    windowAssigner,</span><br><span class="line">                    windowAssigner.getDefaultTrigger(),</span><br><span class="line">                    input.getExecutionConfig(),</span><br><span class="line">                    input.getType(),</span><br><span class="line">                    input.getKeySelector(),</span><br><span class="line">                    input.getKeyType());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Trigger"><a href="#Trigger" class="headerlink" title="Trigger"></a>Trigger</h4><p>有了 WindowOperatorBuilder 之后，我们可以对它进行一些设置，如 trigger、evictor 等，trigger 中提供了一些回调函数，这些回调函数的返回结果 TriggerResult 决定了是否触发窗口计算。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">Trigger</span>&lt;T, W <span class="keyword">extends</span> <span class="title class_">Window</span>&gt; <span class="keyword">implements</span> <span class="title class_">Serializable</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> -<span class="number">4104633972991191369L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title function_">onElement</span><span class="params">(T element, <span class="type">long</span> timestamp, W window, TriggerContext ctx)</span></span><br><span class="line">            <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title function_">onProcessingTime</span><span class="params">(<span class="type">long</span> time, W window, TriggerContext ctx)</span></span><br><span class="line">            <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> TriggerResult <span class="title function_">onEventTime</span><span class="params">(<span class="type">long</span> time, W window, TriggerContext ctx)</span></span><br><span class="line">            <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">canMerge</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMerge</span><span class="params">(W window, OnMergeContext ctx)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UnsupportedOperationException</span>(<span class="string">&quot;This trigger does not support merging.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">(W window, TriggerContext ctx)</span> <span class="keyword">throws</span> Exception;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>回调函数有三个，分别是 onElement、onProcessingTime、onEventTime，onElement 是在处理每条消息的时候触发，onProcessingTime 和 onEventTime 都是与定时器配合触发，上一篇文章我们提到过，在处理 Watermark 的时候会注册定时器，触发时就会回调这两个方法。</p><p>此外，Trigger 类中还有三个方法，我们简单介绍一下。canMerge 是用来判断窗口是否可以被合并，onMerge 则是在合并窗口时的回调方法。clear 方法用于清除窗口的状态数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">TriggerResult</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** No action is taken on the window. */</span></span><br><span class="line">    CONTINUE(<span class="literal">false</span>, <span class="literal">false</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** &#123;<span class="doctag">@code</span> FIRE_AND_PURGE&#125; evaluates the window function and emits the window result. */</span></span><br><span class="line">    FIRE_AND_PURGE(<span class="literal">true</span>, <span class="literal">true</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * On &#123;<span class="doctag">@code</span> FIRE&#125;, the window is evaluated and results are emitted. The window is not purged,</span></span><br><span class="line"><span class="comment">     * though, all elements are retained.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    FIRE(<span class="literal">true</span>, <span class="literal">false</span>),</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * All elements in the window are cleared and the window is discarded, without evaluating the</span></span><br><span class="line"><span class="comment">     * window function or emitting any elements.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    PURGE(<span class="literal">false</span>, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>说回 TriggerResult，它有四种枚举：</p><ul><li><p>CONTINUE：什么也不做</p></li><li><p>FIRE_AND_PURGE：触发窗口计算并清除窗口中的元素</p></li><li><p>FIRE：只触发窗口计算</p></li><li><p>PURGE：清除窗口中的元素，不触发计算</p></li></ul><h4 id="Evictor"><a href="#Evictor" class="headerlink" title="Evictor"></a>Evictor</h4><p>Evictor 是用来自定义删除窗口中元素的的接口，如果设置了 evictor，WindowOperatorBuilder 就会创建 EvictingWindowOperator。在执行窗口计算逻辑前后，都会调用 evictBefore 和 evictAfter。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">emitWindowContents</span><span class="params">(</span></span><br><span class="line"><span class="params">        W window, Iterable&lt;StreamRecord&lt;IN&gt;&gt; contents, ListState&lt;StreamRecord&lt;IN&gt;&gt; windowState)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    ...</span><br><span class="line">    evictorContext.evictBefore(recordsWithTimestamp, Iterables.size(recordsWithTimestamp));</span><br><span class="line"></span><br><span class="line">    FluentIterable&lt;IN&gt; projectedContents =</span><br><span class="line">            recordsWithTimestamp.transform(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">Function</span>&lt;TimestampedValue&lt;IN&gt;, IN&gt;() &#123;</span><br><span class="line">                        <span class="meta">@Override</span></span><br><span class="line">                        <span class="keyword">public</span> IN <span class="title function_">apply</span><span class="params">(TimestampedValue&lt;IN&gt; input)</span> &#123;</span><br><span class="line">                            <span class="keyword">return</span> input.getValue();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line"></span><br><span class="line">    processContext.window = triggerContext.window;</span><br><span class="line">    userFunction.process(</span><br><span class="line">            triggerContext.key,</span><br><span class="line">            triggerContext.window,</span><br><span class="line">            processContext,</span><br><span class="line">            projectedContents,</span><br><span class="line">            timestampedCollector);</span><br><span class="line">    evictorContext.evictAfter(recordsWithTimestamp, Iterables.size(recordsWithTimestamp));</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="allowedLateness-amp-sideOutputLateData"><a href="#allowedLateness-amp-sideOutputLateData" class="headerlink" title="allowedLateness &amp; sideOutputLateData"></a>allowedLateness &amp; sideOutputLateData</h4><p>allowedLateness 和 sideOutputLateData 都是针对迟到数据的，allowedLateness 是用来指定允许的最大迟到时长，sideOutputLateData 则是将迟到数据输出到指定 outputTag。</p><p>判断是否迟到的方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="type">boolean</span> <span class="title function_">isElementLate</span><span class="params">(StreamRecord&lt;IN&gt; element)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (windowAssigner.isEventTime())</span><br><span class="line">            &amp;&amp; (element.getTimestamp() + allowedLateness</span><br><span class="line">                    &lt;= internalTimerService.currentWatermark());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是迟到数据，则进行如下处理：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (isSkippedElement &amp;&amp; isElementLate(element)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (lateDataOutputTag != <span class="literal">null</span>) &#123;</span><br><span class="line">        sideOutput(element);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.numLateRecordsDropped.inc();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="WindowOperator"><a href="#WindowOperator" class="headerlink" title="WindowOperator"></a>WindowOperator</h4><p>设置好 WindowOperatorBuilder 之后，接着就可以调用 process/aggregate/reduce 等方法进行数据计算。</p><p>我们以 process 方法为例，来看下具体的处理逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; <span class="title function_">process</span><span class="params">(</span></span><br><span class="line"><span class="params">        ProcessWindowFunction&lt;T, R, K, W&gt; function, TypeInformation&lt;R&gt; resultType)</span> &#123;</span><br><span class="line">    function = input.getExecutionEnvironment().clean(function);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">opName</span> <span class="operator">=</span> builder.generateOperatorName();</span><br><span class="line">    <span class="keyword">final</span> <span class="type">String</span> <span class="variable">opDesc</span> <span class="operator">=</span> builder.generateOperatorDescription(function, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">    OneInputStreamOperator&lt;T, R&gt; operator =</span><br><span class="line">            isEnableAsyncState ? builder.asyncProcess(function) : builder.process(function);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> input.transform(opName, resultType, operator).setDescription(opDesc);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 <code>WindowedStream.process</code> 方法中，就是调用 WindowOperatorBuilder 的 process 方法（如果是异步则调用异步方法）生成 WindowOperator，再将 WindowOperator 加入到执行图中。</p><p>下面我们来看 WindowOperator 中几个重要的方法。</p><h5 id="open"><a href="#open" class="headerlink" title="open"></a>open</h5><p>首先是 open 方法，它主要负责进行初始化，包括创建 timerService，创建 windowState 等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="built_in">super</span>.open();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.numLateRecordsDropped = metrics.counter(LATE_ELEMENTS_DROPPED_METRIC_NAME);</span><br><span class="line">    timestampedCollector = <span class="keyword">new</span> <span class="title class_">TimestampedCollector</span>&lt;&gt;(output);</span><br><span class="line"></span><br><span class="line">    internalTimerService = getInternalTimerService(<span class="string">&quot;window-timers&quot;</span>, windowSerializer, <span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">    triggerContext = <span class="keyword">new</span> <span class="title class_">Context</span>(<span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line">    processContext = <span class="keyword">new</span> <span class="title class_">WindowContext</span>(<span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">    windowAssignerContext =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">WindowAssigner</span>.WindowAssignerContext() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getCurrentProcessingTime</span><span class="params">()</span> &#123;</span><br><span class="line">                    <span class="keyword">return</span> internalTimerService.currentProcessingTime();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create (or restore) the state that hold the actual window contents</span></span><br><span class="line">    <span class="comment">// NOTE - the state may be null in the case of the overriding evicting window operator</span></span><br><span class="line">    <span class="keyword">if</span> (windowStateDescriptor != <span class="literal">null</span>) &#123;</span><br><span class="line">        windowState =</span><br><span class="line">                (InternalAppendingState&lt;K, W, IN, ACC, ACC&gt;)</span><br><span class="line">                        getOrCreateKeyedState(windowSerializer, windowStateDescriptor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create the typed and helper states for merging windows</span></span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> MergingWindowAssigner) &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="processElement"><a href="#processElement" class="headerlink" title="processElement"></a>processElement</h5><p>processElement 是负责处理进入窗口的数据，这里首先调用 <code>WindowAssigner.assignWindows</code> 方法确认元素属于哪些窗口。然后遍历窗口进行处理，包括向 windowState 中添加元素，调用 trigger 的 onElement 方法获取 TriggerResult。如果触发了窗口计算，调用 emitWindowContents 执行计算逻辑。最后是处理迟到数据，我们前面提到过。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(StreamRecord&lt;IN&gt; element)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="keyword">final</span> Collection&lt;W&gt; elementWindows =</span><br><span class="line">            windowAssigner.assignWindows(</span><br><span class="line">                    element.getValue(), element.getTimestamp(), windowAssignerContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if element is handled by none of assigned elementWindows</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">isSkippedElement</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">K</span> <span class="variable">key</span> <span class="operator">=</span> <span class="built_in">this</span>.&lt;K&gt;getKeyedStateBackend().getCurrentKey();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> MergingWindowAssigner) &#123;</span><br><span class="line">        ...</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (W window : elementWindows) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// drop if the window is already late</span></span><br><span class="line">            <span class="keyword">if</span> (isWindowLate(window)) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            isSkippedElement = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">            windowState.setCurrentNamespace(window);</span><br><span class="line">            windowState.add(element.getValue());</span><br><span class="line"></span><br><span class="line">            triggerContext.key = key;</span><br><span class="line">            triggerContext.window = window;</span><br><span class="line"></span><br><span class="line">            <span class="type">TriggerResult</span> <span class="variable">triggerResult</span> <span class="operator">=</span> triggerContext.onElement(element);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (triggerResult.isFire()) &#123;</span><br><span class="line">                <span class="type">ACC</span> <span class="variable">contents</span> <span class="operator">=</span> windowState.get();</span><br><span class="line">                <span class="keyword">if</span> (contents != <span class="literal">null</span>) &#123;</span><br><span class="line">                    emitWindowContents(window, contents);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (triggerResult.isPurge()) &#123;</span><br><span class="line">                windowState.clear();</span><br><span class="line">            &#125;</span><br><span class="line">            registerCleanupTimer(window);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// side output input event if</span></span><br><span class="line">    <span class="comment">// element not handled by any window</span></span><br><span class="line">    <span class="comment">// late arriving tag has been set</span></span><br><span class="line">    <span class="comment">// windowAssigner is event time and current timestamp + allowed lateness no less than</span></span><br><span class="line">    <span class="comment">// element timestamp</span></span><br><span class="line">    <span class="keyword">if</span> (isSkippedElement &amp;&amp; isElementLate(element)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (lateDataOutputTag != <span class="literal">null</span>) &#123;</span><br><span class="line">            sideOutput(element);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">this</span>.numLateRecordsDropped.inc();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="onEventTime"><a href="#onEventTime" class="headerlink" title="onEventTime"></a>onEventTime</h5><p>onEventTime 方法是 eventTime 触发窗口计算时调用的。主要逻辑就是获取 TriggerResult，然后触发计算逻辑，以及对 windowState 的处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEventTime</span><span class="params">(InternalTimer&lt;K, W&gt; timer)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    triggerContext.key = timer.getKey();</span><br><span class="line">    triggerContext.window = timer.getNamespace();</span><br><span class="line"></span><br><span class="line">    MergingWindowSet&lt;W&gt; mergingWindows;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (windowAssigner <span class="keyword">instanceof</span> MergingWindowAssigner) &#123;</span><br><span class="line">        mergingWindows = getMergingWindowSet();</span><br><span class="line">        <span class="type">W</span> <span class="variable">stateWindow</span> <span class="operator">=</span> mergingWindows.getStateWindow(triggerContext.window);</span><br><span class="line">        <span class="keyword">if</span> (stateWindow == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// Timer firing for non-existent window, this can only happen if a</span></span><br><span class="line">            <span class="comment">// trigger did not clean up timers. We have already cleared the merging</span></span><br><span class="line">            <span class="comment">// window and therefore the Trigger state, however, so nothing to do.</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            windowState.setCurrentNamespace(stateWindow);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        windowState.setCurrentNamespace(triggerContext.window);</span><br><span class="line">        mergingWindows = <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">TriggerResult</span> <span class="variable">triggerResult</span> <span class="operator">=</span> triggerContext.onEventTime(timer.getTimestamp());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (triggerResult.isFire()) &#123;</span><br><span class="line">        <span class="type">ACC</span> <span class="variable">contents</span> <span class="operator">=</span> windowState.get();</span><br><span class="line">        <span class="keyword">if</span> (contents != <span class="literal">null</span>) &#123;</span><br><span class="line">            emitWindowContents(triggerContext.window, contents);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (triggerResult.isPurge()) &#123;</span><br><span class="line">        windowState.clear();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (windowAssigner.isEventTime()</span><br><span class="line">            &amp;&amp; isCleanupTime(triggerContext.window, timer.getTimestamp())) &#123;</span><br><span class="line">        clearAllState(triggerContext.window, windowState, mergingWindows);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mergingWindows != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">// need to make sure to update the merging state in state</span></span><br><span class="line">        mergingWindows.persist();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="onProcessingTime"><a href="#onProcessingTime" class="headerlink" title="onProcessingTime"></a>onProcessingTime</h5><p>onProcessingTime 和 onEventTime 逻辑基本一致，只是触发条件不同，这里就不再赘述了。</p><p>至此，Keyed Window 从设置到使用的源码我们就梳理完成了，下面再来看另外一种窗口 Non-Keyed Window。</p><h3 id="Non-Keyed-Window"><a href="#Non-Keyed-Window" class="headerlink" title="Non-Keyed Window"></a>Non-Keyed Window</h3><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766484574/Blog/flink/16/Non-KeyedWindow.png" alt="AllWindow"></p><p>我们调用 windowAll 得到 AllWindowedStream，在构造函数中，会给对 input 调用 keyBy 方法，传入 NullByteKeySelector， NullByteKeySelector 对每个 key 都返回0，因此所有的 key 都会被分配到同一个节点。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">NullByteKeySelector</span>&lt;T&gt; <span class="keyword">implements</span> <span class="title class_">KeySelector</span>&lt;T, Byte&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">614256539098549020L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Byte <span class="title function_">getKey</span><span class="params">(T value)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Non-Keyed Window 后续的逻辑都和 Keyed Window 比较类似。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们梳理了窗口相关的源码，几个重点概念包括 WindowAssginer、WindowOperator、Trigger、Evictor。其中 WindowAssigner 是用来确定一条消息属于哪些窗口，WindowOperator 则是窗口计算逻辑的具体执行层。Trigger 和 Evictor 分别用于触发窗口和清理窗口中数据。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前文我们梳理了 Watermark 相关的源码，Watermark 的作用就是用来触发窗口，本文我们就一起看一下窗口相关的源码。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：Watermark机制</title>
    <link href="https://jackeyzhe.github.io/2025/12/17/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9AWatermark%E6%9C%BA%E5%88%B6/"/>
    <id>https://jackeyzhe.github.io/2025/12/17/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9AWatermark%E6%9C%BA%E5%88%B6/</id>
    <published>2025-12-17T07:15:22.000Z</published>
    <updated>2025-12-20T13:52:07.904Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们已经梳理了 Flink 状态和 Checkpoint 相关的源码。从本文开始，我们再来关注另外几个核心概念，即时间、Watermark 和窗口。<span id="more"></span></p><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>在 Flink 中 Watermark 是用来解决数据乱序问题的，它也是窗口关闭的触发条件。对于 Watermark 的概念和用法还不熟悉的同学可以先阅读<a href="https://jackeyzhe.github.io/2025/06/30/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E4%B8%8EWatermark/">Flink学习笔记：时间与Watermark</a>一文。下面我们进入正题，开始梳理 Watermark 相关的源码。</p><h3 id="Watermark-定义"><a href="#Watermark-定义" class="headerlink" title="Watermark 定义"></a>Watermark 定义</h3><p>Watermark 的定义非常简单，它继承了 <code>StreamElement</code> 类，内部只有一个 timestamp 变量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PublicEvolving</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Watermark</span> <span class="keyword">extends</span> <span class="title class_">StreamElement</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** The watermark that signifies end-of-event-time. */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Watermark</span> <span class="variable">MAX_WATERMARK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Watermark</span>(Long.MAX_VALUE);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** The watermark that signifies is used before any actual watermark has been generated. */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Watermark</span> <span class="variable">UNINITIALIZED</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Watermark</span>(Long.MIN_VALUE);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/** The timestamp of the watermark in milliseconds. */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Creates a new watermark with the given timestamp in milliseconds. */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">Watermark</span><span class="params">(<span class="type">long</span> timestamp)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.timestamp = timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Returns the timestamp associated with this &#123;<span class="doctag">@link</span> Watermark&#125; in milliseconds. */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getTimestamp</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object o)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">this</span> == o</span><br><span class="line">                || o != <span class="literal">null</span></span><br><span class="line">                        &amp;&amp; o.getClass() == <span class="built_in">this</span>.getClass()</span><br><span class="line">                        &amp;&amp; ((Watermark) o).timestamp == timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hashCode</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> (<span class="type">int</span>) (timestamp ^ (timestamp &gt;&gt;&gt; <span class="number">32</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Watermark @ &quot;</span> + timestamp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Watermark-处理过程"><a href="#Watermark-处理过程" class="headerlink" title="Watermark 处理过程"></a>Watermark 处理过程</h3><p>我们先来回顾一下 Watermark 的生成方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Event&gt; withTimestampsAndWatermarks = source</span><br><span class="line">        .assignTimestampsAndWatermarks(</span><br><span class="line">                WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(<span class="number">20</span>))</span><br><span class="line">        );</span><br></pre></td></tr></table></figure><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>在定义 Watermark 的时候，我们调用 assignTimestampsAndWatermarks 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> SingleOutputStreamOperator&lt;T&gt; <span class="title function_">assignTimestampsAndWatermarks</span><span class="params">(</span></span><br><span class="line"><span class="params">        WatermarkStrategy&lt;T&gt; watermarkStrategy)</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> WatermarkStrategy&lt;T&gt; cleanedStrategy = clean(watermarkStrategy);</span><br><span class="line">    <span class="comment">// match parallelism to input, to have a 1:1 source -&gt; timestamps/watermarks relationship</span></span><br><span class="line">    <span class="comment">// and chain</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">inputParallelism</span> <span class="operator">=</span> getTransformation().getParallelism();</span><br><span class="line">    <span class="keyword">final</span> TimestampsAndWatermarksTransformation&lt;T&gt; transformation =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">TimestampsAndWatermarksTransformation</span>&lt;&gt;(</span><br><span class="line">                    <span class="string">&quot;Timestamps/Watermarks&quot;</span>,</span><br><span class="line">                    inputParallelism,</span><br><span class="line">                    getTransformation(),</span><br><span class="line">                    cleanedStrategy,</span><br><span class="line">                    <span class="literal">false</span>);</span><br><span class="line">    getExecutionEnvironment().addOperator(transformation);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">SingleOutputStreamOperator</span>&lt;&gt;(getExecutionEnvironment(), transformation);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法接收了一个 WatermarkStrategy 参数，把它封装到 TimestampsAndWatermarksTransformation 中之后，就添加到 transformations 列表中了。在生成 StreamGraph 的过程中，会调用每个 transformation 的 transform 方法。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766047572/Blog/flink/15/watermarkTranslate.png" alt="transform"></p><p>通过这个调用链路，创建出了 TimestampsAndWatermarksOperatorFactory，在初始化 StreamTask 时，会调用 <code>TimestampsAndWatermarksOperatorFactory.createStreamOperator</code> 方法来创建 TimestampsAndWatermarksOperator，并调用它的 open 方法。</p><p>在这个 open 方法中，主要是生成 timestampAssigner 和 watermarkGenerator。timestampAssigner 是用于提取时间戳，watermarkGenerator 是用于生成 Watermark。</p><p>生成完成之后注册了一个定时器，到指定时间后会调用 onProcessingTime 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onProcessingTime</span><span class="params">(<span class="type">long</span> timestamp)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    watermarkGenerator.onPeriodicEmit(wmOutput);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> getProcessingTimeService().getCurrentProcessingTime();</span><br><span class="line">    getProcessingTimeService().registerTimer(now + watermarkInterval, <span class="built_in">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法的逻辑也很简单，先发送创建并发送 Watermark，然后再注册一个定时器。</p><h4 id="发送-Watermark"><a href="#发送-Watermark" class="headerlink" title="发送 Watermark"></a>发送 Watermark</h4><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766112568/Blog/flink/15/emitWatermark.png" alt="emitWatermark"></p><p>我们以 BoundedOutOfOrdernessWatermarks 为例，它向下游发送了一个 Watermark，时间戳为 maxTimestamp - outOfOrdernessMillis - 1（maxTimestamp 是当前最大的事件时间戳，outOfOrdernessMillis 是我们定义的周期时间毫秒值）。随后在 WatermarkEmitter.emitWatermark 方法中，更新了当前 Watermark 的值。最后 RecordWriterOutput.emitWatermark 则是向下游广播当前的 Watermark。</p><h4 id="下游处理"><a href="#下游处理" class="headerlink" title="下游处理"></a>下游处理</h4><p>下游处理方法我们从 <code>StreamOneInputProcessor.processInput</code> 入手，先来看具体的调用链路。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766133213/Blog/flink/15/processWatermark.png" alt="processWatermark"></p><p>在 inputWatermark 方法中，先是对 alignedSubpartitionStatuses 进行调整，alignedSubpartitionStatuses 这个变量主要是用来获取最小的 Watermark。最后调用了 <code>findAndOutputNewMinWatermarkAcrossAlignedSubpartitions</code> 方法。这个方法中，会获取到所有上游最小的 Watermark，如果它大于最近发送的一个 Watermark，就会向下游发送。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">emitWatermark</span><span class="params">(Watermark watermark)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    watermarkGauge.setCurrentWatermark(watermark.getTimestamp());</span><br><span class="line">    operator.processWatermark(watermark);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个发送方法中，调用了 <code>operator.processWatermark</code>，我们接着看这个处理方法。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1766136153/Blog/flink/15/advanceWatermark.png" alt="advanceWatermark"></p><p>在 tryAdvanceWatermark 方法中如果 Watermark 的时间大于 eventTimeTimersQueue 队列中头节点的时间，那么对 eventTimeTimersQueue 这个队列进行出队操作，这个操作意味着触发了窗口计算。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">tryAdvanceWatermark</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">long</span> time, InternalTimeServiceManager.ShouldStopAdvancingFn shouldStopAdvancingFn)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    currentWatermark = time;</span><br><span class="line">    InternalTimer&lt;K, N&gt; timer;</span><br><span class="line">    <span class="type">boolean</span> <span class="variable">interrupted</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">while</span> ((timer = eventTimeTimersQueue.peek()) != <span class="literal">null</span></span><br><span class="line">            &amp;&amp; timer.getTimestamp() &lt;= time</span><br><span class="line">            &amp;&amp; !cancellationContext.isCancelled()</span><br><span class="line">            &amp;&amp; !interrupted) &#123;</span><br><span class="line">        keyContext.setCurrentKey(timer.getKey());</span><br><span class="line">        eventTimeTimersQueue.poll();</span><br><span class="line">        triggerTarget.onEventTime(timer);</span><br><span class="line">        taskIOMetricGroup.getNumFiredTimers().inc();</span><br><span class="line">        <span class="comment">// Check if we should stop advancing after at least one iteration to guarantee progress</span></span><br><span class="line">        <span class="comment">// and prevent a potential starvation.</span></span><br><span class="line">        interrupted = shouldStopAdvancingFn.test();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> !interrupted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>之后 Watermark 就随着数据流一直到 sink 节点，在 StreamSink 中，支持用户自己实现方法向 sink 中写入 Watermark，除此之外什么也不做。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们一起梳理了 Watermark 相关的源码，从 Watermark 的定义，到 Watermark 的处理过程。处理过程分成了初始化、上游发送和下游处理三部分。在下游处理部分，关于触发窗口计算的部分我们简单带过了，后面会再详细介绍这部分。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面我们已经梳理了 Flink 状态和 Checkpoint 相关的源码。从本文开始，我们再来关注另外几个核心概念，即时间、Watermark 和窗口。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：Checkpoint机制（下）</title>
    <link href="https://jackeyzhe.github.io/2025/12/12/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9ACheckpoint%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <id>https://jackeyzhe.github.io/2025/12/12/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9ACheckpoint%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%8B%EF%BC%89/</id>
    <published>2025-12-12T15:15:16.000Z</published>
    <updated>2025-12-16T12:45:58.994Z</updated>
    
    <content type="html"><![CDATA[<p>书接上回，前文我们梳理的 Checkpoint 机制的源码，但是对于如何写入状态数据并没有深入了解。今天就一起来梳理一下这部分代码。<span id="more"></span></p><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>前面我们了解到在 <code>StreamOperatorStateHandler.snapshotState</code> 方法中会创建四个 Future，用来支持不同类型的状态写入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">snapshotInProgress.setKeyedStateRawFuture(snapshotContext.getKeyedStateStreamFuture());</span><br><span class="line">snapshotInProgress.setOperatorStateRawFuture(</span><br><span class="line">        snapshotContext.getOperatorStateStreamFuture());</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="literal">null</span> != operatorStateBackend) &#123;</span><br><span class="line">    snapshotInProgress.setOperatorStateManagedFuture(</span><br><span class="line">            operatorStateBackend.snapshot(</span><br><span class="line">                    checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (useAsyncState &amp;&amp; <span class="literal">null</span> != asyncKeyedStateBackend) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isCanonicalSavepoint(checkpointOptions.getCheckpointType())) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UnsupportedOperationException</span>(<span class="string">&quot;Not supported yet.&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        snapshotInProgress.setKeyedStateManagedFuture(</span><br><span class="line">                asyncKeyedStateBackend.snapshot(</span><br><span class="line">                        checkpointId, timestamp, factory, checkpointOptions));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们主要关心 ManagedState，ManagedState 都是调用 <code>Snapshotable.snapshot</code> 方法来写入数据的，下面具体看 KeyedState 和 OperatorState 的具体实现。</p><h3 id="KeyedState"><a href="#KeyedState" class="headerlink" title="KeyedState"></a>KeyedState</h3><p>KeyedState 我们以 HeapKeyedStateBackend 为例，这里先是创建了一个 <code>SnapshotStrategyRunner</code> 实例，SnapshotStrategyRunner 是一个快照策略的一个执行类，创建完成后就会调用 snapshot 方法。在这个 snapshot 方法中主要做了做了下面几件事：</p><ol><li><p>同步拷贝状态数据的引用。</p></li><li><p>创建 Checkpoint 输出流 <code>CheckpointStateOutputStream</code></p></li><li><p>完成 Checkpoint 持久化</p></li><li><p>返回元信息结果</p></li></ol><h4 id="状态数据引用拷贝"><a href="#状态数据引用拷贝" class="headerlink" title="状态数据引用拷贝"></a>状态数据引用拷贝</h4><p>在 HeapSnapshotStrategy 的 syncPrepareResources 方法中调用了 <code>HeapSnapshotResources.create</code> 方法。这里有一个比较重要的参数是 registeredKVStates，它代表我们在业务代码中注册的状态数据表。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ValueStateDescriptor&lt;Tuple2&lt;Long, Long&gt;&gt; descriptor =</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">ValueStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                <span class="string">&quot;average&quot;</span>,</span><br><span class="line">                TypeInformation.of(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;));</span><br></pre></td></tr></table></figure><p>例如我们这样注册状态数据表，那么 registeredKVStates 的 key 就是 average，value 就是状态表，它通常是一个 CopyOnWriteStateTable。具体的状态数据引用拷贝的逻辑在 <code>processSnapshotMetaInfoForAllStates</code> 方法中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">processSnapshotMetaInfoForAllStates</span><span class="params">(</span></span><br><span class="line"><span class="params">        List&lt;StateMetaInfoSnapshot&gt; metaInfoSnapshots,</span></span><br><span class="line"><span class="params">        Map&lt;StateUID, StateSnapshot&gt; cowStateStableSnapshots,</span></span><br><span class="line"><span class="params">        Map&lt;StateUID, Integer&gt; stateNamesToId,</span></span><br><span class="line"><span class="params">        Map&lt;String, ? extends StateSnapshotRestore&gt; registeredStates,</span></span><br><span class="line"><span class="params">        StateMetaInfoSnapshot.BackendStateType stateType)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String, ? <span class="keyword">extends</span> <span class="title class_">StateSnapshotRestore</span>&gt; kvState :</span><br><span class="line">            registeredStates.entrySet()) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">StateUID</span> <span class="variable">stateUid</span> <span class="operator">=</span> StateUID.of(kvState.getKey(), stateType);</span><br><span class="line">        stateNamesToId.put(stateUid, stateNamesToId.size());</span><br><span class="line">        <span class="type">StateSnapshotRestore</span> <span class="variable">state</span> <span class="operator">=</span> kvState.getValue();</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">null</span> != state) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="type">StateSnapshot</span> <span class="variable">stateSnapshot</span> <span class="operator">=</span> state.stateSnapshot();</span><br><span class="line">            metaInfoSnapshots.add(stateSnapshot.getMetaInfoSnapshot());</span><br><span class="line">            cowStateStableSnapshots.put(stateUid, stateSnapshot);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对每个 State，这里都创建一个 CopyOnWriteStateTableSnapshot，然后存在 cowStateStableSnapshots 里。这里 CopyOnWriteStateTableSnapshot 就是拷贝数据的引用，因此可以同步执行。</p><h4 id="创建-CheckpointStateOutputStream"><a href="#创建-CheckpointStateOutputStream" class="headerlink" title="创建 CheckpointStateOutputStream"></a>创建 CheckpointStateOutputStream</h4><p>创建 CheckpointStateOutputStream 的方法是 <code>CheckpointStreamWithResultProvider.createSimpleStream</code>，生产环境通常使用的是 FsCheckpointStateOutputStream。FsCheckpointStateOutputStream 中的参数如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 状态数据写入缓冲数组，数据先写到内存中，然后 flush 到磁盘</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">byte</span>[] writeBuffer;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 缓冲数组当前写入位置</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> pos;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 文件输出流</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> FSDataOutputStream outStream;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 内存中状态大小阈值，超过阈值会 flush 到磁盘，默认20KB，最大1MB</span></span><br><span class="line"><span class="comment">// 目的是为了减少小文件数量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> localStateThreshold;</span><br><span class="line"></span><br><span class="line"><span class="comment">// checkpoint 基础路径</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Path basePath;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Flink 自己封装的文件系统</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> FileSystem fs;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 状态数据完整路径</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> Path statePath;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 相对路径</span></span><br><span class="line"><span class="keyword">private</span> String relativeStatePath;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否已关闭</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> closed;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否允许使用相对路径</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">boolean</span> allowRelativePaths;</span><br></pre></td></tr></table></figure><h4 id="Checkpoint-持久化"><a href="#Checkpoint-持久化" class="headerlink" title="Checkpoint 持久化"></a>Checkpoint 持久化</h4><p>创建完 CheckpointStateOutputStream 之后，会调用 <code>serializationProxy.write(outView)</code> 写入状态的元数据。元数据包括状态的名称、类型、序列化器等一些配置。</p><p>元数据写完之后，就开始分组写入状态数据。在写入时，先写 keyGroupId，然后再写当前分组的状态数据</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> <span class="variable">keyGroupPos</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        keyGroupPos &lt; keyGroupRange.getNumberOfKeyGroups();</span><br><span class="line">        ++keyGroupPos) &#123;</span><br><span class="line">    <span class="type">int</span> <span class="variable">keyGroupId</span> <span class="operator">=</span> keyGroupRange.getKeyGroupId(keyGroupPos);</span><br><span class="line">    keyGroupRangeOffsets[keyGroupPos] = localStream.getPos();</span><br><span class="line">    <span class="comment">// 写 keyGroupId</span></span><br><span class="line">    outView.writeInt(keyGroupId);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;StateUID, StateSnapshot&gt; stateSnapshot :</span><br><span class="line">            cowStateStableSnapshots.entrySet()) &#123;</span><br><span class="line">        StateSnapshot.<span class="type">StateKeyGroupWriter</span> <span class="variable">partitionedSnapshot</span> <span class="operator">=</span></span><br><span class="line">                stateSnapshot.getValue().getKeyGroupWriter();</span><br><span class="line">        <span class="keyword">try</span> (<span class="type">OutputStream</span> <span class="variable">kgCompressionOut</span> <span class="operator">=</span></span><br><span class="line">                keyGroupCompressionDecorator.decorateWithCompression(localStream)) &#123;</span><br><span class="line">            <span class="type">DataOutputViewStreamWrapper</span> <span class="variable">kgCompressionView</span> <span class="operator">=</span></span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">DataOutputViewStreamWrapper</span>(kgCompressionOut);</span><br><span class="line">            kgCompressionView.writeShort(stateNamesToId.get(stateSnapshot.getKey()));</span><br><span class="line">            <span class="comment">// 写状态数据</span></span><br><span class="line">            partitionedSnapshot.writeStateInKeyGroup(kgCompressionView, keyGroupId);</span><br><span class="line">        &#125; <span class="comment">// this will just close the outer compression stream</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>状态数据写入的调用链路如下</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765870202/Blog/flink/14/writeState.png" alt="writeState"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeState</span><span class="params">(</span></span><br><span class="line"><span class="params">        TypeSerializer&lt;K&gt; keySerializer,</span></span><br><span class="line"><span class="params">        TypeSerializer&lt;N&gt; namespaceSerializer,</span></span><br><span class="line"><span class="params">        TypeSerializer&lt;S&gt; stateSerializer,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nonnull</span> DataOutputView dov,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nullable</span> StateSnapshotTransformer&lt;S&gt; stateSnapshotTransformer)</span></span><br><span class="line">        <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    SnapshotIterator&lt;K, N, S&gt; snapshotIterator =</span><br><span class="line">            getIterator(</span><br><span class="line">                    keySerializer,</span><br><span class="line">                    namespaceSerializer,</span><br><span class="line">                    stateSerializer,</span><br><span class="line">                    stateSnapshotTransformer);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">size</span> <span class="operator">=</span> snapshotIterator.size();</span><br><span class="line">    dov.writeInt(size);</span><br><span class="line">    <span class="keyword">while</span> (snapshotIterator.hasNext()) &#123;</span><br><span class="line">        StateEntry&lt;K, N, S&gt; stateEntry = snapshotIterator.next();</span><br><span class="line">        namespaceSerializer.serialize(stateEntry.getNamespace(), dov);</span><br><span class="line">        keySerializer.serialize(stateEntry.getKey(), dov);</span><br><span class="line">        stateSerializer.serialize(stateEntry.getState(), dov);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="返回结果"><a href="#返回结果" class="headerlink" title="返回结果"></a>返回结果</h4><p>最后一步就是封装并返回元信息，这里收集的信息包括了每个 keyGroup 的状态数据在状态文件中的存储位置，状态数据存储的文件路径、文件大小等。</p><h3 id="OperatorState"><a href="#OperatorState" class="headerlink" title="OperatorState"></a>OperatorState</h3><p>OperatorState 的处理逻辑比 KeyedState 更简单一些，流程上都是先做状态数据的引用快照，然后写入状态数据和返回结果。在写入数据时，没有了分组写入的逻辑。直接处理 operatorState 和 broadcastState。这里就只贴一下调用流程，不做过多赘述了。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765871416/Blog/flink/14/operatorState.png" alt="operatorState"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们重点梳理了 KeyedState 数据写入的代码。其主要步骤包括：同步拷贝状态数据的引用，创建 Checkpoint 输出流 <code>CheckpointStateOutputStream</code> 并完成 Checkpoint 持久化，最后返回元信息结果。OperatorState 的处理过程和 KeyedState 的过程类似，只是少了分组的逻辑。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;书接上回，前文我们梳理的 Checkpoint 机制的源码，但是对于如何写入状态数据并没有深入了解。今天就一起来梳理一下这部分代码。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：Checkpoint机制（上）</title>
    <link href="https://jackeyzhe.github.io/2025/12/09/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9ACheckpoint%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <id>https://jackeyzhe.github.io/2025/12/09/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9ACheckpoint%E6%9C%BA%E5%88%B6%EF%BC%88%E4%B8%8A%EF%BC%89/</id>
    <published>2025-12-09T07:14:59.000Z</published>
    <updated>2025-12-12T14:23:46.079Z</updated>
    
    <content type="html"><![CDATA[<p>前文我们梳理了 Flink 状态管理相关的源码，我们知道，状态是要与 Checkpoint 配合使用的。因此，本文我们就一起来看一下 Checkpoint 相关的源码。<span id="more"></span></p><h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>在<a href="https://jackeyzhe.github.io/2025/08/17/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A6%82%E4%BD%95%E5%81%9A%E5%AE%B9%E9%94%99/">Flink学习笔记：如何做容错</a>一文中，我们介绍了 Flink 的 Checkpoint 机制。Checkpoint 分为 EXACTLY_ONCE 和 AT_LEAST_ONCE 两种模式。</p><p>我们一起回顾一下一次完整的 Checkpoint 具体流程：Checkpoint 是由 CheckpointCoordinator 触发，Source 节点收到触发请求后，会将 State 进行持久化，同时向下游发送 Barrier 消息，下游节点收到 Barrier 消息后，也同样对 State 进行持久化和发送 Barrier 消息。当所有节点都完成持久化过程后 CheckpointCoordinator 会将一些元数据进行持久化。</p><p>带着这些背景知识，我们再来梳理一下 Checkpoint 相关的代码。</p><h3 id="JobManager-端触发流程"><a href="#JobManager-端触发流程" class="headerlink" title="JobManager 端触发流程"></a>JobManager 端触发流程</h3><p>JobManager 在调用 <code>DefaultExecutionGraphBuilder.buildGraph</code> 生成 ExecutionGraph 之后，会调用 <code>executionGraph.enableCheckpointing</code> 方法来设置 Checkpoint 相关的配置，这个方法中创建了 CheckpointCoordinator 并注册了 CheckpointCoordinatorDeActivator 这个监听，它负责启动和停止 Checkpoint 的调度。</p><p>当作业变成 RUNNING 状态时，CheckpointCoordinator 会部署一个定时任务 ScheduledTrigger，这个定时任务就是用来周期性的触发 Checkpoint。</p><p>触发 Checkpoint 的核心逻辑在  <code>CheckpointCoordinator.startTriggeringCheckpoint</code> 这个方法中。这个方法中使用了多个 CompletableFuture 来完成整个流程的编排。具体流程见下图（图中不同颜色代表着使用不同线程池执行）。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765450882/Blog/flink/13/checkpoint.png" alt="checkpoint"></p><ul><li><p>checkpointPlanFuture：这是生成 Checkpoint 执行计划的 Future，Checkpoint Plan 中维护了三个关键的集合：tasksToTrigger、tasksToWaitFor 和 tasksToCommitTo。tasksToTrigger 是所有的 Source 节点，表示触发 Checkpoint 的节点，另外两个集合都包含了全部节点，分别表示等待进行 Checkpoint 的节点和等待提交的节点。</p></li><li><p>pendingCheckpointCompletableFuture：生成完 Checkpoint Plan 之后，会创建 pendingCheckpointCompletableFuture，这个 Future 中有两个执行任务，分别是生成自增的 CheckpointID 和 创建 PendingCheckpoint。PendingCheckpoint 中维护了等待完成的 task 列表，当所有 task 都确认完成之后，PendingCheckpoint 会变成 CompletedCheckpoint。</p></li><li><p>coordinatorCheckpointsComplete：这个 Future 也有两个任务，第一个是初始化存储路径，第二个是触发所有 OperatorCoordinator Checkpoint，并确认它们的状态。</p></li><li><p>masterStatesComplete：触发快照所有的 Master Hook，这一步主要是 CheckpointCoordinator 用来收集 JobManager 级别状态。</p></li><li><p>masterTriggerCompletionPromise：在 masterStatesComplete 和 coordinatorCheckpointsComplete 都执行完成后，会开始执行 masterTriggerCompletionPromise。masterTriggerCompletionPromise 的任务是调用 triggerCheckpointRequest 来产生 Barrier 消息。具体的触发流程见下图。</p></li></ul><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765506339/Blog/flink/13/triggerTaskCheckpoint.png" alt="triggerTask"></p><p>至此，JobManager 端的触发流程就完成了，接下来就到了 TaskManager 端了。</p><h3 id="TaskManager-端执行流程"><a href="#TaskManager-端执行流程" class="headerlink" title="TaskManager 端执行流程"></a>TaskManager 端执行流程</h3><p>进入 TaskExecutor 后，具体调用过程如下图。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765508196/Blog/flink/13/tmCheckpoint.png" alt="TaskManagerCheckpoint"></p><p>TaskManager 的核心逻辑在 <code>SubtaskCheckpointCoordinatorImpl.checkpointState</code> 方法中。这个方法中的注释也很详细，整体上分为6个步骤：</p><ol start="0"><li><p>判断是否是需要终止的 Checkpoint，如果是，则向下游发送取消 Checkpoint 的广播消息。</p></li><li><p>做一些前置的准备工作，这一步通常情况下是一个空实现。</p></li><li><p>向下游发送 Barrier 消息。</p></li><li><p>注册 Alignment timer，当 aligned 超时时，转换为 unaligned。</p></li><li><p>通知 StateWriter，当前 Subtask 对输出通道的写入已经完成，并提交状态句柄。</p></li><li><p>异步执行状态写入并完成上报。</p></li></ol><p>下面我们来关注几个重点的步骤。</p><h4 id="Barrier-消息"><a href="#Barrier-消息" class="headerlink" title="Barrier 消息"></a>Barrier 消息</h4><p>在步骤2中，首先是创建 Barrier，Barrier 消息包括三个部分</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// checkpointId</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> id;</span><br><span class="line"><span class="comment">// 时间戳</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> timestamp;</span><br><span class="line"><span class="comment">// checkpoint 相关参数，包括对齐类型、checkpoint 类型、目前地址</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> CheckpointOptions checkpointOptions;</span><br></pre></td></tr></table></figure><p>生成 Barrier 之后，会调用 <code>operatorChain.broadcastEvent</code> 进行广播消息。这里广播消息就是向下游所有的节点的所有 ResultSubpartition 发送。</p><h4 id="状态写入"><a href="#状态写入" class="headerlink" title="状态写入"></a>状态写入</h4><p><code>SubtaskCheckpointCoordinatorImpl.takeSnapshotSync</code> 方法用来构建 OperatorSnapshotFutures 中的四个 Future，每个 Future 的任务是为不同类型的 State 提供写入逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Nonnull</span> <span class="keyword">private</span> RunnableFuture&lt;SnapshotResult&lt;KeyedStateHandle&gt;&gt; keyedStateManagedFuture;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nonnull</span> <span class="keyword">private</span> RunnableFuture&lt;SnapshotResult&lt;KeyedStateHandle&gt;&gt; keyedStateRawFuture;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nonnull</span> <span class="keyword">private</span> RunnableFuture&lt;SnapshotResult&lt;OperatorStateHandle&gt;&gt; operatorStateManagedFuture;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nonnull</span> <span class="keyword">private</span> RunnableFuture&lt;SnapshotResult&lt;OperatorStateHandle&gt;&gt; operatorStateRawFuture;</span><br></pre></td></tr></table></figure><p>在底层逻辑中，会为每个 Operator 设置对应的 State 的 Future。具体调用流程如下</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765524276/Blog/flink/13/snapshotState.png" alt="snapshotState"></p><p>设置好这些 Future 之后，会在 <code>finishAndReportAsync</code> 方法中创建 AsyncCheckpointRunnable 线程调用 get 来获取执行结果，拿到执行结果后会将 Checkpoint 信息上报给 CheckpointCoordinator。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765526479/Blog/flink/13/tmReport.png" alt="TaskManagerReport"></p><h3 id="JobManager-端确认流程"><a href="#JobManager-端确认流程" class="headerlink" title="JobManager 端确认流程"></a>JobManager 端确认流程</h3><p>TaskManager 通过调用 <code>checkpointCoordinatorGateway.acknowledgeCheckpoint</code> 上报 Checkpoint 信息后，流程就又回到 JobManager 了。</p><p>JobManager 的确认流程主要做了两件事：</p><ol><li><p>将 pendingCheckpoint 转换成 completedCheckpoint，在这个转换过程中，还做了清理过期 Checkpoint 和持久化元数据等操作。</p></li><li><p>向所有 commit 的 Task 发送 Checkpoint 完成的通知。收到这个通知后，大部分 Task 没有什么特殊逻辑，也有一部分 Source 或者 Sink 会做提交事务等操作。</p></li></ol><p>至此，JobManager 和 Source 端算子的一次 Checkpoint 就完成了。接下来我们再看一下非 Source 节点是如何做 Checkpoint 的。</p><h3 id="非-Source-节点处理流程"><a href="#非-Source-节点处理流程" class="headerlink" title="非 Source 节点处理流程"></a>非 Source 节点处理流程</h3><p>非 Source 节点处理 Barrier 的入口和处理业务数据的入口相同，都是 <code>StreamTask.processInput</code> 方法。我们还是先来看具体的调用流程。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765530817/Blog/flink/13/processBarrier.png" alt="processBarrier"></p><p>跟着调用链路，我们一路找到了 processBarrier 方法，这里区分了两个 barrierHandler。SingleCheckpointBarrierHandler 负责处理 EXACTLY_ONCE 语义，CheckpointBarrierTracker 负责处理 AT_LEAST_ONCE 语义。</p><h4 id="EXACTLY-ONCE"><a href="#EXACTLY-ONCE" class="headerlink" title="EXACTLY_ONCE"></a>EXACTLY_ONCE</h4><p>EXACTLY_ONCE 在处理 Barrier 的逻辑如下：</p><ol><li><p>如果只有一个 channel，就立即触发 Checkpoint。</p></li><li><p>如果有多个 channel，分为三种情况</p><p>a) 如果收到的是第一个 channel，标记开始进行 barrier 对齐，并阻塞 channel。</p><p>b) 如果不是第一个 channel，也不是最后一个 channel，只对 channel 进行阻塞。</p><p>c) 如果收到最后一个 channel，就会触发 Checkpoint，并取消所有 channel 阻塞状态。</p></li></ol><p>这里触发的逻辑与 Source 节点相同，通过调用链路可以一直找到 performCheckpoint。</p><h4 id="AT-LEAST-ONCE"><a href="#AT-LEAST-ONCE" class="headerlink" title="AT_LEAST_ONCE"></a>AT_LEAST_ONCE</h4><p>AT_LEAST_ONCE 处理 Barrier 的逻辑如下：</p><ol><li><p>如果只有一个 channel，就立即触发 Checkpoint。</p></li><li><p>如果有多个 channel，同样分为三种情况</p><p>a) 如果收到的是第一个 channel，则更新当前 checkpointID，标记开始 barrier 对齐。</p><p>b) 如果收到的不是第一个 channel，也不是最后一个 channel，就只做计数。</p><p>c) 如果收到的是最后一个 channel，就会开始触发 Checkpoint。</p></li></ol><p>这里触发逻辑也是调用 performCheckpoint，与 Source 节点逻辑相同。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们梳理了 Checkpoint 的源码逻辑。最开始由 JobManager 中的 CheckpointCoordinator 进行调度，并向 TaskManager 发送触发请求。Source 节点收到请求后会向下游发送 Barrier 消息然后写入状态数据和上报 Checkpoint 信息。CheckpointCoordinator 收集完确认消息后，会持久化元数据并通知所有 Task 完成 commit。最后还分别介绍了 EXACTLY_ONCE 和 AT_LEAST_ONCE 模式下非 Source 节点的处理逻辑。</p><p>这里埋一个 Hook，状态数据写入逻辑的细节我们没有深入了解，会在下篇进行深入分析。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前文我们梳理了 Flink 状态管理相关的源码，我们知道，状态是要与 Checkpoint 配合使用的。因此，本文我们就一起来看一下 Checkpoint 相关的源码。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：状态管理</title>
    <link href="https://jackeyzhe.github.io/2025/12/03/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/"/>
    <id>https://jackeyzhe.github.io/2025/12/03/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/</id>
    <published>2025-12-03T03:11:28.000Z</published>
    <updated>2025-12-12T14:34:41.525Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们介绍了 Flink 状态的分类和应用。今天从源码层面再看一下 Flink 是如何管理状态的。<span id="more"></span></p><h3 id="State-概述"><a href="#State-概述" class="headerlink" title="State 概述"></a>State 概述</h3><p>关于 State 的详细介绍可以参考 <a href="https://jackeyzhe.github.io/2025/08/04/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8/">Flink学习笔记：状态类型和应用</a> 和 <a href="https://jackeyzhe.github.io/2025/08/24/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF/">Flink学习笔记：状态后端</a>这两篇文章，为了方面阅读，这里我们再简单介绍一下。</p><h4 id="State-使用"><a href="#State-使用" class="headerlink" title="State 使用"></a>State 使用</h4><p>State 是 Flink 做复杂逻辑所依赖的核心组件。它的分类如下</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1754928263/Blog/flink/4/%E7%8A%B6%E6%80%81%E5%88%86%E7%B1%BB.png" alt="State 分类"></p><p>常见的是 Keyed State 和 Operator State，Keyed State 作用于 KeyedStream 上，Operator State 可以作用于所有的 Operator 上。Keyed State 使用时，需要先创建 StateDescriptor，然后再调用 getState 获取。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ValueStateDescriptor&lt;Tuple2&lt;Long, Long&gt;&gt; descriptor =</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">ValueStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                <span class="string">&quot;average&quot;</span>,</span><br><span class="line">                TypeInformation.of(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;));</span><br><span class="line">ValueState&lt;Tuple2&lt;Long, Long&gt;&gt; sum = getRuntimeContext().getState(descriptor);</span><br></pre></td></tr></table></figure><p>Opeartor State 的获取方式与 Keyed State 类似，都需要 StateDescriptor。Operator State 在定义时需要实现 CheckpointedFunction。</p><h4 id="State-存储"><a href="#State-存储" class="headerlink" title="State 存储"></a>State 存储</h4><p>State Backend 用来管理 State 存储，根据存储格式和存储类型的组合，可以分为三类：</p><ol><li><p>MemoryStateBackend：HashMapStateBackend 和 JobManagerCheckpointStorage 的组合，即将 State 以 Java 对象的形式存储在 JobManager 内存中。</p></li><li><p>FsStateBackend：HashMapStateBackend 和 FileSystemCheckpointStorage 的组合，将 State 以 Java 对象的形式存储在远端文件系统中。</p></li><li><p>RocksDBStateBackend：EmbeddedRocksDBStateBackend 和 FileSystemCheckpointStorage 的组合，State 序列化后存储在 RocksDB。</p></li></ol><h3 id="创建-State-Backend"><a href="#创建-State-Backend" class="headerlink" title="创建 State Backend"></a>创建 State Backend</h3><p>创建 State Backend 的入口在 StreamTask，StreamTask 是 Flink 部署和运行在 TaskManager 的基本单元。</p><p>在 StreamTask 的 invoke 方法中，会先调用 restoreStateAndGates 方法去创建 State Backend。完整的调用链路如下图所示。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764852973/Blog/flink/12/statebackend.png" alt="stateBackend"></p><p>在 streamOperatorStateContext 方法中，分别调用了 keyedStatedBackend 和 operatorStateBackend 来创建两种 State Backend。</p><p>我们先来看 keyedStateBackend 的逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> &lt;K, R <span class="keyword">extends</span> <span class="title class_">Disposable</span> &amp; Closeable&gt; R <span class="title function_">keyedStatedBackend</span><span class="params">(</span></span><br><span class="line"><span class="params">        TypeSerializer&lt;K&gt; keySerializer,</span></span><br><span class="line"><span class="params">        String operatorIdentifierText,</span></span><br><span class="line"><span class="params">        PrioritizedOperatorSubtaskState prioritizedOperatorSubtaskStates,</span></span><br><span class="line"><span class="params">        CloseableRegistry backendCloseableRegistry,</span></span><br><span class="line"><span class="params">        MetricGroup metricGroup,</span></span><br><span class="line"><span class="params">        <span class="type">double</span> managedMemoryFraction,</span></span><br><span class="line"><span class="params">        StateObject.StateObjectSizeStatsCollector statsCollector,</span></span><br><span class="line"><span class="params">        KeyedStateBackendCreator&lt;K, R&gt; keyedStateBackendCreator)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (keySerializer == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">KeyGroupRange</span> <span class="variable">keyGroupRange</span> <span class="operator">=</span></span><br><span class="line">            KeyGroupRangeAssignment.computeKeyGroupRangeForOperatorIndex(</span><br><span class="line">                    taskInfo.getMaxNumberOfParallelSubtasks(),</span><br><span class="line">                    taskInfo.getNumberOfParallelSubtasks(),</span><br><span class="line">                    taskInfo.getIndexOfThisSubtask());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Now restore processing is included in backend building/constructing process, so we need</span></span><br><span class="line">    <span class="comment">// to make sure</span></span><br><span class="line">    <span class="comment">// each stream constructed in restore could also be closed in case of task cancel, for</span></span><br><span class="line">    <span class="comment">// example the data</span></span><br><span class="line">    <span class="comment">// input stream opened for serDe during restore.</span></span><br><span class="line">    <span class="type">CloseableRegistry</span> <span class="variable">cancelStreamRegistryForRestore</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CloseableRegistry</span>();</span><br><span class="line">    backendCloseableRegistry.registerCloseable(cancelStreamRegistryForRestore);</span><br><span class="line">    BackendRestorerProcedure&lt;R, KeyedStateHandle&gt; backendRestorer =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">BackendRestorerProcedure</span>&lt;&gt;(</span><br><span class="line">                    (stateHandles) -&gt; &#123;</span><br><span class="line">                        KeyedStateBackendParametersImpl&lt;K&gt; parameters =</span><br><span class="line">                                <span class="keyword">new</span> <span class="title class_">KeyedStateBackendParametersImpl</span>&lt;&gt;(...);</span><br><span class="line">                        <span class="keyword">return</span> keyedStateBackendCreator.create(...),</span><br><span class="line">                                parameters);</span><br><span class="line">                    &#125;,</span><br><span class="line">                    backendCloseableRegistry,</span><br><span class="line">                    logDescription);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> backendRestorer.createAndRestore(</span><br><span class="line">                prioritizedOperatorSubtaskStates.getPrioritizedManagedKeyedState(),</span><br><span class="line">                statsCollector);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (backendCloseableRegistry.unregisterCloseable(cancelStreamRegistryForRestore)) &#123;</span><br><span class="line">            IOUtils.closeQuietly(cancelStreamRegistryForRestore);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的创建过程也比较简单，先是获取 KeyGroupRange，它表示的是当前 Operator 上处理的 key 的范围。然后就是创建 StateBackend 实例，这里通过 BackendRestorerProcedure 封装统一的恢复、异常处理和资源清理逻辑。operatorStateBackend 方法的逻辑相比较来说，只是少了 KeyGroupRange 的处理，直接创建 StateBackend 实例。</p><h3 id="创建和使用-State"><a href="#创建和使用-State" class="headerlink" title="创建和使用 State"></a>创建和使用 State</h3><h4 id="创建-KeyedState"><a href="#创建-KeyedState" class="headerlink" title="创建 KeyedState"></a>创建 KeyedState</h4><p>KeyedState 是通过调用 StreamingRuntimeContext.getState 方法获取的。我们先来看完整的调用流程。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1765164156/Blog/flink/12/getstate.png" alt="getState"></p><p>在调用 getState 这些方法时，都会先调用 keyedStateStore 提供的方法，它是 Flink 提供的一个封装 keyedStateBackend 的接口。调用流程的最后，是调用 keyedStateBackend 中的 createOrUpdateInternalState 方法（这里我们以 HeapStateBackend 为例）。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;N, SV, SEV, S <span class="keyword">extends</span> <span class="title class_">State</span>, IS <span class="keyword">extends</span> <span class="title class_">S</span>&gt; IS <span class="title function_">createOrUpdateInternalState</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="meta">@Nonnull</span> TypeSerializer&lt;N&gt; namespaceSerializer,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nonnull</span> StateDescriptor&lt;S, SV&gt; stateDesc,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nonnull</span> StateSnapshotTransformFactory&lt;SEV&gt; snapshotTransformFactory,</span></span><br><span class="line"><span class="params">        <span class="type">boolean</span> allowFutureMetadataUpdates)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    StateTable&lt;K, N, SV&gt; stateTable =</span><br><span class="line">            tryRegisterStateTable(</span><br><span class="line">                    namespaceSerializer,</span><br><span class="line">                    stateDesc,</span><br><span class="line">                    getStateSnapshotTransformFactory(stateDesc, snapshotTransformFactory),</span><br><span class="line">                    allowFutureMetadataUpdates);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">    <span class="type">IS</span> <span class="variable">createdState</span> <span class="operator">=</span> (IS) createdKVStates.get(stateDesc.getName());</span><br><span class="line">    <span class="keyword">if</span> (createdState == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="type">StateCreateFactory</span> <span class="variable">stateCreateFactory</span> <span class="operator">=</span> STATE_CREATE_FACTORIES.get(stateDesc.getType());</span><br><span class="line">        <span class="keyword">if</span> (stateCreateFactory == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">FlinkRuntimeException</span>(stateNotSupportedMessage(stateDesc));</span><br><span class="line">        &#125;</span><br><span class="line">        createdState =</span><br><span class="line">                stateCreateFactory.createState(stateDesc, stateTable, getKeySerializer());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">StateUpdateFactory</span> <span class="variable">stateUpdateFactory</span> <span class="operator">=</span> STATE_UPDATE_FACTORIES.get(stateDesc.getType());</span><br><span class="line">        <span class="keyword">if</span> (stateUpdateFactory == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">FlinkRuntimeException</span>(stateNotSupportedMessage(stateDesc));</span><br><span class="line">        &#125;</span><br><span class="line">        createdState = stateUpdateFactory.updateState(stateDesc, stateTable, createdState);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    createdKVStates.put(stateDesc.getName(), createdState);</span><br><span class="line">    <span class="keyword">return</span> createdState;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Map&lt;StateDescriptor.Type, StateCreateFactory&gt; STATE_CREATE_FACTORIES =</span><br><span class="line">        Stream.of(</span><br><span class="line">                        Tuple2.of(</span><br><span class="line">                                StateDescriptor.Type.VALUE,</span><br><span class="line">                                (StateCreateFactory) HeapValueState::create),</span><br><span class="line">                        Tuple2.of(</span><br><span class="line">                                StateDescriptor.Type.LIST,</span><br><span class="line">                                (StateCreateFactory) HeapListState::create),</span><br><span class="line">                        Tuple2.of(</span><br><span class="line">                                StateDescriptor.Type.MAP,</span><br><span class="line">                                (StateCreateFactory) HeapMapState::create),</span><br><span class="line">                        Tuple2.of(</span><br><span class="line">                                StateDescriptor.Type.AGGREGATING,</span><br><span class="line">                                (StateCreateFactory) HeapAggregatingState::create),</span><br><span class="line">                        Tuple2.of(</span><br><span class="line">                                StateDescriptor.Type.REDUCING,</span><br><span class="line">                                (StateCreateFactory) HeapReducingState::create))</span><br><span class="line">                .collect(Collectors.toMap(t -&gt; t.f0, t -&gt; t.f1));</span><br></pre></td></tr></table></figure><p>这里首先是注册了一个 StateTable，这个是 State 中一个非常重要的成员变量，它内部是一个类似 Map 的结构，用来保存 key 和 key 的状态。</p><p>STATE_CREATE_FACTORIES 这个变量保存了不同类型的 State 和它对应的创建方法，同理 STATE_UPDATE_FACTORIES 保存的是不同 State 对应的 更新方法。</p><h4 id="创建-OperatorState"><a href="#创建-OperatorState" class="headerlink" title="创建 OperatorState"></a>创建 OperatorState</h4><p>看完了 KeyedState 的创建过程后，我们再来看下 OperatorState 的创建过程。</p><p>OperatorState 的创建方法是通过 FunctionInitializationContext 先获取到 OperatorStateStore，它与 KeyedStateStore 类似，都是对 StateBackend 的方法进行了封装。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ListStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                    <span class="string">&quot;buffered-elements&quot;</span>,</span><br><span class="line">                    TypeInformation.of(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;&#125;));</span><br><span class="line"></span><br><span class="line">    checkpointedState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element : checkpointedState.get()) &#123;</span><br><span class="line">            bufferedElements.add(element);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>OperatorStateStore 的 getListState 方法中，直接创建出了 PartitionableListState，同时也做了一些缓存操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;S&gt; ListState&lt;S&gt; <span class="title function_">getListState</span><span class="params">(</span></span><br><span class="line"><span class="params">        ListStateDescriptor&lt;S&gt; stateDescriptor, OperatorStateHandle.Mode mode)</span></span><br><span class="line">        <span class="keyword">throws</span> StateMigrationException &#123;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">    PartitionableListState&lt;S&gt; partitionableListState =</span><br><span class="line">            (PartitionableListState&lt;S&gt;) registeredOperatorStates.get(name);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> == partitionableListState) &#123;</span><br><span class="line">        <span class="comment">// no restored state for the state name; simply create new state holder</span></span><br><span class="line"></span><br><span class="line">        partitionableListState =</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">PartitionableListState</span>&lt;&gt;(</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">RegisteredOperatorStateBackendMetaInfo</span>&lt;&gt;(</span><br><span class="line">                                name, partitionStateSerializer, mode));</span><br><span class="line"></span><br><span class="line">        registeredOperatorStates.put(name, partitionableListState);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ......</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    accessedStatesByName.put(name, partitionableListState);</span><br><span class="line">    <span class="keyword">return</span> partitionableListState;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>PartitionableListState 内部有一个 ArrayList 用于保存数据。</p><h4 id="使用-KeyedState"><a href="#使用-KeyedState" class="headerlink" title="使用 KeyedState"></a>使用 KeyedState</h4><p>了解完 State 的创建之后，接下来就是 State 的使用了。我们以 HeapValueState 为例来看如何获取 State。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// HeapValueState 类</span></span><br><span class="line"><span class="keyword">public</span> V <span class="title function_">value</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">V</span> <span class="variable">result</span> <span class="operator">=</span> stateTable.get(currentNamespace);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (result == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> getDefaultValue();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 HeapValueState 类的 value 方法中，直接调用 StateTable 的 get 方法，最终调用的是 CopyOnWriteStateMap 的 get 方法，这个方法与 HashMap 的 get 方法比较类似。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> S <span class="title function_">get</span><span class="params">(K key, N namespace)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">hash</span> <span class="operator">=</span> computeHashForOperationAndDoIncrementalRehash(key, namespace);</span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">requiredVersion</span> <span class="operator">=</span> highestRequiredSnapshotVersion;</span><br><span class="line">    <span class="keyword">final</span> StateMapEntry&lt;K, N, S&gt;[] tab = selectActiveTable(hash);</span><br><span class="line">    <span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> hash &amp; (tab.length - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (StateMapEntry&lt;K, N, S&gt; e = tab[index]; e != <span class="literal">null</span>; e = e.next) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">K</span> <span class="variable">eKey</span> <span class="operator">=</span> e.key;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">N</span> <span class="variable">eNamespace</span> <span class="operator">=</span> e.namespace;</span><br><span class="line">        <span class="keyword">if</span> ((e.hash == hash &amp;&amp; key.equals(eKey) &amp;&amp; namespace.equals(eNamespace))) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// copy-on-write check for state</span></span><br><span class="line">            <span class="keyword">if</span> (e.stateVersion &lt; requiredVersion) &#123;</span><br><span class="line">                <span class="comment">// copy-on-write check for entry</span></span><br><span class="line">                <span class="keyword">if</span> (e.entryVersion &lt; requiredVersion) &#123;</span><br><span class="line">                    e = handleChainedEntryCopyOnWrite(tab, hash &amp; (tab.length - <span class="number">1</span>), e);</span><br><span class="line">                &#125;</span><br><span class="line">                e.stateVersion = stateMapVersion;</span><br><span class="line">                e.state = getStateSerializer().copy(e.state);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> e.state;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用-OperatorState"><a href="#使用-OperatorState" class="headerlink" title="使用 OperatorState"></a>使用 OperatorState</h4><p>OperatorState 底层使用的是 PartitionableListState，前面也提到了，它的内部用了一个 ArrayList 来保存数据，对于 OperatorState 的各种操作也都是来操作这个 ArrayList。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">clear</span><span class="params">()</span> &#123;</span><br><span class="line">    internalList.clear();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> Iterable&lt;S&gt; <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> internalList;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(S value)</span> &#123;</span><br><span class="line">    Preconditions.checkNotNull(value, <span class="string">&quot;You cannot add null to a ListState.&quot;</span>);</span><br><span class="line">    internalList.add(value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">update</span><span class="params">(List&lt;S&gt; values)</span> &#123;</span><br><span class="line">    internalList.clear();</span><br><span class="line"></span><br><span class="line">    addAll(values);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addAll</span><span class="params">(List&lt;S&gt; values)</span> &#123;</span><br><span class="line">    Preconditions.checkNotNull(values, <span class="string">&quot;List of values to add cannot be null.&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span> (!values.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (S value : values) &#123;</span><br><span class="line">            checkNotNull(value, <span class="string">&quot;Any value to add to a list cannot be null.&quot;</span>);</span><br><span class="line">            add(value);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文对 State 的相关代码进行了梳理。包括 StateBackend 的创建，KeyedState 和 OperatorState 的创建和使用。State 和 Checkpoint 两者需要结合使用，因此后面我们会再梳理 Checkpoint 的相关代码。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面我们介绍了 Flink 状态的分类和应用。今天从源码层面再看一下 Flink 是如何管理状态的。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：集群启动</title>
    <link href="https://jackeyzhe.github.io/2025/11/27/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8/"/>
    <id>https://jackeyzhe.github.io/2025/11/27/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8/</id>
    <published>2025-11-27T08:35:40.000Z</published>
    <updated>2025-12-02T13:16:13.741Z</updated>
    
    <content type="html"><![CDATA[<p>前文中，我们已经了解了 Flink 的三种执行图是怎么生成的。今天继续看一下 Flink 集群是如何启动的。<span id="more"></span></p><h3 id="启动脚本"><a href="#启动脚本" class="headerlink" title="启动脚本"></a>启动脚本</h3><p>集群启动脚本的位置在：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flink-dist/src/main/flink-bin/bin/start-cluster.sh</span><br></pre></td></tr></table></figure><p>脚本会负责启动 JobManager 和 TaskManager，我们主要关注 standalone 启动模式，具体的流程见下图。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764258366/Blog/flink/11/start-cluster.png" alt="start-cluster"></p><p>从图中可以看出 JobManager 是通过 jobmanager.sh 文件启动的，TaskManager 是通过taskmanager.sh 启动的，两者都调用了 flink-daemon.sh，通过传递不同的参数，最终运行不同的 Java 类。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="variable">$DAEMON</span> <span class="keyword">in</span></span><br><span class="line">    (taskexecutor)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.taskexecutor.TaskManagerRunner</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (zookeeper)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (historyserver)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.webmonitor.history.HistoryServer</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonesession)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (standalonejob)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.container.entrypoint.StandaloneApplicationClusterEntryPoint</span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (sql-gateway)</span><br><span class="line">        CLASS_TO_RUN=org.apache.flink.table.gateway.SqlGateway</span><br><span class="line">        SQL_GATEWAY_CLASSPATH=<span class="string">&quot;`findSqlGatewayJar`&quot;</span>:<span class="string">&quot;`findFlinkPythonJar`&quot;</span></span><br><span class="line">    ;;</span><br><span class="line"></span><br><span class="line">    (*)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Unknown daemon &#x27;<span class="variable">$&#123;DAEMON&#125;</span>&#x27;. <span class="variable">$USAGE</span>.&quot;</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><h3 id="JobManager-启动流程"><a href="#JobManager-启动流程" class="headerlink" title="JobManager 启动流程"></a>JobManager 启动流程</h3><p>在 StandaloneSessionClusterEntrypoint 的 main 方法中，主要就是加载各种配置和环境变量，然后调用 ClusterEntrypoint.runClusterEntrypoint 来启动集群。跟着调用链一直找到 ClusterEntrypoint.runCluster 方法，这里会启动 ResourceManager、DispatcherRunner 等组件。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">runCluster</span><span class="params">(Configuration configuration, PluginManager pluginManager)</span></span><br><span class="line">        <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">        <span class="comment">// 初始化各种服务</span></span><br><span class="line">        initializeServices(configuration, pluginManager);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 DispatcherResourceManagerComponentFactory，</span></span><br><span class="line">        <span class="comment">// 包含了三个核心组件的 Factory</span></span><br><span class="line">        <span class="comment">// DispatcherRunnerFactory、ResourceManagerFactory、RestEndpointFactory</span></span><br><span class="line">        <span class="keyword">final</span> <span class="type">DispatcherResourceManagerComponentFactory</span></span><br><span class="line">                <span class="variable">dispatcherResourceManagerComponentFactory</span> <span class="operator">=</span></span><br><span class="line">                        createDispatcherResourceManagerComponentFactory(configuration);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 启动 ResourceManager、DispatcherRunner、WebMonitorEndpoint</span></span><br><span class="line">        clusterComponent =</span><br><span class="line">                dispatcherResourceManagerComponentFactory.create(</span><br><span class="line">                        configuration,</span><br><span class="line">                        resourceId.unwrap(),</span><br><span class="line">                        ioExecutor,</span><br><span class="line">                        commonRpcService,</span><br><span class="line">                        haServices,</span><br><span class="line">                        blobServer,</span><br><span class="line">                        heartbeatServices,</span><br><span class="line">                        delegationTokenManager,</span><br><span class="line">                        metricRegistry,</span><br><span class="line">                        executionGraphInfoStore,</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">RpcMetricQueryServiceRetriever</span>(</span><br><span class="line">                                metricRegistry.getMetricQueryServiceRpcService()),</span><br><span class="line">                        failureEnrichers,</span><br><span class="line">                        <span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 关闭服务</span></span><br><span class="line">        clusterComponent</span><br><span class="line">                .getShutDownFuture()</span><br><span class="line">                .whenComplete(</span><br><span class="line">                        (ApplicationStatus applicationStatus, Throwable throwable) -&gt; &#123;</span><br><span class="line">                            <span class="keyword">if</span> (throwable != <span class="literal">null</span>) &#123;</span><br><span class="line">                                shutDownAsync(</span><br><span class="line">                                        ApplicationStatus.UNKNOWN,</span><br><span class="line">                                        ShutdownBehaviour.GRACEFUL_SHUTDOWN,</span><br><span class="line">                                        ExceptionUtils.stringifyException(throwable),</span><br><span class="line">                                        <span class="literal">false</span>);</span><br><span class="line">                            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                <span class="comment">// This is the general shutdown path. If a separate more</span></span><br><span class="line">                                <span class="comment">// specific shutdown was</span></span><br><span class="line">                                <span class="comment">// already triggered, this will do nothing</span></span><br><span class="line">                                shutDownAsync(</span><br><span class="line">                                        applicationStatus,</span><br><span class="line">                                        ShutdownBehaviour.GRACEFUL_SHUTDOWN,</span><br><span class="line">                                        <span class="literal">null</span>,</span><br><span class="line">                                        <span class="literal">true</span>);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面来详细看一下这几个方法， initializeServices 就是负责初始化各种服务，有几个比较重要的可以着重关注下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 初始化并启动一个通用的 RPC Service</span></span><br><span class="line">commonRpcService = RpcUtils.createRemoteRpcService(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个 IO 线程池，线程数量位 CPU 核数 * 4</span></span><br><span class="line">ioExecutor = Executors.newFixedThreadPool(...);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 HA 服务组件，根据配置初始化 Standalone、ZK、K8S 三种</span></span><br><span class="line">haServices = createHaServices(configuration, ioExecutor, rpcSystem);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建并启动 blobServer,blobServer 可以理解为是 Flink 内部的</span></span><br><span class="line">blobServer = BlobUtils.createBlobServer(...);</span><br><span class="line">blobServer.start();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建心跳服务</span></span><br><span class="line">heartbeatServices = createHeartbeatServices(configuration);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个监控服务</span></span><br><span class="line">processMetricGroup = MetricUtils.instantiateProcessMetricGroup(...);</span><br></pre></td></tr></table></figure><p>createDispatcherResourceManagerComponentFactory 这个方法就是创建了三个工厂类，不需要过多介绍。我们重点关注 dispatcherResourceManagerComponentFactory.create 方法，即 ResourceManager、DispatcherRunner、WebMonitorEndpoint 是如何启动的。</p><h4 id="WebMonitorEndpoint"><a href="#WebMonitorEndpoint" class="headerlink" title="WebMonitorEndpoint"></a>WebMonitorEndpoint</h4><p>WebMonitorEndpoint 的启动流程图如下，图中细箭头代表同一个方法中顺序调用，粗箭头代表进入上一个方法内部的调用。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764428386/Blog/flink/11/webmonitor.png" alt="webMonitorEndpoint"></p><p>WebMonitorEndpoint 创建和启动步骤如下：</p><ol><li><p>通过工厂创建出了 WebMonitorEndpoint，这里就是比较常规的初始化操作。</p></li><li><p>调用 WebMonitorEndpoint 的 start 方法开始启动，start 方法内部先是创建了一个 Router 并调用 initializeHandlers 创建了一大堆 handler（是真的一大堆，这个方法有接近一千行，都是在创建 handler），创建完成之后，对 handler 进行排序和去重，再把它们都注册到 Router 中。这里排序是为了确保路由匹配的正确性，排序规则是先静态路径（/jobs/overview），后动态路径（/jobs/:jobid），假如我们没有排序，先注册了 /jobs/:jobid ，后注册 /jobs/overview ，这时当我们请求 /jobs/overview 时，就会被错误的路由到 /jobs/:jobid 上去。</p></li><li><p>是调用 startInternal 方法，在 startInternal 方法内部只有 leader 选举和启动缓存清理任务两个步骤。</p></li></ol><h4 id="ResourceManager"><a href="#ResourceManager" class="headerlink" title="ResourceManager"></a>ResourceManager</h4><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764517440/Blog/flink/11/resourceManager.png" alt="ResourceManager"></p><p>ResourceManager 创建和启动步骤如下：</p><ol><li><p>调用 ResourceManagerServiceImpl.create 方法创建 ResourceManagerService，这里只是创建 ResourceManager 服务，实际创建 ResourceManager 在后面的步骤中。</p></li><li><p>调用 resourceManagerService.start 方法启动服务，这里就是启动选主服务，standalne 模式直接调用 grantLeadership 成为 leader。</p></li><li><p>成为 leader 后，就会调用 startNewLeaderResourceManager 方法，这个方法中会调用 resourceManagerFactory.createResourceManager 正式创建 resourceManager。创建完成后，就会调用 resourceManager.start 来启动它。</p></li><li><p>启动后会回调 ResourceManager.onStart 方法。这里调用 startHeartbeatServices 启动了两个心跳服务，一个是 ResourceManager 和 TaskManager 之间的心跳，一个是 ResourceManager 和 JobManager 之间的心跳，然后会启动 SlotManager。SlotManager 可以被当作 Flink 集群的资源调度中心。它会负责管理集群中的所有 Slot 资源，也需要响应 JobManager 的资源请求。</p></li></ol><h4 id="DispatcherRunner"><a href="#DispatcherRunner" class="headerlink" title="DispatcherRunner"></a>DispatcherRunner</h4><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764578180/Blog/flink/11/dispatcherRunner.png" alt="dispatcherRunner"></p><ol><li><p>先创建工厂，创建完成后调用 DefaultDispatcherRunner.create 创建出 DispatcherRunner，接着是调用 start 启动选主流程。</p></li><li><p>选主完成后就调用 startNewDispatcherLeaderProcess 启动新的流程。启动新的流程需要先关闭旧流程，然后创建新的 dispatcherLeaderProcess，并调用 start 启动。</p></li><li><p>启动时，会回调 onStart 方法。</p></li><li><p>回调方法中，先启动 executionPlanStore，它主要是用于持久化 JobGraph。然后恢复执行计划，重建状态（如果是从失败中恢复），实例化 Dispatcher，完成作业启动。</p></li></ol><h3 id="TaskManager-启动流程"><a href="#TaskManager-启动流程" class="headerlink" title="TaskManager 启动流程"></a>TaskManager 启动流程</h3><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1764666573/Blog/flink/11/taskManager.png" alt="taskManager"></p><p>TaskManager 是 Flink 的执行节点，其最小执行单元是 slot。TaskManager 启动流程也主要是和资源管理相关，包括 slot 列表的管理和与 ResourceManager 的通信。</p><p>TaskManager 启动流程大体分为以下几部分：</p><ol><li><p>构建并启动 TaskManagerRunner（蓝色部分）</p></li><li><p>启动 TaskExecutor（红色部分）</p></li><li><p>完成与 ResourceManager 的连接（橙色部分）</p></li></ol><h4 id="启动-TaskManagerRunner"><a href="#启动-TaskManagerRunner" class="headerlink" title="启动 TaskManagerRunner"></a>启动 TaskManagerRunner</h4><p>在 TaskManagerRunner 的 start 方法中，有两个步骤：</p><p>第一步是调用 startTaskManagerRunnerServices 创建和启动了很多服务，这一点和 JobManager 的启动流程比较像。这些服务包括了高可用服务、心跳服务、监控指标服务等，这里也创建了 taskExecutorService，它的启动在第二步。</p><p>第二步是调用 taskExecutorService.start 方法，启动 TaskExecutorService，它内部主要负责启动 TaskExecutor。</p><h4 id="启动-TaskExecutor"><a href="#启动-TaskExecutor" class="headerlink" title="启动 TaskExecutor"></a>启动 TaskExecutor</h4><p>TaskExecutor 是 TaskManager 内部的一个核心组件，负责帮助 TaskManager 完成 task 的部署和执行等核心操作。</p><p>在上一步调用 taskExecutor 的 start 方法后，会回调 onStart 方法，这里主要是三个步骤</p><ol><li><p>连接 ResourceManager 以及注册监听</p></li><li><p>启动 taskSlotTable</p></li><li><p>连接 JobMaster 以及注册监听</p></li></ol><p>第一步我们在下面详细解释。第二步启动的 TaskSlotTable 是 TaskManager 中负责资源的核心组件，它维护了一个 Slot 列表，管理每个 Slot 的状态，负责 Slot 的分配和释放。第三步主要是和 JobMaster 建立连接并保持心跳，同时也会接收 Slot 申请的请求。</p><h4 id="连接-ResourceManager"><a href="#连接-ResourceManager" class="headerlink" title="连接 ResourceManager"></a>连接 ResourceManager</h4><p>TaskExecutor 注册完监听之后，会收到 ResourceManagerLeaderListener.notifyLeaderAddress 方法回调。回调方法中，会创建一个 TaskExecutorToResourceManagerConnection 实例并启动它。这个类是用来将 TaskExecutor 注册到 ResourceManager，注册成功会回调 onRegistrationSuccess 方法。回调成功的方法中，TaskManager 会调用 resourceManagerGateway.sendSlotReport 将 Slot 的状态进行上报。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文介绍了 Flink 集群在 Standalone 模式下的启动过程，其中 JobManager 重点介绍了 WebMonitorEndpoint、ResourceManager 和 DispatcherRunner 这三个组件的启动过程。TaskManager 主要介绍了启动 TaskExecutor 和连接 ResourceManager 的过程。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前文中，我们已经了解了 Flink 的三种执行图是怎么生成的。今天继续看一下 Flink 集群是如何启动的。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：如何生成ExecutionGraph</title>
    <link href="https://jackeyzhe.github.io/2025/11/08/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90ExecutionGraph/"/>
    <id>https://jackeyzhe.github.io/2025/11/08/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90ExecutionGraph/</id>
    <published>2025-11-08T15:23:57.000Z</published>
    <updated>2025-11-25T15:10:23.710Z</updated>
    
    <content type="html"><![CDATA[<p>今天我们一起来了解 Flink 最后一种执行图，ExecutionGraph 的执行过程。<span id="more"></span></p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>在阅读源码之前，我们先来了解一下 ExecutionGraph 中的一些基本概念。</p><ul><li><p><strong>ExecutionJobVertex:</strong>  ExecutionJobVertex 是 ExecutionGraph 中的节点，对应的是 JobGraph 中的 JobVertex。</p></li><li><p><strong>ExecutionVertex:</strong> 每个 ExecutionJobVertex 都包含了一组 ExecutionVertex，ExecutionVertex 的数量就是节点对应的并行度。</p></li><li><p><strong>IntermediateResult:</strong> IntermediateResult 表示节点的输出结果，与之对应的是 JobGraph 中的 IntermediateDataSet。</p></li><li><p><strong>IntermediateResultPartition:</strong> IntermediateResultPartition 是每个 ExecutionVertex 的输出。</p></li><li><p><strong>EdgeManager:</strong> EdgeManager 主要负责存储 ExecutionGraph 中所有之间的连接，包括其并行度。</p></li><li><p><strong>Execution:</strong> Execution 可以认为是一次实际的运行尝试。每次执行时，Flink 都会将ExecutionVertex 封装成一个 Execution，并通过一个 ExecutionAttemptID 来做唯一标识。</p></li></ul><h3 id="ExecutionGraph-生成过程"><a href="#ExecutionGraph-生成过程" class="headerlink" title="ExecutionGraph 生成过程"></a>ExecutionGraph 生成过程</h3><p>了解了这些基本概念之后，我们一起来看一下 ExecutionGraph 的具体生成过程。生成 ExecutionGraph 的代码入口是 DefaultExecutionGraphBuilder.build 方法。</p><p>首先是获取一些基本信息，包括 jobInformation、jobStatusChangedListeners 等。</p><p>接下来就是创建一个 DefaultExecutionGraph 和生成执行计划。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create a new execution graph, if none exists so far</span></span><br><span class="line"><span class="keyword">final</span> <span class="type">DefaultExecutionGraph</span> <span class="variable">executionGraph</span> <span class="operator">=</span></span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">DefaultExecutionGraph</span>(</span><br><span class="line">                jobInformation,</span><br><span class="line">                futureExecutor,</span><br><span class="line">                ioExecutor,</span><br><span class="line">                rpcTimeout,</span><br><span class="line">                executionHistorySizeLimit,</span><br><span class="line">                classLoader,</span><br><span class="line">                blobWriter,</span><br><span class="line">                partitionGroupReleaseStrategyFactory,</span><br><span class="line">                shuffleMaster,</span><br><span class="line">                partitionTracker,</span><br><span class="line">                executionDeploymentListener,</span><br><span class="line">                executionStateUpdateListener,</span><br><span class="line">                initializationTimestamp,</span><br><span class="line">                vertexAttemptNumberStore,</span><br><span class="line">                vertexParallelismStore,</span><br><span class="line">                isDynamicGraph,</span><br><span class="line">                executionJobVertexFactory,</span><br><span class="line">                jobGraph.getJobStatusHooks(),</span><br><span class="line">                markPartitionFinishedStrategy,</span><br><span class="line">                taskDeploymentDescriptorFactory,</span><br><span class="line">                jobStatusChangedListeners,</span><br><span class="line">                executionPlanSchedulingContext);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    executionGraph.setPlan(JsonPlanGenerator.generatePlan(jobGraph));</span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    log.warn(<span class="string">&quot;Cannot create plan for job&quot;</span>, t);</span><br><span class="line">    <span class="comment">// give the graph an empty plan</span></span><br><span class="line">    executionGraph.setPlan(<span class="keyword">new</span> <span class="title class_">JobPlanInfo</span>.Plan(<span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, <span class="string">&quot;&quot;</span>, <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面就是两个比较核心的方法 getVerticesSortedTopologicallyFromSources 和 attachJobGraph。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// topologically sort the job vertices and attach the graph to the existing one</span></span><br><span class="line">List&lt;JobVertex&gt; sortedTopology = jobGraph.getVerticesSortedTopologicallyFromSources();</span><br><span class="line"></span><br><span class="line">executionGraph.attachJobGraph(sortedTopology, jobManagerJobMetricGroup);</span><br></pre></td></tr></table></figure><p>这两个方法是先将 JobVertex 进行排序，然后构建 ExecutionGraph 的拓扑图。</p><h4 id="getVerticesSortedTopologicallyFromSources"><a href="#getVerticesSortedTopologicallyFromSources" class="headerlink" title="getVerticesSortedTopologicallyFromSources"></a>getVerticesSortedTopologicallyFromSources</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> List&lt;JobVertex&gt; <span class="title function_">getVerticesSortedTopologicallyFromSources</span><span class="params">()</span></span><br><span class="line">        <span class="keyword">throws</span> InvalidProgramException &#123;</span><br><span class="line">    <span class="comment">// early out on empty lists</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">this</span>.taskVertices.isEmpty()) &#123;</span><br><span class="line">        <span class="keyword">return</span> Collections.emptyList();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;JobVertex&gt; sorted = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;JobVertex&gt;(<span class="built_in">this</span>.taskVertices.size());</span><br><span class="line">    Set&lt;JobVertex&gt; remaining = <span class="keyword">new</span> <span class="title class_">LinkedHashSet</span>&lt;JobVertex&gt;(<span class="built_in">this</span>.taskVertices.values());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// start by finding the vertices with no input edges</span></span><br><span class="line">    <span class="comment">// and the ones with disconnected inputs (that refer to some standalone data set)</span></span><br><span class="line">    &#123;</span><br><span class="line">        Iterator&lt;JobVertex&gt; iter = remaining.iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">            <span class="type">JobVertex</span> <span class="variable">vertex</span> <span class="operator">=</span> iter.next();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (vertex.isInputVertex()) &#123;</span><br><span class="line">                sorted.add(vertex);</span><br><span class="line">                iter.remove();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="variable">startNodePos</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// traverse from the nodes that were added until we found all elements</span></span><br><span class="line">    <span class="keyword">while</span> (!remaining.isEmpty()) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// first check if we have more candidates to start traversing from. if not, then the</span></span><br><span class="line">        <span class="comment">// graph is cyclic, which is not permitted</span></span><br><span class="line">        <span class="keyword">if</span> (startNodePos &gt;= sorted.size()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">InvalidProgramException</span>(<span class="string">&quot;The job graph is cyclic.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">JobVertex</span> <span class="variable">current</span> <span class="operator">=</span> sorted.get(startNodePos++);</span><br><span class="line">        addNodesThatHaveNoNewPredecessors(current, sorted, remaining);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sorted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码是将所有的节点进行排序，先将所有的 Source 节点筛选出来，然后再将剩余节点假如列表。这样就能构建出最终的拓扑图。</p><h4 id="attachJobGraph"><a href="#attachJobGraph" class="headerlink" title="attachJobGraph"></a>attachJobGraph</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">attachJobGraph</span><span class="params">(</span></span><br><span class="line"><span class="params">        List&lt;JobVertex&gt; verticesToAttach, JobManagerJobMetricGroup jobManagerJobMetricGroup)</span></span><br><span class="line">        <span class="keyword">throws</span> JobException &#123;</span><br><span class="line"></span><br><span class="line">    assertRunningInJobMasterMainThread();</span><br><span class="line"></span><br><span class="line">    LOG.debug(</span><br><span class="line">            <span class="string">&quot;Attaching &#123;&#125; topologically sorted vertices to existing job graph with &#123;&#125; &quot;</span></span><br><span class="line">                    + <span class="string">&quot;vertices and &#123;&#125; intermediate results.&quot;</span>,</span><br><span class="line">            verticesToAttach.size(),</span><br><span class="line">            tasks.size(),</span><br><span class="line">            intermediateResults.size());</span><br><span class="line"></span><br><span class="line">    attachJobVertices(verticesToAttach, jobManagerJobMetricGroup);</span><br><span class="line">    <span class="keyword">if</span> (!isDynamic) &#123;</span><br><span class="line">        initializeJobVertices(verticesToAttach);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the topology assigning should happen before notifying new vertices to failoverStrategy</span></span><br><span class="line">    executionTopology = DefaultExecutionTopology.fromExecutionGraph(<span class="built_in">this</span>);</span><br><span class="line"></span><br><span class="line">    partitionGroupReleaseStrategy =</span><br><span class="line">            partitionGroupReleaseStrategyFactory.createInstance(getSchedulingTopology());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>attachJobGraph 方法主要包含两步逻辑，第一步是调用 attachJobVertices 方法创建 ExecutionJobVertex 实例，第二步是调用 fromExecutionGraph 创建一些其他的核心对象。</p><p><strong>attachJobVertices</strong></p><p>attachJobVertices 方法中就是遍历所有的 JobVertex，然后利用 JobVertex 生成 ExecutionJobVertex。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Attach job vertices without initializing them. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">attachJobVertices</span><span class="params">(</span></span><br><span class="line"><span class="params">        List&lt;JobVertex&gt; topologicallySorted, JobManagerJobMetricGroup jobManagerJobMetricGroup)</span></span><br><span class="line">        <span class="keyword">throws</span> JobException &#123;</span><br><span class="line">    <span class="keyword">for</span> (JobVertex jobVertex : topologicallySorted) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (jobVertex.isInputVertex() &amp;&amp; !jobVertex.isStoppable()) &#123;</span><br><span class="line">            <span class="built_in">this</span>.isStoppable = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">VertexParallelismInformation</span> <span class="variable">parallelismInfo</span> <span class="operator">=</span></span><br><span class="line">                parallelismStore.getParallelismInfo(jobVertex.getID());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// create the execution job vertex and attach it to the graph</span></span><br><span class="line">        <span class="type">ExecutionJobVertex</span> <span class="variable">ejv</span> <span class="operator">=</span></span><br><span class="line">                executionJobVertexFactory.createExecutionJobVertex(</span><br><span class="line">                        <span class="built_in">this</span>,</span><br><span class="line">                        jobVertex,</span><br><span class="line">                        parallelismInfo,</span><br><span class="line">                        coordinatorStore,</span><br><span class="line">                        jobManagerJobMetricGroup);</span><br><span class="line"></span><br><span class="line">        <span class="type">ExecutionJobVertex</span> <span class="variable">previousTask</span> <span class="operator">=</span> <span class="built_in">this</span>.tasks.putIfAbsent(jobVertex.getID(), ejv);</span><br><span class="line">        <span class="keyword">if</span> (previousTask != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">JobException</span>(</span><br><span class="line">                    String.format(</span><br><span class="line">                            <span class="string">&quot;Encountered two job vertices with ID %s : previous=[%s] / new=[%s]&quot;</span>,</span><br><span class="line">                            jobVertex.getID(), ejv, previousTask));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.verticesInCreationOrder.add(ejv);</span><br><span class="line">        <span class="built_in">this</span>.numJobVerticesTotal++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>initializeJobVertices</strong></p><p>在 DefaultExecutionGraph.initializeJobVertices 中是遍历了刚刚排好序的 JobVertex，获取了 ExecutionJobVertex 之后调用了 ExecutionGraph.initializeJobVertex 方法。</p><p>我们直接来看 ExecutionGraph.initializeJobVertex 的逻辑。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title function_">initializeJobVertex</span><span class="params">(ExecutionJobVertex ejv, <span class="type">long</span> createTimestamp)</span></span><br><span class="line">        <span class="keyword">throws</span> JobException &#123;</span><br><span class="line">    initializeJobVertex(</span><br><span class="line">            ejv,</span><br><span class="line">            createTimestamp,</span><br><span class="line">            VertexInputInfoComputationUtils.computeVertexInputInfos(</span><br><span class="line">                    ejv, getAllIntermediateResults()::get));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里先是调用了 VertexInputInfoComputationUtils.computeVertexInputInfos 方法，生成了 Map&lt;IntermediateDataSetID, JobVertexInputInfo&gt; jobVertexInputInfos。它表示的是每个 ExecutionVertex 消费上游 IntermediateResultPartition 的范围。</p><p>这里有两种模式，分别是 POINTWISE （点对点）和 ALL_TO_ALL（全对全）</p><p>在 POINTWISE 模式中，会按照尽量均匀分布的方式处理。</p><ul><li><p>例如上游并发度是4，下游并发度是2时，那么前两个 IntermediateResultPartition 就会被第一个 ExecutionVertex 消费，后两个 IntermediateResultPartition 就会被第二个 ExecutionVertex 消费。</p></li><li><p>如果上游并发度是2，下游是3时，那么下游前两个 IntermediateResultPartition 会被第一个 ExecutionVertex 消费，第三个 IntermediateResultPartition 则会被第二个 ExecutionVertex 消费。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> JobVertexInputInfo <span class="title function_">computeVertexInputInfoForPointwise</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">int</span> sourceCount,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> targetCount,</span></span><br><span class="line"><span class="params">        Function&lt;Integer, Integer&gt; numOfSubpartitionsRetriever,</span></span><br><span class="line"><span class="params">        <span class="type">boolean</span> isDynamicGraph)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> List&lt;ExecutionVertexInputInfo&gt; executionVertexInputInfos = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (sourceCount &gt;= targetCount) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">index</span> <span class="operator">=</span> <span class="number">0</span>; index &lt; targetCount; index++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> index * sourceCount / targetCount;</span><br><span class="line">            <span class="type">int</span> <span class="variable">end</span> <span class="operator">=</span> (index + <span class="number">1</span>) * sourceCount / targetCount;</span><br><span class="line"></span><br><span class="line">            <span class="type">IndexRange</span> <span class="variable">partitionRange</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexRange</span>(start, end - <span class="number">1</span>);</span><br><span class="line">            <span class="type">IndexRange</span> <span class="variable">subpartitionRange</span> <span class="operator">=</span></span><br><span class="line">                    computeConsumedSubpartitionRange(</span><br><span class="line">                            index,</span><br><span class="line">                            <span class="number">1</span>,</span><br><span class="line">                            () -&gt; numOfSubpartitionsRetriever.apply(start),</span><br><span class="line">                            isDynamicGraph,</span><br><span class="line">                            <span class="literal">false</span>,</span><br><span class="line">                            <span class="literal">false</span>);</span><br><span class="line">            executionVertexInputInfos.add(</span><br><span class="line">                    <span class="keyword">new</span> <span class="title class_">ExecutionVertexInputInfo</span>(index, partitionRange, subpartitionRange));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">partitionNum</span> <span class="operator">=</span> <span class="number">0</span>; partitionNum &lt; sourceCount; partitionNum++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> <span class="variable">start</span> <span class="operator">=</span> (partitionNum * targetCount + sourceCount - <span class="number">1</span>) / sourceCount;</span><br><span class="line">            <span class="type">int</span> <span class="variable">end</span> <span class="operator">=</span> ((partitionNum + <span class="number">1</span>) * targetCount + sourceCount - <span class="number">1</span>) / sourceCount;</span><br><span class="line">            <span class="type">int</span> <span class="variable">numConsumers</span> <span class="operator">=</span> end - start;</span><br><span class="line"></span><br><span class="line">            <span class="type">IndexRange</span> <span class="variable">partitionRange</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexRange</span>(partitionNum, partitionNum);</span><br><span class="line">            <span class="comment">// Variable used in lambda expression should be final or effectively final</span></span><br><span class="line">            <span class="keyword">final</span> <span class="type">int</span> <span class="variable">finalPartitionNum</span> <span class="operator">=</span> partitionNum;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> start; i &lt; end; i++) &#123;</span><br><span class="line">                <span class="type">IndexRange</span> <span class="variable">subpartitionRange</span> <span class="operator">=</span></span><br><span class="line">                        computeConsumedSubpartitionRange(</span><br><span class="line">                                i,</span><br><span class="line">                                numConsumers,</span><br><span class="line">                                () -&gt; numOfSubpartitionsRetriever.apply(finalPartitionNum),</span><br><span class="line">                                isDynamicGraph,</span><br><span class="line">                                <span class="literal">false</span>,</span><br><span class="line">                                <span class="literal">false</span>);</span><br><span class="line">                executionVertexInputInfos.add(</span><br><span class="line">                        <span class="keyword">new</span> <span class="title class_">ExecutionVertexInputInfo</span>(i, partitionRange, subpartitionRange));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">JobVertexInputInfo</span>(executionVertexInputInfos);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 ALL_TO_ALL 模式中，每个下游都会消费所有上游的数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> JobVertexInputInfo <span class="title function_">computeVertexInputInfoForAllToAll</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">int</span> sourceCount,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> targetCount,</span></span><br><span class="line"><span class="params">        Function&lt;Integer, Integer&gt; numOfSubpartitionsRetriever,</span></span><br><span class="line"><span class="params">        <span class="type">boolean</span> isDynamicGraph,</span></span><br><span class="line"><span class="params">        <span class="type">boolean</span> isBroadcast,</span></span><br><span class="line"><span class="params">        <span class="type">boolean</span> isSingleSubpartitionContainsAllData)</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> List&lt;ExecutionVertexInputInfo&gt; executionVertexInputInfos = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    <span class="type">IndexRange</span> <span class="variable">partitionRange</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexRange</span>(<span class="number">0</span>, sourceCount - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; targetCount; ++i) &#123;</span><br><span class="line">        <span class="type">IndexRange</span> <span class="variable">subpartitionRange</span> <span class="operator">=</span></span><br><span class="line">                computeConsumedSubpartitionRange(</span><br><span class="line">                        i,</span><br><span class="line">                        targetCount,</span><br><span class="line">                        () -&gt; numOfSubpartitionsRetriever.apply(<span class="number">0</span>),</span><br><span class="line">                        isDynamicGraph,</span><br><span class="line">                        isBroadcast,</span><br><span class="line">                        isSingleSubpartitionContainsAllData);</span><br><span class="line">        executionVertexInputInfos.add(</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">ExecutionVertexInputInfo</span>(i, partitionRange, subpartitionRange));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">JobVertexInputInfo</span>(executionVertexInputInfos);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成好了 jobVertexInputInfos 之后，我们再回到 DefaultExecutionGraph.initializeJobVertex 方法中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initializeJobVertex</span><span class="params">(</span></span><br><span class="line"><span class="params">        ExecutionJobVertex ejv,</span></span><br><span class="line"><span class="params">        <span class="type">long</span> createTimestamp,</span></span><br><span class="line"><span class="params">        Map&lt;IntermediateDataSetID, JobVertexInputInfo&gt; jobVertexInputInfos)</span></span><br><span class="line">        <span class="keyword">throws</span> JobException &#123;</span><br><span class="line"></span><br><span class="line">    checkNotNull(ejv);</span><br><span class="line">    checkNotNull(jobVertexInputInfos);</span><br><span class="line"></span><br><span class="line">    jobVertexInputInfos.forEach(</span><br><span class="line">            (resultId, info) -&gt;</span><br><span class="line">                    <span class="built_in">this</span>.vertexInputInfoStore.put(ejv.getJobVertexId(), resultId, info));</span><br><span class="line"></span><br><span class="line">    ejv.initialize(</span><br><span class="line">            executionHistorySizeLimit,</span><br><span class="line">            rpcTimeout,</span><br><span class="line">            createTimestamp,</span><br><span class="line">            <span class="built_in">this</span>.initialAttemptCounts.getAttemptCounts(ejv.getJobVertexId()),</span><br><span class="line">            executionPlanSchedulingContext);</span><br><span class="line"></span><br><span class="line">    ejv.connectToPredecessors(<span class="built_in">this</span>.intermediateResults);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (IntermediateResult res : ejv.getProducedDataSets()) &#123;</span><br><span class="line">        <span class="type">IntermediateResult</span> <span class="variable">previousDataSet</span> <span class="operator">=</span></span><br><span class="line">                <span class="built_in">this</span>.intermediateResults.putIfAbsent(res.getId(), res);</span><br><span class="line">        <span class="keyword">if</span> (previousDataSet != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">JobException</span>(</span><br><span class="line">                    String.format(</span><br><span class="line">                            <span class="string">&quot;Encountered two intermediate data set with ID %s : previous=[%s] / new=[%s]&quot;</span>,</span><br><span class="line">                            res.getId(), res, previousDataSet));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    registerExecutionVerticesAndResultPartitionsFor(ejv);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// enrich network memory.</span></span><br><span class="line">    <span class="type">SlotSharingGroup</span> <span class="variable">slotSharingGroup</span> <span class="operator">=</span> ejv.getSlotSharingGroup();</span><br><span class="line">    <span class="keyword">if</span> (areJobVerticesAllInitialized(slotSharingGroup)) &#123;</span><br><span class="line">        SsgNetworkMemoryCalculationUtils.enrichNetworkMemory(</span><br><span class="line">                slotSharingGroup, <span class="built_in">this</span>::getJobVertex, shuffleMaster);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先来看 ExecutionJobVertex.initialize 方法。这个方法主要是生成 IntermediateResult 和 ExecutionVertex。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">initialize</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="type">int</span> executionHistorySizeLimit,</span></span><br><span class="line"><span class="params">        Duration timeout,</span></span><br><span class="line"><span class="params">        <span class="type">long</span> createTimestamp,</span></span><br><span class="line"><span class="params">        SubtaskAttemptNumberStore initialAttemptCounts,</span></span><br><span class="line"><span class="params">        ExecutionPlanSchedulingContext executionPlanSchedulingContext)</span></span><br><span class="line">        <span class="keyword">throws</span> JobException &#123;</span><br><span class="line"></span><br><span class="line">    checkState(parallelismInfo.getParallelism() &gt; <span class="number">0</span>);</span><br><span class="line">    checkState(!isInitialized());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.taskVertices = <span class="keyword">new</span> <span class="title class_">ExecutionVertex</span>[parallelismInfo.getParallelism()];</span><br><span class="line"></span><br><span class="line">    <span class="built_in">this</span>.inputs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(jobVertex.getInputs().size());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create the intermediate results</span></span><br><span class="line">    <span class="built_in">this</span>.producedDataSets =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">IntermediateResult</span>[jobVertex.getNumberOfProducedIntermediateDataSets()];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; jobVertex.getProducedDataSets().size(); i++) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="type">IntermediateDataSet</span> <span class="variable">result</span> <span class="operator">=</span> jobVertex.getProducedDataSets().get(i);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.producedDataSets[i] =</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">IntermediateResult</span>(</span><br><span class="line">                        result,</span><br><span class="line">                        <span class="built_in">this</span>,</span><br><span class="line">                        <span class="built_in">this</span>.parallelismInfo.getParallelism(),</span><br><span class="line">                        result.getResultType(),</span><br><span class="line">                        executionPlanSchedulingContext);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create all task vertices</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="built_in">this</span>.parallelismInfo.getParallelism(); i++) &#123;</span><br><span class="line">        <span class="type">ExecutionVertex</span> <span class="variable">vertex</span> <span class="operator">=</span></span><br><span class="line">                createExecutionVertex(</span><br><span class="line">                        <span class="built_in">this</span>,</span><br><span class="line">                        i,</span><br><span class="line">                        producedDataSets,</span><br><span class="line">                        timeout,</span><br><span class="line">                        createTimestamp,</span><br><span class="line">                        executionHistorySizeLimit,</span><br><span class="line">                        initialAttemptCounts.getAttemptCount(i));</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.taskVertices[i] = vertex;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sanity check for the double referencing between intermediate result partitions and</span></span><br><span class="line">    <span class="comment">// execution vertices</span></span><br><span class="line">    <span class="keyword">for</span> (IntermediateResult ir : <span class="built_in">this</span>.producedDataSets) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ir.getNumberOfAssignedPartitions() != <span class="built_in">this</span>.parallelismInfo.getParallelism()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(</span><br><span class="line">                    <span class="string">&quot;The intermediate result&#x27;s partitions were not correctly assigned.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// set up the input splits, if the vertex has any</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="meta">@SuppressWarnings(&quot;unchecked&quot;)</span></span><br><span class="line">        InputSplitSource&lt;InputSplit&gt; splitSource =</span><br><span class="line">                (InputSplitSource&lt;InputSplit&gt;) jobVertex.getInputSplitSource();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (splitSource != <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="type">Thread</span> <span class="variable">currentThread</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">            <span class="type">ClassLoader</span> <span class="variable">oldContextClassLoader</span> <span class="operator">=</span> currentThread.getContextClassLoader();</span><br><span class="line">            currentThread.setContextClassLoader(graph.getUserClassLoader());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                inputSplits =</span><br><span class="line">                        splitSource.createInputSplits(<span class="built_in">this</span>.parallelismInfo.getParallelism());</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (inputSplits != <span class="literal">null</span>) &#123;</span><br><span class="line">                    splitAssigner = splitSource.getInputSplitAssigner(inputSplits);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                currentThread.setContextClassLoader(oldContextClassLoader);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            inputSplits = <span class="literal">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">JobException</span>(</span><br><span class="line">                <span class="string">&quot;Creating the input splits caused an error: &quot;</span> + t.getMessage(), t);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在创建 ExecutionVertex 时，会创建 IntermediateResultPartition 和 Execution，创建 Execution 时，会设置 attemptNumber，这个值默认是0，如果 ExecutionVertex 是重新调度的，那么 attemptNumber 会自增加1。</p><p>ExecutionJobVertex.connectToPredecessors 方法主要是生成 ExecutionVertex 与 IntermediateResultPartition 的关联关系。这里设置关联关系也分成了点对点和全对全两种模式处理，点对点模式需要计算 ExecutionVertex 对应的 IntermediateResultPartition index 的范围。两种模式最终都调用了 connectInternal 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Connect all execution vertices to all partitions. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">connectInternal</span><span class="params">(</span></span><br><span class="line"><span class="params">        List&lt;ExecutionVertex&gt; taskVertices,</span></span><br><span class="line"><span class="params">        List&lt;IntermediateResultPartition&gt; partitions,</span></span><br><span class="line"><span class="params">        ResultPartitionType resultPartitionType,</span></span><br><span class="line"><span class="params">        EdgeManager edgeManager)</span> &#123;</span><br><span class="line">    checkState(!taskVertices.isEmpty());</span><br><span class="line">    checkState(!partitions.isEmpty());</span><br><span class="line"></span><br><span class="line">    <span class="type">ConsumedPartitionGroup</span> <span class="variable">consumedPartitionGroup</span> <span class="operator">=</span></span><br><span class="line">            createAndRegisterConsumedPartitionGroupToEdgeManager(</span><br><span class="line">                    taskVertices.size(), partitions, resultPartitionType, edgeManager);</span><br><span class="line">    <span class="keyword">for</span> (ExecutionVertex ev : taskVertices) &#123;</span><br><span class="line">        ev.addConsumedPartitionGroup(consumedPartitionGroup);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;ExecutionVertexID&gt; consumerVertices =</span><br><span class="line">            taskVertices.stream().map(ExecutionVertex::getID).collect(Collectors.toList());</span><br><span class="line">    <span class="type">ConsumerVertexGroup</span> <span class="variable">consumerVertexGroup</span> <span class="operator">=</span></span><br><span class="line">            ConsumerVertexGroup.fromMultipleVertices(consumerVertices, resultPartitionType);</span><br><span class="line">    <span class="keyword">for</span> (IntermediateResultPartition partition : partitions) &#123;</span><br><span class="line">        partition.addConsumers(consumerVertexGroup);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    consumedPartitionGroup.setConsumerVertexGroup(consumerVertexGroup);</span><br><span class="line">    consumerVertexGroup.setConsumedPartitionGroup(consumedPartitionGroup);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个方法中 ev.addConsumedPartitionGroup(consumedPartitionGroup); 负责将 ExecutionVertex 到 IntermediateResultPartition 的关联关系保存在 EdgeManager.vertexConsumedPartitions 中。</p><p>而 partition.addConsumers(consumerVertexGroup); 则负责将 IntermediateResultPartition 到 ExecutionVertex 的关系保存在 EdgeManager.partitionConsumers 中。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过本文，我们了解了 Flink 是如何将 JobGraph 转换成 ExecutionGraph 的。其中涉及到的一些核心概念名称比较类似，建议认真学习和理解透彻之后再研究其生成方法和对应关系，也可以借助前文中 ExecutionGraph 示意图辅助学习。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天我们一起来了解 Flink 最后一种执行图，ExecutionGraph 的执行过程。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：如何生成JobGraph</title>
    <link href="https://jackeyzhe.github.io/2025/09/18/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90JobGraph/"/>
    <id>https://jackeyzhe.github.io/2025/09/18/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90JobGraph/</id>
    <published>2025-09-18T14:02:40.000Z</published>
    <updated>2025-11-04T15:19:13.037Z</updated>
    
    <content type="html"><![CDATA[<p>前文我们介绍了 Flink 的四种执行图，并且通过源码了解了 Flink 的 StreamGraph 是怎么生成的，本文我们就一起来看下 Flink 的另一种执行图——JobGraph 是如何生成的。<span id="more"></span></p><h3 id="StreamGraph-和-JobGraph-的区别"><a href="#StreamGraph-和-JobGraph-的区别" class="headerlink" title="StreamGraph 和 JobGraph 的区别"></a>StreamGraph 和 JobGraph 的区别</h3><p>在正式开始之前，我们再来回顾一下 StreamGraph 和 JobGraph 的区别。假设我们的任务是建造一座大楼，StreamGraph 就像是设计蓝图，它描述了每个窗户、每根水管的位置和规格，而 JobGraph 像是给到施工队的施工流程图，它描述了每个任务模块，例如先把地基浇筑好，再铺设管线等。总的来说，JobGraph 更偏向执行层面，它是由 StreamGraph 优化而来。</p><p>回到 Flink 本身，我们通过一个表格来了解两个图的区别。</p><table><thead><tr><th></th><th>StreamGraph</th><th>JobGraph</th></tr></thead><tbody><tr><td>生成阶段</td><td>客户端，执行 execute() 时</td><td>客户端，提交前由 StreamGraph 转换生成</td></tr><tr><td>抽象层级</td><td>高层逻辑图，直接对应 API</td><td>优化后的执行图，为调度做准备</td></tr><tr><td>核心优化</td><td>无</td><td>主要是算子链优化</td></tr><tr><td>节点</td><td>StreamNode</td><td>JobVertex</td></tr><tr><td>边</td><td>StreamEdge</td><td>JobEdge</td></tr><tr><td>提交对象</td><td>无</td><td>提交给 JobManager</td></tr><tr><td>包含资源</td><td>无</td><td>包含执行作业所需的 Jar 包、依赖库和资源文件</td></tr></tbody></table><h3 id="JobVertex"><a href="#JobVertex" class="headerlink" title="JobVertex"></a>JobVertex</h3><p>JobGraph 中的节点是 JobVertex，在 StreamGraph 转换成 JobGraph 的过程中，会将多个节点串联起来，最终生成 JobVertex。</p><p>JobVertex包含以下成员变量：</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1758469798/Blog/flink/9/JobVertex.png" alt="JobVertex"></p><p>我们分别看一下这些成员变量及其作用。</p><h4 id="1、标识符相关"><a href="#1、标识符相关" class="headerlink" title="1、标识符相关"></a>1、标识符相关</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// JobVertex的id，在作业执行过程中的唯一标识。监控、调度和故障恢复都会使用</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> JobVertexID id;</span><br><span class="line"></span><br><span class="line"><span class="comment">// operator id列表，按照深度优先顺序存储。operator 的管理、状态分配都会用到</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;OperatorIDPair&gt; operatorIDs;</span><br></pre></td></tr></table></figure><h4 id="2、输入输出相关"><a href="#2、输入输出相关" class="headerlink" title="2、输入输出相关"></a>2、输入输出相关</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义所有的输入边</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;JobEdge&gt; inputs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义所有的输出数据集</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;IntermediateDataSetID, IntermediateDataSet&gt; results = <span class="keyword">new</span> <span class="title class_">LinkedHashMap</span>&lt;&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输入分片源，主要用于批处理作业，定义如何将数据分成多个片</span></span><br><span class="line"><span class="keyword">private</span> InputSplitSource&lt;?&gt; inputSplitSource;</span><br></pre></td></tr></table></figure><h4 id="3、执行配置相关"><a href="#3、执行配置相关" class="headerlink" title="3、执行配置相关"></a>3、执行配置相关</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 并行度，即运行时拆分子任务数量，默认使用全局配置</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="variable">parallelism</span> <span class="operator">=</span> ExecutionConfig.PARALLELISM_DEFAULT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 最大并行度</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">int</span> <span class="variable">maxParallelism</span> <span class="operator">=</span> MAX_PARALLELISM_DEFAULT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 存储运行时实际执行的类，使 Flink 可以灵活处理不同类型的操作符</span></span><br><span class="line"><span class="comment">// 流任务可以是&quot;org.apache.flink.streaming.runtime.tasks.StreamTask&quot;</span></span><br><span class="line"><span class="comment">// 批任务可以是&quot;org.apache.flink.runtime.operators.BatchTask&quot;</span></span><br><span class="line"><span class="keyword">private</span> String invokableClassName;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 自定义配置</span></span><br><span class="line"><span class="keyword">private</span> Configuration configuration;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否是动态设置并发度</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">dynamicParallelism</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否支持优雅停止</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">isStoppable</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><h4 id="4、资源管理相关"><a href="#4、资源管理相关" class="headerlink" title="4、资源管理相关"></a>4、资源管理相关</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// JobVertex 最小资源需求</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">ResourceSpec</span> <span class="variable">minResources</span> <span class="operator">=</span> ResourceSpec.DEFAULT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// JobVertex 推荐资源需求</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">ResourceSpec</span> <span class="variable">preferredResources</span> <span class="operator">=</span> ResourceSpec.DEFAULT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 用于资源优化，运行不同的 JobVertex 的子任务运行在同一个 slot</span></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> SlotSharingGroup slotSharingGroup;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要严格共址的 JobVertex 组，每个 JobVertex 的第 n 个子任务运行在同一个 TaskManager</span></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> CoLocationGroupImpl coLocationGroup;</span><br></pre></td></tr></table></figure><h4 id="5、协调器"><a href="#5、协调器" class="headerlink" title="5、协调器"></a>5、协调器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 操作符协调器，用于处理全局协调逻辑</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;SerializedValue&lt;OperatorCoordinator.Provider&gt;&gt; operatorCoordinators =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br></pre></td></tr></table></figure><h4 id="6、显示和描述信息"><a href="#6、显示和描述信息" class="headerlink" title="6、显示和描述信息"></a>6、显示和描述信息</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// JobVertex 的名称</span></span><br><span class="line"><span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 操作符名称，比如 &#x27;Flat Map&#x27; 或 &#x27;Join&#x27;</span></span><br><span class="line"><span class="keyword">private</span> String operatorName;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 操作符的描述，比如 &#x27;Hash Join&#x27; 或 &#x27;Sorted Group Reduce&#x27;</span></span><br><span class="line"><span class="keyword">private</span> String operatorDescription;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 提供比 name 更友好的描述信息</span></span><br><span class="line"><span class="keyword">private</span> String operatorPrettyName;</span><br></pre></td></tr></table></figure><h4 id="7、状态和行为标志"><a href="#7、状态和行为标志" class="headerlink" title="7、状态和行为标志"></a>7、状态和行为标志</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 是否支持同一个子任务并发多次执行</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">supportsConcurrentExecutionAttempts</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 标记并发度是否被显式设置</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">parallelismConfigured</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否有阻塞型输出</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="variable">anyOutputBlocking</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><h4 id="8、缓存数据集"><a href="#8、缓存数据集" class="headerlink" title="8、缓存数据集"></a>8、缓存数据集</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 存储该 JobVertex 需要消费的缓存中间数据集的 ID，可提高作业执行效率</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;IntermediateDataSetID&gt; intermediateDataSetIdsToConsume = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br></pre></td></tr></table></figure><h3 id="JobEdge"><a href="#JobEdge" class="headerlink" title="JobEdge"></a>JobEdge</h3><p>在 StreamGraph 中，StreamEdge 是连接 StreamNode 的桥梁。在 JobGraph 中，与之对应的是 JobEdge，不同点在于  JobEdge 中保存的是输入节点和输出结果。</p><h4 id="1、连接关系成员"><a href="#1、连接关系成员" class="headerlink" title="1、连接关系成员"></a>1、连接关系成员</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义数据流向哪个 JobVertex</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> JobVertex target;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义这条边的源数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> IntermediateDataSet source;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输入类型的编号</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> typeNumber;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多个输入间的键是否相关，如果为 true，相同键的数据在一个输入被分割时，在其他数据对应的记录也会发送到相同的下游节点</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">boolean</span> interInputsKeysCorrelated;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 同一输入内相同的键是否必须发送到同一下游任务</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">boolean</span> intraInputKeyCorrelated;</span><br></pre></td></tr></table></figure><h4 id="2、数据分发模式"><a href="#2、数据分发模式" class="headerlink" title="2、数据分发模式"></a>2、数据分发模式</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义数据在并行任务期间的分发模式</span></span><br><span class="line"><span class="comment">// 可能值：</span></span><br><span class="line"><span class="comment">// ALL_TO_ALL：全连接，每个上游子任务连接所有下游任务</span></span><br><span class="line"><span class="comment">// POINTWISE：点对点连接，一对一或一对多的本地连接</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> DistributionPattern distributionPattern;</span><br></pre></td></tr></table></figure><h4 id="3、数据传输策略"><a href="#3、数据传输策略" class="headerlink" title="3、数据传输策略"></a>3、数据传输策略</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 是否为广播连接</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">boolean</span> isBroadcast;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 是否为 forward 连接，forward 连接最高效，直接转发，无需序列化网络传输</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="type">boolean</span> isForward;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数据传输策略名称，用于显示</span></span><br><span class="line"><span class="keyword">private</span> String shipStrategyName;</span><br></pre></td></tr></table></figure><h4 id="4、状态重分布映射器"><a href="#4、状态重分布映射器" class="headerlink" title="4、状态重分布映射器"></a>4、状态重分布映射器</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下游状态重分布映射器，当作业扩容时，决定是否重新分配下游算子的持久化状态</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">SubtaskStateMapper</span> <span class="variable">downstreamSubtaskStateMapper</span> <span class="operator">=</span> SubtaskStateMapper.ROUND_ROBIN;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 上游状态重分布映射器，当作业扩容时，决定是否重新分配上游算子的持久化状态</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">SubtaskStateMapper</span> <span class="variable">upstreamSubtaskStateMapper</span> <span class="operator">=</span> SubtaskStateMapper.ROUND_ROBIN;</span><br></pre></td></tr></table></figure><h4 id="5、描述和缓存信息"><a href="#5、描述和缓存信息" class="headerlink" title="5、描述和缓存信息"></a>5、描述和缓存信息</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 预处理操作的名称</span></span><br><span class="line"><span class="keyword">private</span> String preProcessingOperationName;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 操作符级别缓存的描述</span></span><br><span class="line"><span class="keyword">private</span> String operatorLevelCachingDescription;</span><br></pre></td></tr></table></figure><h3 id="StreamGraph-转换成-JobGraph"><a href="#StreamGraph-转换成-JobGraph" class="headerlink" title="StreamGraph 转换成 JobGraph"></a>StreamGraph 转换成 JobGraph</h3><p>现在我们再来看一下 StreamGraph 是如何转换成 JobGraph 的。转换逻辑的入口是 StreamGraph.getJobGraph 方法。它只是调用了 StreamingJobGraphGenerator.createJobGraph，核心逻辑在 createJobGraph 方法中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> JobGraph <span class="title function_">createJobGraph</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 预验证，检查 StreamGraph 配置正确性</span></span><br><span class="line">    preValidate(streamGraph, userClassloader);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 【核心】链化操作符</span></span><br><span class="line">    setChaining();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (jobGraph.isDynamic()) &#123;</span><br><span class="line">        <span class="comment">// 支持动态扩缩容场景，为动态图设置并行度</span></span><br><span class="line">        setVertexParallelismsForDynamicGraphIfNecessary();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Note that we set all the non-chainable outputs configuration here because the</span></span><br><span class="line">    <span class="comment">// &quot;setVertexParallelismsForDynamicGraphIfNecessary&quot; may affect the parallelism of job</span></span><br><span class="line">    <span class="comment">// vertices and partition-reuse</span></span><br><span class="line">    <span class="keyword">final</span> Map&lt;Integer, Map&lt;StreamEdge, NonChainedOutput&gt;&gt; opIntermediateOutputs =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    <span class="comment">// 设置不能链化的输出边</span></span><br><span class="line">    setAllOperatorNonChainedOutputsConfigs(opIntermediateOutputs, jobVertexBuildContext);</span><br><span class="line">    setAllVertexNonChainedOutputsConfigs(opIntermediateOutputs);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置物理边连接</span></span><br><span class="line">    setPhysicalEdges(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置支持并发执行的 JobVertex</span></span><br><span class="line">    markSupportingConcurrentExecutionAttempts(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证混合 shuffle 模式只在批处理模式下使用</span></span><br><span class="line">    validateHybridShuffleExecuteInBatchMode(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置 Slot 共享和协同定位</span></span><br><span class="line">    setSlotSharingAndCoLocation(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置托管内存比例</span></span><br><span class="line">    setManagedMemoryFraction(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 为 JobVertex 名称添加前缀</span></span><br><span class="line">    addVertexIndexPrefixInVertexName(jobVertexBuildContext, <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 设置操作符描述信息</span></span><br><span class="line">    setVertexDescription(jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Wait for the serialization of operator coordinators and stream config.</span></span><br><span class="line">    <span class="comment">// 序列化操作符协调器和流配置</span></span><br><span class="line">    serializeOperatorCoordinatorsAndStreamConfig(serializationExecutor, jobVertexBuildContext);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> jobGraph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，在 createJobGraph 方法中，调用了 setChaining 方法，即进行链化操作。这也是 JobGraph 最核心的优化之一。下面我们来看一下具体怎么做链化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">setChaining</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// we separate out the sources that run as inputs to another operator (chained inputs)</span></span><br><span class="line">    <span class="comment">// from the sources that needs to run as the main (head) operator.</span></span><br><span class="line">    <span class="keyword">final</span> Map&lt;Integer, OperatorChainInfo&gt; chainEntryPoints =</span><br><span class="line">            buildChainedInputsAndGetHeadInputs();</span><br><span class="line">    <span class="keyword">final</span> Collection&lt;OperatorChainInfo&gt; initialEntryPoints =</span><br><span class="line">            chainEntryPoints.entrySet().stream()</span><br><span class="line">                    .sorted(Comparator.comparing(Map.Entry::getKey))</span><br><span class="line">                    .map(Map.Entry::getValue)</span><br><span class="line">                    .collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// iterate over a copy of the values, because this map gets concurrently modified</span></span><br><span class="line">    <span class="keyword">for</span> (OperatorChainInfo info : initialEntryPoints) &#123;</span><br><span class="line">        createChain(</span><br><span class="line">                info.getStartNodeId(),</span><br><span class="line">                <span class="number">1</span>, <span class="comment">// operators start at position 1 because 0 is for chained source inputs</span></span><br><span class="line">                info,</span><br><span class="line">                chainEntryPoints,</span><br><span class="line">                <span class="literal">true</span>,</span><br><span class="line">                serializationExecutor,</span><br><span class="line">                jobVertexBuildContext,</span><br><span class="line">                <span class="literal">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>setChaining 方法中主要分为两步，第一步是处理 Source 节点，将可以链化的 Source 和不能链化的 Source 节点分开。先来看如何判断一个 Source 是否可被链化。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isChainableSource</span><span class="params">(StreamNode streamNode, StreamGraph streamGraph)</span> &#123;</span><br><span class="line">    <span class="comment">// 最基本的一些判空，输出边数量为1</span></span><br><span class="line">    <span class="keyword">if</span> (streamNode.getOperatorFactory() == <span class="literal">null</span></span><br><span class="line">            || !(streamNode.getOperatorFactory() <span class="keyword">instanceof</span> SourceOperatorFactory)</span><br><span class="line">            || streamNode.getOutEdges().size() != <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">StreamEdge</span> <span class="variable">sourceOutEdge</span> <span class="operator">=</span> streamNode.getOutEdges().get(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">final</span> <span class="type">StreamNode</span> <span class="variable">target</span> <span class="operator">=</span> streamGraph.getStreamNode(sourceOutEdge.getTargetId());</span><br><span class="line">    <span class="keyword">final</span> <span class="type">ChainingStrategy</span> <span class="variable">targetChainingStrategy</span> <span class="operator">=</span></span><br><span class="line">            Preconditions.checkNotNull(target.getOperatorFactory()).getChainingStrategy();</span><br><span class="line">    <span class="comment">// 链化策略必须 HEAD_WITH_SOURCES，输出边是可链化的</span></span><br><span class="line">    <span class="keyword">return</span> targetChainingStrategy == ChainingStrategy.HEAD_WITH_SOURCES</span><br><span class="line">            &amp;&amp; isChainableInput(sourceOutEdge, streamGraph, <span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isChainableInput</span><span class="params">(</span></span><br><span class="line"><span class="params">        StreamEdge edge, StreamGraph streamGraph, <span class="type">boolean</span> allowChainWithDefaultParallelism)</span> &#123;</span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">upStreamVertex</span> <span class="operator">=</span> streamGraph.getSourceVertex(edge);</span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">downStreamVertex</span> <span class="operator">=</span> streamGraph.getTargetVertex(edge);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!(streamGraph.isChainingEnabled()</span><br><span class="line">            <span class="comment">// 上下游节点是否在同一个 slot 共享组</span></span><br><span class="line">            &amp;&amp; upStreamVertex.isSameSlotSharingGroup(downStreamVertex)</span><br><span class="line">            <span class="comment">// 操作符是否可以链化，主要做并行度检查</span></span><br><span class="line">            &amp;&amp; areOperatorsChainable(</span><br><span class="line">                    upStreamVertex,</span><br><span class="line">                    downStreamVertex,</span><br><span class="line">                    streamGraph,</span><br><span class="line">                    allowChainWithDefaultParallelism)</span><br><span class="line">            <span class="comment">// 分区器和交换模式是否支持链化</span></span><br><span class="line">            &amp;&amp; arePartitionerAndExchangeModeChainable(</span><br><span class="line">                    edge.getPartitioner(), edge.getExchangeMode(), streamGraph.isDynamic()))) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// check that we do not have a union operation, because unions currently only work</span></span><br><span class="line">    <span class="comment">// through the network/byte-channel stack.</span></span><br><span class="line">    <span class="comment">// we check that by testing that each &quot;type&quot; (which means input position) is used only once</span></span><br><span class="line">    <span class="comment">// 检查是否为 Union 操作，Union 操作不能链化</span></span><br><span class="line">    <span class="keyword">for</span> (StreamEdge inEdge : downStreamVertex.getInEdges()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (inEdge != edge &amp;&amp; inEdge.getTypeNumber() == edge.getTypeNumber()) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Source 的链化条件主要就是这些，我们结合一些例子来看一下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">Source(并行度=4) -&gt; Map(并行度=4) -&gt; Filter(并行度=4)</span><br><span class="line"></span><br><span class="line">Source -&gt; Map 边：</span><br><span class="line">1. isChainingEnabled() = true</span><br><span class="line">2. isSameSlotSharingGroup() = true (都在默认组)</span><br><span class="line">3. areOperatorsChainable() = true (Source可链化，Map是HEAD_WITH_SOURCES)</span><br><span class="line">4. arePartitionerAndExchangeModeChainable() = true (ForwardPartitioner)</span><br><span class="line">5. Union检查通过</span><br><span class="line">结果：可链化</span><br><span class="line"></span><br><span class="line">Map -&gt; Filter 边：</span><br><span class="line">1. isChainingEnabled() = true</span><br><span class="line">2. isSameSlotSharingGroup() = true</span><br><span class="line">3. areOperatorsChainable() = true (Map和Filter都是ALWAYS)</span><br><span class="line">4. arePartitionerAndExchangeModeChainable() = true (ForwardPartitioner)</span><br><span class="line">5. Union检查通过</span><br><span class="line">结果：可链化</span><br><span class="line"></span><br><span class="line">最终：Source -&gt; Map -&gt; Filter 三者链化到一个JobVertex中</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Source(并行度=2) -&gt; Map(并行度=4)  // 并行度不匹配</span><br><span class="line"></span><br><span class="line">Source -&gt; Map 边：</span><br><span class="line">1. isChainingEnabled() = true</span><br><span class="line">2. isSameSlotSharingGroup() = true</span><br><span class="line">3. areOperatorsChainable() = false (并行度不匹配)</span><br><span class="line">结果：不可链化，需要网络传输</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Source1 --\</span><br><span class="line">          Union -&gt; Map</span><br><span class="line">Source2 --/</span><br><span class="line"></span><br><span class="line">Source1 -&gt; Union 边：</span><br><span class="line">虽然满足前4个条件，但Union节点有两个输入边，typeNumber相同</span><br><span class="line">Union检查失败，不可链化</span><br></pre></td></tr></table></figure><p>得到了所有入口之后，就可以进行后续节点的链化操作了，它的逻辑在 createChain 方法中。这里主要是一个递归过程，先将节点的输出边分为可链化和不可链化两个 list，之后对可链化的边进行递归调用链化。对不可链化的边，需要创建出新的链。由于篇幅原因，这里只贴一部分核心的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;StreamEdge&gt; <span class="title function_">createChain</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> Integer currentNodeId,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> <span class="type">int</span> chainIndex,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> OperatorChainInfo chainInfo,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> Map&lt;Integer, OperatorChainInfo&gt; chainEntryPoints,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> <span class="type">boolean</span> canCreateNewChain,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> Executor serializationExecutor,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> JobVertexBuildContext jobVertexBuildContext,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> <span class="meta">@Nullable</span> Consumer&lt;Integer&gt; visitedStreamNodeConsumer)</span> &#123;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 拆分可链化边和不可链化边</span></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge outEdge : currentNode.getOutEdges()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (isChainable(outEdge, streamGraph)) &#123;</span><br><span class="line">                chainableOutputs.add(outEdge);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                nonChainableOutputs.add(outEdge);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 处理可链化边</span></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge chainable : chainableOutputs) &#123;</span><br><span class="line">            <span class="type">StreamNode</span> <span class="variable">targetNode</span> <span class="operator">=</span> streamGraph.getStreamNode(chainable.getTargetId());</span><br><span class="line">            <span class="type">Attribute</span> <span class="variable">targetNodeAttribute</span> <span class="operator">=</span> targetNode.getAttribute();</span><br><span class="line">            <span class="keyword">if</span> (isNoOutputUntilEndOfInput) &#123;</span><br><span class="line">                <span class="keyword">if</span> (targetNodeAttribute != <span class="literal">null</span>) &#123;</span><br><span class="line">                    targetNodeAttribute.setNoOutputUntilEndOfInput(<span class="literal">true</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            transitiveOutEdges.addAll(</span><br><span class="line">                    createChain(</span><br><span class="line">                            chainable.getTargetId(),</span><br><span class="line">                            chainIndex + <span class="number">1</span>,</span><br><span class="line">                            chainInfo,</span><br><span class="line">                            chainEntryPoints,</span><br><span class="line">                            canCreateNewChain,</span><br><span class="line">                            serializationExecutor,</span><br><span class="line">                            jobVertexBuildContext,</span><br><span class="line">                            visitedStreamNodeConsumer));</span><br><span class="line">            <span class="comment">// Mark upstream nodes in the same chain as outputBlocking</span></span><br><span class="line">            <span class="keyword">if</span> (targetNodeAttribute != <span class="literal">null</span></span><br><span class="line">                    &amp;&amp; targetNodeAttribute.isNoOutputUntilEndOfInput()) &#123;</span><br><span class="line">                currentNodeAttribute.setNoOutputUntilEndOfInput(<span class="literal">true</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 处理不可链化边</span></span><br><span class="line">        <span class="keyword">for</span> (StreamEdge nonChainable : nonChainableOutputs) &#123;</span><br><span class="line">            transitiveOutEdges.add(nonChainable);</span><br><span class="line">            <span class="comment">// Used to control whether a new chain can be created, this value is true in the</span></span><br><span class="line">            <span class="comment">// full graph generation algorithm and false in the progressive generation</span></span><br><span class="line">            <span class="comment">// algorithm. In the future, this variable can be a boolean type function to adapt</span></span><br><span class="line">            <span class="comment">// to more adaptive scenarios.</span></span><br><span class="line">            <span class="keyword">if</span> (canCreateNewChain) &#123;</span><br><span class="line">                createChain(</span><br><span class="line">                        nonChainable.getTargetId(),</span><br><span class="line">                        <span class="number">1</span>, <span class="comment">// operators start at position 1 because 0 is for chained source</span></span><br><span class="line">                        <span class="comment">// inputs</span></span><br><span class="line">                        chainEntryPoints.computeIfAbsent(</span><br><span class="line">                                nonChainable.getTargetId(),</span><br><span class="line">                                (k) -&gt; chainInfo.newChain(nonChainable.getTargetId())),</span><br><span class="line">                        chainEntryPoints,</span><br><span class="line">                        canCreateNewChain,</span><br><span class="line">                        serializationExecutor,</span><br><span class="line">                        jobVertexBuildContext,</span><br><span class="line">                        visitedStreamNodeConsumer);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 JobVertex</span></span><br><span class="line">        StreamConfig config;</span><br><span class="line">        <span class="keyword">if</span> (currentNodeId.equals(startNodeId)) &#123;</span><br><span class="line">            <span class="type">JobVertex</span> <span class="variable">jobVertex</span> <span class="operator">=</span> jobVertexBuildContext.getJobVertex(startNodeId);</span><br><span class="line">            <span class="keyword">if</span> (jobVertex == <span class="literal">null</span>) &#123;</span><br><span class="line">                jobVertex =</span><br><span class="line">                        createJobVertex(</span><br><span class="line">                                chainInfo, serializationExecutor, jobVertexBuildContext);</span><br><span class="line">            &#125;</span><br><span class="line">            config = <span class="keyword">new</span> <span class="title class_">StreamConfig</span>(jobVertex.getConfiguration());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            config = <span class="keyword">new</span> <span class="title class_">StreamConfig</span>(<span class="keyword">new</span> <span class="title class_">Configuration</span>());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 判断是否为起始节点，如果不是，将对应的配置信息存到链化起始节点的 key 中</span></span><br><span class="line">        <span class="keyword">if</span> (currentNodeId.equals(startNodeId)) &#123;</span><br><span class="line">            chainInfo.setTransitiveOutEdges(transitiveOutEdges);</span><br><span class="line">            jobVertexBuildContext.addChainInfo(startNodeId, chainInfo);</span><br><span class="line"></span><br><span class="line">            config.setChainStart();</span><br><span class="line">            config.setChainIndex(chainIndex);</span><br><span class="line">            config.setOperatorName(streamGraph.getStreamNode(currentNodeId).getOperatorName());</span><br><span class="line">            config.setTransitiveChainedTaskConfigs(</span><br><span class="line">                    jobVertexBuildContext.getChainedConfigs().get(startNodeId));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            config.setChainIndex(chainIndex);</span><br><span class="line">            <span class="type">StreamNode</span> <span class="variable">node</span> <span class="operator">=</span> streamGraph.getStreamNode(currentNodeId);</span><br><span class="line">            config.setOperatorName(node.getOperatorName());</span><br><span class="line">            jobVertexBuildContext</span><br><span class="line">                    .getOrCreateChainedConfig(startNodeId)</span><br><span class="line">                    .put(currentNodeId, config);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>是否可链化依赖于 isChainable 方法的结果。它主要判断了下游的输入边数量是否为1，然后调用了 isChainableInput，这个方法我们刚刚已经看过了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isChainable</span><span class="params">(StreamEdge edge, StreamGraph streamGraph)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> isChainable(edge, streamGraph, <span class="literal">false</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">isChainable</span><span class="params">(</span></span><br><span class="line"><span class="params">        StreamEdge edge, StreamGraph streamGraph, <span class="type">boolean</span> allowChainWithDefaultParallelism)</span> &#123;</span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">downStreamVertex</span> <span class="operator">=</span> streamGraph.getTargetVertex(edge);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> downStreamVertex.getInEdges().size() == <span class="number">1</span></span><br><span class="line">            &amp;&amp; isChainableInput(edge, streamGraph, allowChainWithDefaultParallelism);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们主要介绍了生成 JobGraph 的相关代码。首先了解了 JobGraph 中的节点和边对应的类，以及它们和 StreamGraph 中的类的映射关系。然后又看了生成 JobGraph 的核心代码，其中重点学习了链化相关的代码。</p><p>最后补充一个生成 JobGraph 的调用链路，感兴趣的同学可以看下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clusterClient.submitJob() → MiniCluster.submitJob() → Dispatcher.submitJob() → JobMasterServiceLeadershipRunnerFactory → DefaultJobMasterServiceFactory → JobMaster → DefaultSchedulerFactory.createInstance()→ StreamGraph.getJobGraph()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;前文我们介绍了 Flink 的四种执行图，并且通过源码了解了 Flink 的 StreamGraph 是怎么生成的，本文我们就一起来看下 Flink 的另一种执行图——JobGraph 是如何生成的。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink源码阅读：如何生成StreamGraph</title>
    <link href="https://jackeyzhe.github.io/2025/09/10/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90StreamGraph/"/>
    <id>https://jackeyzhe.github.io/2025/09/10/Flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%EF%BC%9A%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90StreamGraph/</id>
    <published>2025-09-10T13:55:59.000Z</published>
    <updated>2025-09-16T16:50:56.288Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 中有四种执行图，分别是 StreamGraph、JobGraph、ExecutionGraph 和 Physical Graph。今天我们来看下我们编写的 Flink 程序代码是如何生成 StreamGraph 的。<span id="more"></span></p><p>在开始读代码之前，我们先来简单介绍一下四种图之间的关系和区别。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1757598202/Blog/flink/8/flink_graph.png" alt="flink_graph"></p><p>StreamGraph 是根据用户用 Stream API 编写的代码生成的图，用来表示整个程序的拓扑结构。</p><p>JobGraph 是由 StreamGraph 生成的，它在 StreamGraph 的基础上，对链化了部分算子，将其合并成为一个节点，减少数据在节点之间传输时序列化和反序列化这些消耗。</p><p>ExecutionGraph 是由 JobGraph 生成的，它的主要特点是并行，将多并发的节点拆分。</p><p>PhysicalGraph 是 ExecutionGraph 实际部署后的图，它并不是一种数据结构。</p><h3 id="StreamExecutionEnvironment"><a href="#StreamExecutionEnvironment" class="headerlink" title="StreamExecutionEnvironment"></a>StreamExecutionEnvironment</h3><p>OK，了解了 Flink 四种执行图之后，我们就正式开始源码探索了。首先从 StreamExecutionEnvironment 入手，在编写 Flink 程序时，它是必不可少的一个类。它提供了一系列方法来配置流处理程序的执行环境（如并行度、Checkpoint 配置、时间属性等）。</p><p>本文我们主要关注 StreamGraph 的生成，首先是数据流的入口，即 Source 节点。在 StreamExecutionEnvironment 中有 addSource 和 fromSource 等方法，它们用来定义从哪个数据源读取数据，然后返回一个 DataStreamSource （继承自 DataStream），得到 DataStream 之后，它会在各个算子之间流转，最终到 Sink 端输出。</p><p>我们从 addSource 方法入手，addSource 方法中主要做了三件事：</p><p>1、处理数据类型，优先使用用户执行的数据类型，也可以自动推断</p><p>2、闭包清理，使用户传入的 function 能被序列化并发布到分布式环境执行</p><p>3、创建 DataStreamSource 并返回</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;OUT&gt; DataStreamSource&lt;OUT&gt; <span class="title function_">addSource</span><span class="params">(</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> SourceFunction&lt;OUT&gt; function,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> String sourceName,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nullable</span> <span class="keyword">final</span> TypeInformation&lt;OUT&gt; typeInfo,</span></span><br><span class="line"><span class="params">        <span class="keyword">final</span> Boundedness boundedness)</span> &#123;</span><br><span class="line">    checkNotNull(function);</span><br><span class="line">    checkNotNull(sourceName);</span><br><span class="line">    checkNotNull(boundedness);</span><br><span class="line"></span><br><span class="line">    TypeInformation&lt;OUT&gt; resolvedTypeInfo =</span><br><span class="line">            getTypeInfo(function, sourceName, SourceFunction.class, typeInfo);</span><br><span class="line"></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">isParallel</span> <span class="operator">=</span> function <span class="keyword">instanceof</span> ParallelSourceFunction;</span><br><span class="line"></span><br><span class="line">    clean(function);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> StreamSource&lt;OUT, ?&gt; sourceOperator = <span class="keyword">new</span> <span class="title class_">StreamSource</span>&lt;&gt;(function);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DataStreamSource</span>&lt;&gt;(</span><br><span class="line">            <span class="built_in">this</span>, resolvedTypeInfo, sourceOperator, isParallel, sourceName, boundedness);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在我们有了 DataStream 了，那如何知道后续要进行哪些转换逻辑呢？答案在 transformations 这个变量中，它保存了后续所有的转换。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> List&lt;Transformation&lt;?&gt;&gt; transformations = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br></pre></td></tr></table></figure><h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><p>我们来看 Transformation 是如何生成和描述 DataStream 的转换流程的。以最常见的 map 方法为例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; <span class="title function_">map</span><span class="params">(</span></span><br><span class="line"><span class="params">        MapFunction&lt;T, R&gt; mapper, TypeInformation&lt;R&gt; outputType)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> transform(<span class="string">&quot;Map&quot;</span>, outputType, <span class="keyword">new</span> <span class="title class_">StreamMap</span>&lt;&gt;(clean(mapper)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它调用了 transform 方法，transform 又调用了 doTransform 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> &lt;R&gt; SingleOutputStreamOperator&lt;R&gt; <span class="title function_">doTransform</span><span class="params">(</span></span><br><span class="line"><span class="params">        String operatorName,</span></span><br><span class="line"><span class="params">        TypeInformation&lt;R&gt; outTypeInfo,</span></span><br><span class="line"><span class="params">        StreamOperatorFactory&lt;R&gt; operatorFactory)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// read the output type of the input Transform to coax out errors about MissingTypeInfo</span></span><br><span class="line">    transformation.getOutputType();</span><br><span class="line"></span><br><span class="line">    OneInputTransformation&lt;T, R&gt; resultTransform =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">OneInputTransformation</span>&lt;&gt;(</span><br><span class="line">                    <span class="built_in">this</span>.transformation,</span><br><span class="line">                    operatorName,</span><br><span class="line">                    operatorFactory,</span><br><span class="line">                    outTypeInfo,</span><br><span class="line">                    environment.getParallelism(),</span><br><span class="line">                    <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;rawtypes&quot;&#125;)</span></span><br><span class="line">    SingleOutputStreamOperator&lt;R&gt; returnStream =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">SingleOutputStreamOperator</span>(environment, resultTransform);</span><br><span class="line"></span><br><span class="line">    getExecutionEnvironment().addOperator(resultTransform);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> returnStream;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 doTransform 方法中，就是创建 Transformation 和 SingleOutputStreamOperator（DataStream 的一个子类），然后调用 addOperator 方法将 transform 存到 StreamExecutionEnviroment 中的 transformations 变量中。</p><p>每个 Transformation 都有 id、name、parallelism 和 slotSharingGroup 等信息。其子类也记录有输入信息，如 OneInputTransformation 和 TwoInputTransformation。</p><h3 id="StreamOperator"><a href="#StreamOperator" class="headerlink" title="StreamOperator"></a>StreamOperator</h3><p>我们在调用 map 方法时，会传入一个自定义的处理函数，它也会保存在 Transformation 中。在 Flink 中定义了 StreamOperator 方法来抽象这类处理函数。在 map 方法中，它将我们传入的函数转成了 StreamMap，它继承了 AbstractUdfStreamOperator，同时实现了 OneInputStreamOperator 接口。</p><p>StreamOperator 定义了对算子生命周期管理的函数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span> <span class="title function_">open</span><span class="params">()</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">finish</span><span class="params">()</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">OperatorSnapshotFutures <span class="title function_">snapshotState</span><span class="params">(</span></span><br><span class="line"><span class="params">            <span class="type">long</span> checkpointId,</span></span><br><span class="line"><span class="params">            <span class="type">long</span> timestamp,</span></span><br><span class="line"><span class="params">            CheckpointOptions checkpointOptions,</span></span><br><span class="line"><span class="params">            CheckpointStreamFactory storageLocation)</span></span><br><span class="line">            <span class="keyword">throws</span> Exception;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">initializeState</span><span class="params">(StreamTaskStateInitializer streamTaskStateManager)</span> <span class="keyword">throws</span> Exception;</span><br></pre></td></tr></table></figure><p>OneInputStreamOperator 是 StreamOperator 的子接口。在其基础上增加了对具体元素的处理，主要是对 key 的提取。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title function_">setKeyContextElement</span><span class="params">(StreamRecord&lt;IN&gt; record)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    setKeyContextElement1(record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AbstractUdfStreamOperator 则是提供了对自定义函数生命周期管理的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">open</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="built_in">super</span>.open();</span><br><span class="line">    FunctionUtils.openFunction(userFunction, DefaultOpenContext.INSTANCE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">finish</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="built_in">super</span>.finish();</span><br><span class="line">    <span class="keyword">if</span> (userFunction <span class="keyword">instanceof</span> SinkFunction) &#123;</span><br><span class="line">        ((SinkFunction&lt;?&gt;) userFunction).finish();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    <span class="built_in">super</span>.close();</span><br><span class="line">    FunctionUtils.closeFunction(userFunction);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到这里，我们就知道了 Flink 中 DataStream 是如何转换的。处理逻辑保存在 Transformation 中。下面我们来看一组 Transformation 是如何生成 StreamGraph 的。</p><h3 id="StreamGraph"><a href="#StreamGraph" class="headerlink" title="StreamGraph"></a>StreamGraph</h3><p>生成 StreamGraph 的入口在 <code>org.apache.flink.streaming.api.environment.StreamExecutionEnvironment#generateStreamGraph</code> 。</p><p>在 generate 方法中，会遍历所有 Transformation 并调用 transform 方法。在调用节点的 transform 方法之前，会先确保它的输入节点都已经转换成功。</p><p>目前定义了以下 Transformation：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;rawtypes&quot;)</span></span><br><span class="line">    Map&lt;Class&lt;? <span class="keyword">extends</span> <span class="title class_">Transformation</span>&gt;, TransformationTranslator&lt;?, ? <span class="keyword">extends</span> <span class="title class_">Transformation</span>&gt;&gt;</span><br><span class="line">            tmp = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    tmp.put(OneInputTransformation.class, <span class="keyword">new</span> <span class="title class_">OneInputTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(TwoInputTransformation.class, <span class="keyword">new</span> <span class="title class_">TwoInputTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(MultipleInputTransformation.class, <span class="keyword">new</span> <span class="title class_">MultiInputTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(KeyedMultipleInputTransformation.class, <span class="keyword">new</span> <span class="title class_">MultiInputTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(SourceTransformation.class, <span class="keyword">new</span> <span class="title class_">SourceTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(SinkTransformation.class, <span class="keyword">new</span> <span class="title class_">SinkTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(GlobalCommitterTransform.class, <span class="keyword">new</span> <span class="title class_">GlobalCommitterTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(LegacySinkTransformation.class, <span class="keyword">new</span> <span class="title class_">LegacySinkTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(LegacySourceTransformation.class, <span class="keyword">new</span> <span class="title class_">LegacySourceTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(UnionTransformation.class, <span class="keyword">new</span> <span class="title class_">UnionTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(StubTransformation.class, <span class="keyword">new</span> <span class="title class_">StubTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(PartitionTransformation.class, <span class="keyword">new</span> <span class="title class_">PartitionTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(SideOutputTransformation.class, <span class="keyword">new</span> <span class="title class_">SideOutputTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(ReduceTransformation.class, <span class="keyword">new</span> <span class="title class_">ReduceTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(</span><br><span class="line">            TimestampsAndWatermarksTransformation.class,</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">TimestampsAndWatermarksTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(BroadcastStateTransformation.class, <span class="keyword">new</span> <span class="title class_">BroadcastStateTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(</span><br><span class="line">            KeyedBroadcastStateTransformation.class,</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">KeyedBroadcastStateTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    tmp.put(CacheTransformation.class, <span class="keyword">new</span> <span class="title class_">CacheTransformationTranslator</span>&lt;&gt;());</span><br><span class="line">    translatorMap = Collections.unmodifiableMap(tmp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Flink 会根据不同的 Transformation 类调用其 translateInternal 方法。在 translateInternal 方法中就会去添加节点和边。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">streamGraph.addOperator(</span><br><span class="line">        transformationId,</span><br><span class="line">        slotSharingGroup,</span><br><span class="line">        transformation.getCoLocationGroupKey(),</span><br><span class="line">        operatorFactory,</span><br><span class="line">        inputType,</span><br><span class="line">        transformation.getOutputType(),</span><br><span class="line">        transformation.getName());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (Integer inputId : context.getStreamNodeIds(parentTransformations.get(<span class="number">0</span>))) &#123;</span><br><span class="line">    streamGraph.addEdge(inputId, transformationId, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 addOperator 方法中，它通过调用 addNode 来创建 StreamNode。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> StreamNode <span class="title function_">addNode</span><span class="params">(</span></span><br><span class="line"><span class="params">        Integer vertexID,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nullable</span> String slotSharingGroup,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nullable</span> String coLocationGroup,</span></span><br><span class="line"><span class="params">        Class&lt;? extends TaskInvokable&gt; vertexClass,</span></span><br><span class="line"><span class="params">        <span class="meta">@Nullable</span> StreamOperatorFactory&lt;?&gt; operatorFactory,</span></span><br><span class="line"><span class="params">        String operatorName)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (streamNodes.containsKey(vertexID)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(<span class="string">&quot;Duplicate vertexID &quot;</span> + vertexID);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">vertex</span> <span class="operator">=</span></span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">StreamNode</span>(</span><br><span class="line">                    vertexID,</span><br><span class="line">                    slotSharingGroup,</span><br><span class="line">                    coLocationGroup,</span><br><span class="line">                    operatorFactory,</span><br><span class="line">                    operatorName,</span><br><span class="line">                    vertexClass);</span><br><span class="line"></span><br><span class="line">    streamNodes.put(vertexID, vertex);</span><br><span class="line">    isEmpty = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> vertex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 addEdgeInternal 方法中，对于 sideOutput 和 partition 这类虚拟节点，会先解析出原始节点，再建立实际的边。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">addEdgeInternal</span><span class="params">(</span></span><br><span class="line"><span class="params">        Integer upStreamVertexID,</span></span><br><span class="line"><span class="params">        Integer downStreamVertexID,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> typeNumber,</span></span><br><span class="line"><span class="params">        StreamPartitioner&lt;?&gt; partitioner,</span></span><br><span class="line"><span class="params">        List&lt;String&gt; outputNames,</span></span><br><span class="line"><span class="params">        OutputTag outputTag,</span></span><br><span class="line"><span class="params">        StreamExchangeMode exchangeMode,</span></span><br><span class="line"><span class="params">        IntermediateDataSetID intermediateDataSetId)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (virtualSideOutputNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">virtualId</span> <span class="operator">=</span> upStreamVertexID;</span><br><span class="line">        upStreamVertexID = virtualSideOutputNodes.get(virtualId).f0;</span><br><span class="line">        <span class="keyword">if</span> (outputTag == <span class="literal">null</span>) &#123;</span><br><span class="line">            outputTag = virtualSideOutputNodes.get(virtualId).f1;</span><br><span class="line">        &#125;</span><br><span class="line">        addEdgeInternal(</span><br><span class="line">                upStreamVertexID,</span><br><span class="line">                downStreamVertexID,</span><br><span class="line">                typeNumber,</span><br><span class="line">                partitioner,</span><br><span class="line">                <span class="literal">null</span>,</span><br><span class="line">                outputTag,</span><br><span class="line">                exchangeMode,</span><br><span class="line">                intermediateDataSetId);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (virtualPartitionNodes.containsKey(upStreamVertexID)) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">virtualId</span> <span class="operator">=</span> upStreamVertexID;</span><br><span class="line">        upStreamVertexID = virtualPartitionNodes.get(virtualId).f0;</span><br><span class="line">        <span class="keyword">if</span> (partitioner == <span class="literal">null</span>) &#123;</span><br><span class="line">            partitioner = virtualPartitionNodes.get(virtualId).f1;</span><br><span class="line">        &#125;</span><br><span class="line">        exchangeMode = virtualPartitionNodes.get(virtualId).f2;</span><br><span class="line">        addEdgeInternal(</span><br><span class="line">                upStreamVertexID,</span><br><span class="line">                downStreamVertexID,</span><br><span class="line">                typeNumber,</span><br><span class="line">                partitioner,</span><br><span class="line">                outputNames,</span><br><span class="line">                outputTag,</span><br><span class="line">                exchangeMode,</span><br><span class="line">                intermediateDataSetId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        createActualEdge(</span><br><span class="line">                upStreamVertexID,</span><br><span class="line">                downStreamVertexID,</span><br><span class="line">                typeNumber,</span><br><span class="line">                partitioner,</span><br><span class="line">                outputTag,</span><br><span class="line">                exchangeMode,</span><br><span class="line">                intermediateDataSetId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后根据两个物理节点创建 StreamEdge 进行连接。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">createActualEdge</span><span class="params">(</span></span><br><span class="line"><span class="params">        Integer upStreamVertexID,</span></span><br><span class="line"><span class="params">        Integer downStreamVertexID,</span></span><br><span class="line"><span class="params">        <span class="type">int</span> typeNumber,</span></span><br><span class="line"><span class="params">        StreamPartitioner&lt;?&gt; partitioner,</span></span><br><span class="line"><span class="params">        OutputTag outputTag,</span></span><br><span class="line"><span class="params">        StreamExchangeMode exchangeMode,</span></span><br><span class="line"><span class="params">        IntermediateDataSetID intermediateDataSetId)</span> &#123;</span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">upstreamNode</span> <span class="operator">=</span> getStreamNode(upStreamVertexID);</span><br><span class="line">    <span class="type">StreamNode</span> <span class="variable">downstreamNode</span> <span class="operator">=</span> getStreamNode(downStreamVertexID);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If no partitioner was specified and the parallelism of upstream and downstream</span></span><br><span class="line">    <span class="comment">// operator matches use forward partitioning, use rebalance otherwise.</span></span><br><span class="line">    <span class="keyword">if</span> (partitioner == <span class="literal">null</span></span><br><span class="line">            &amp;&amp; upstreamNode.getParallelism() == downstreamNode.getParallelism()) &#123;</span><br><span class="line">        partitioner =</span><br><span class="line">                dynamic ? <span class="keyword">new</span> <span class="title class_">ForwardForUnspecifiedPartitioner</span>&lt;&gt;() : <span class="keyword">new</span> <span class="title class_">ForwardPartitioner</span>&lt;&gt;();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (partitioner == <span class="literal">null</span>) &#123;</span><br><span class="line">        partitioner = <span class="keyword">new</span> <span class="title class_">RebalancePartitioner</span>&lt;Object&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> ForwardPartitioner) &#123;</span><br><span class="line">        <span class="keyword">if</span> (upstreamNode.getParallelism() != downstreamNode.getParallelism()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (partitioner <span class="keyword">instanceof</span> ForwardForConsecutiveHashPartitioner) &#123;</span><br><span class="line">                partitioner =</span><br><span class="line">                        ((ForwardForConsecutiveHashPartitioner&lt;?&gt;) partitioner)</span><br><span class="line">                                .getHashPartitioner();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">UnsupportedOperationException</span>(</span><br><span class="line">                        <span class="string">&quot;Forward partitioning does not allow &quot;</span></span><br><span class="line">                                + <span class="string">&quot;change of parallelism. Upstream operation: &quot;</span></span><br><span class="line">                                + upstreamNode</span><br><span class="line">                                + <span class="string">&quot; parallelism: &quot;</span></span><br><span class="line">                                + upstreamNode.getParallelism()</span><br><span class="line">                                + <span class="string">&quot;, downstream operation: &quot;</span></span><br><span class="line">                                + downstreamNode</span><br><span class="line">                                + <span class="string">&quot; parallelism: &quot;</span></span><br><span class="line">                                + downstreamNode.getParallelism()</span><br><span class="line">                                + <span class="string">&quot; You must use another partitioning strategy, such as broadcast, rebalance, shuffle or global.&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (exchangeMode == <span class="literal">null</span>) &#123;</span><br><span class="line">        exchangeMode = StreamExchangeMode.UNDEFINED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Just make sure that &#123;<span class="doctag">@link</span> StreamEdge&#125; connecting same nodes (for example as a result of</span></span><br><span class="line"><span class="comment">     * self unioning a &#123;<span class="doctag">@link</span> DataStream&#125;) are distinct and unique. Otherwise it would be</span></span><br><span class="line"><span class="comment">     * difficult on the &#123;<span class="doctag">@link</span> StreamTask&#125; to assign &#123;<span class="doctag">@link</span> RecordWriter&#125;s to correct &#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment">     * StreamEdge&#125;.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">uniqueId</span> <span class="operator">=</span> getStreamEdges(upstreamNode.getId(), downstreamNode.getId()).size();</span><br><span class="line"></span><br><span class="line">    <span class="type">StreamEdge</span> <span class="variable">edge</span> <span class="operator">=</span></span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">StreamEdge</span>(</span><br><span class="line">                    upstreamNode,</span><br><span class="line">                    downstreamNode,</span><br><span class="line">                    typeNumber,</span><br><span class="line">                    partitioner,</span><br><span class="line">                    outputTag,</span><br><span class="line">                    exchangeMode,</span><br><span class="line">                    uniqueId,</span><br><span class="line">                    intermediateDataSetId);</span><br><span class="line"></span><br><span class="line">    getStreamNode(edge.getSourceId()).addOutEdge(edge);</span><br><span class="line">    getStreamNode(edge.getTargetId()).addInEdge(edge);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过 StreamNode 和 StreamEdge，就可以得到所有的节点和边，也就是我们的 StreamGraph 就创建完成了。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文先介绍了 Flink 的四种执行图以及它们之间的关系。接着又通过源码探索了 StreamGraph 的生成逻辑，Flink 将处理 逻辑保存在 Transformation 中，又由 Transformation 生成了 StreamGraph。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink 中有四种执行图，分别是 StreamGraph、JobGraph、ExecutionGraph 和 Physical Graph。今天我们来看下我们编写的 Flink 程序代码是如何生成 StreamGraph 的。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：反压</title>
    <link href="https://jackeyzhe.github.io/2025/08/26/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%8F%8D%E5%8E%8B/"/>
    <id>https://jackeyzhe.github.io/2025/08/26/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%8F%8D%E5%8E%8B/</id>
    <published>2025-08-26T15:13:46.000Z</published>
    <updated>2025-09-07T14:17:06.951Z</updated>
    
    <content type="html"><![CDATA[<p>今天来聊在 Flink 运维过程中比较常见的一个问题：反压。<span id="more"></span></p><h3 id="什么是反压"><a href="#什么是反压" class="headerlink" title="什么是反压"></a>什么是反压</h3><p>反压是流式系统中关于数据处理能力的动态反馈机制，并且是从下游到上游的反馈，一般发生在上游节点的生产速度大于下游节点的消费速度的情况。</p><h3 id="数据如何传输"><a href="#数据如何传输" class="headerlink" title="数据如何传输"></a>数据如何传输</h3><p>在了解反压的细节之前，首先要知道 Flink 中数据是如何传输的。在 Flink 中，两个算子之间的关系分为三种：</p><ol><li><p>部署在同一个 TaskManager 上，且属于同一算子链。</p></li><li><p>部署在同一个 TaskManager 上，但不是同一个算子链。</p></li><li><p>部署在不同的 TaskManager 上。</p></li></ol><p>三种不同的关系，对应的算子间的数据传输方式也不同。先说第一种。</p><h4 id="同一线程数据传输"><a href="#同一线程数据传输" class="headerlink" title="同一线程数据传输"></a>同一线程数据传输</h4><p>同一线程中的两个算子共享内存，因此数据传输非常简单，上游产出好数据后，直接调用下游的 processElement 方法即可。</p><h4 id="本地线程数据传输"><a href="#本地线程数据传输" class="headerlink" title="本地线程数据传输"></a>本地线程数据传输</h4><p>对于第二种关系，两个算子不在同一线程，但是部署在同一个 TaskManager 上，也就是算子之间的数据传输是跨线程的。我们通过一个图来解释。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1757168841/Blog/flink/7/Flink%E9%80%9A%E4%BF%A1.png" alt="本地线程传输"></p><p>图中，Flat Map Task 是上游算子，sum 是下游的算子。它们共享一块 Buffer 内存。当 Buffer 中没有数据可以消费时，sum 所在的线程会阻塞（步骤1）。随着数据的流入，Flat Map Task 会将处理好的数据写入到 ResultSubpartition（步骤2），然后 flush 到 Buffer 中（步骤3）。此时会唤醒 sum 所在的线程（步骤4），它就可以从 Buffer 中读取数据了（步骤5）。</p><h4 id="远程数据传输"><a href="#远程数据传输" class="headerlink" title="远程数据传输"></a>远程数据传输</h4><p>第三种跨 TaskManager 的数据传输，与第二种类似，不过也有些区别。我们还是通过一张图来解释。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1757170148/Blog/flink/7/Flink%E8%BF%9C%E7%A8%8B%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93.png" alt="远程数据传输"></p><p>从图中可以看到，当 sum 所在线程没有 Buffer 可以消费时，会通过 PartitionRequestClient 向 Flat Map Task 所在的进程发送请求。Flat Map Task 所在进程接收到请求后，会读取 Buffer 中的数据并返回。</p><h3 id="Flink-的反压"><a href="#Flink-的反压" class="headerlink" title="Flink 的反压"></a>Flink 的反压</h3><p>了解了 Flink 的数据传输方式之后，我们再来看下 Flink 是如何感知反压的。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1757170638/Blog/flink/7/Flink%E5%8F%8D%E5%8E%8B%E8%BF%87%E7%A8%8B.png" alt="Flink反压"></p><p>上图是一个数据传输的简图。当 Task1 有 Buffer 空间时，记录 A 被序列化并写入 LocalBufferPool 中，接着发送到 Task2 的 LocalBufferPool 中，Task2 读取并反序列化后交由程序处理。</p><p>这里我们也分两个场景讨论。</p><h4 id="本地传输"><a href="#本地传输" class="headerlink" title="本地传输"></a>本地传输</h4><p>Task1 和 Task2 在同一个 TaskManager 节点，Task1 和 Task2 共用 Buffer，一旦 Task2 消费了 Buffer，该 Buffer 就会被回收。如果 Task2 的处理速度比 Task1 慢，那么 Buffer 的回收速度就赶不上 Task1 取 Buffer 的速度，这样会导致无 Buffer 可用，最终 Task1 就会降速。</p><h4 id="远程传输"><a href="#远程传输" class="headerlink" title="远程传输"></a>远程传输</h4><p>Task1 和 Task2 运行在不同的 TaskManager 上，那 Buffer 会发送到网络后，等接收端消费完再回收。在发送端，会通过 Netty 水位机制来保证不往网络中写太多数据，如果网络中的数据超过了高水位值，就会等其下降到低水位值以下才会继续写数据。如果网络有堆积，发送端就会暂停发送，Buffer 也不会被回收，这就会阻塞 writer 往 ResultSubPartition 中写数据。</p><h3 id="反压监控"><a href="#反压监控" class="headerlink" title="反压监控"></a>反压监控</h3><p>在 Flink Web UI 中，可以找到反压的监控</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1757254334/Blog/flink/7/back_pressure_subtasks.png" alt="反压监控"></p><p>它有三种状态：</p><ul><li><strong>OK</strong>: 0% &lt;= 反压比例 &lt;= 10%，此时一般不用处理。</li><li><strong>LOW</strong>: 10% &lt; 反压比例 &lt;= 50%，这种状态需要关注。</li><li><strong>HIGH</strong>: 50% &lt; 反压比例 &lt;= 100%，已经反压，需要赶快处理。</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>今天我们聊了什么是反压，以及 Flink 中数据传输方法和 Flink 任务是如何感知反压的。Flink 的传输方式分为三种，分别是同线程传输、本地跨线程传输以及远程传输。Flink 任务在感知反压时也分别针对本地传输和远程传输做了讨论。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天来聊在 Flink 运维过程中比较常见的一个问题：反压。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：状态后端</title>
    <link href="https://jackeyzhe.github.io/2025/08/24/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF/"/>
    <id>https://jackeyzhe.github.io/2025/08/24/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E5%90%8E%E7%AB%AF/</id>
    <published>2025-08-23T16:16:42.000Z</published>
    <updated>2025-09-16T14:39:27.083Z</updated>
    
    <content type="html"><![CDATA[<p>我们继续来聊 Flink 容错相关的内容。前面在介绍 Checkpoint 和 Savepoint 时提到了 State 的稳定存储，那究竟如何存储以及存储在什么地方呢？相信通过读完本文之后，你会有答案。<span id="more"></span></p><h3 id="State-Backend-分类"><a href="#State-Backend-分类" class="headerlink" title="State Backend 分类"></a>State Backend 分类</h3><p>在 Flink 中状态后端（State Backend）是用来管理状态如何存储的。当前内置了两种 State Backend，分别是 HashMapStateBackend 和 EmbeddedRocksDBStateBackend。Flink 默认使用的是 HashMapStateBackend。</p><h4 id="HashMapStateBackend"><a href="#HashMapStateBackend" class="headerlink" title="HashMapStateBackend"></a>HashMapStateBackend</h4><p>在 HashMapBackend 中，数据是以 Java 对象的形式存储的，它适用于有较大 State，较长 window 和 较大 key/value 状态的场景。同时适用于高可用场景。在使用 HashMapStateBackend 时，建议把 managed memory 设置为 0，以此来增加用户代码可使用的内存。</p><h4 id="EmbeddedRocksDBStateBackend"><a href="#EmbeddedRocksDBStateBackend" class="headerlink" title="EmbeddedRocksDBStateBackend"></a>EmbeddedRocksDBStateBackend</h4><p>对于 EmbeddedRocksDBStateBackend 而言，数据是存储在 RocksDB 中的，在存储之前，要对数据进行序列化。EmbeddedRocksDBStateBackend 也存在一定局限性，那就是最大只能支持每个 key/value 存储 2^31 字节大小的数据，这是当前 RocksDB JNI 的限制。</p><p>EmbeddedRocksDBStateBackend 也有一定的优势，其一是它是目前唯一支持增量 Checkpoint 的 State Backend。其二是因为它是外部存储，因此它可以支持非常大的 State，非常长的窗口。</p><p>增量快照只包含自上一次快照完成后被修改的记录，所以增量快照的一大优点就是可以显著减少快照的耗时。在恢复时间上，要分情况讨论，如果瓶颈在网络带宽，那么增量快照的恢复时间要比全量快照更长，因为增量快照包含的多个 sst 文件之间可能存在重复数据。如果瓶颈在 CPU 或 IO，那增量快照恢复时间更短，因为增量快照不需要恢复不需要解析 Flink 统一的存储格式来重建本地的 RocksDB 表，而是直接基于 sst 文件加载。</p><h3 id="Checkpoint-存储类型"><a href="#Checkpoint-存储类型" class="headerlink" title="Checkpoint 存储类型"></a>Checkpoint 存储类型</h3><p>了解了 State Backend 分类之后，我们再来看 Checkpoint 的存储类型。它也分为两类：JobManagerCheckpointStorage 和 FileSystemCheckpointStorage。</p><h4 id="JobManagerCheckpointStorage"><a href="#JobManagerCheckpointStorage" class="headerlink" title="JobManagerCheckpointStorage"></a>JobManagerCheckpointStorage</h4><p>JobManagerCheckpointStorage 是将快照存储在 JobManager 的堆内存中。JobManagerCheckpointStorage 在使用时有一定限制：</p><ul><li><p>默认每个 State 大小最大为 5MB</p></li><li><p>总的状态大小不能超过 JobManager 内存</p></li></ul><p>基于这些限制，JobManagerCheckpointStorage 只适用于本地的开发和调试。</p><h4 id="FileSystemCheckpointStorage"><a href="#FileSystemCheckpointStorage" class="headerlink" title="FileSystemCheckpointStorage"></a>FileSystemCheckpointStorage</h4><p>FileSystemCheckpointStorage 是将状态数据保存在外部存储中，要适用 FileSystemCheckpointStorage，需要配置文件系统的 URL。例如：“hdfs://namenode:40010/flink/checkpoints”。而元数据则存储在 JobManager 的内存中。</p><h3 id="Checkpoint-存储设置"><a href="#Checkpoint-存储设置" class="headerlink" title="Checkpoint 存储设置"></a>Checkpoint 存储设置</h3><p>有了前面 State Backend 和 存储类型的分类之后，我们就可以将其进行组合，得到最终 Checkpoint 的存储了。</p><p>目前共有三种组合，也对应了旧版本的三种 State Backend。</p><h4 id="MemoryStateBackend"><a href="#MemoryStateBackend" class="headerlink" title="MemoryStateBackend"></a>MemoryStateBackend</h4><p>MemoryStateBackend 对应了 HashMapStateBackend 和 JobManagerCheckpointStorage 的组合。</p><p>设置方法为</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">state.backend:</span> <span class="string">hashmap</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional, Flink will automatically default to JobManagerCheckpointStorage</span></span><br><span class="line"><span class="comment"># when no checkpoint directory is specified.</span></span><br><span class="line"><span class="attr">execution.checkpointing.storage:</span> <span class="string">jobmanager</span></span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">config.set(StateBackendOptions.STATE_BACKEND, <span class="string">&quot;hashmap&quot;</span>);</span><br><span class="line">config.set(CheckpointingOptions.CHECKPOINT_STORAGE, <span class="string">&quot;jobmanager&quot;</span>);</span><br><span class="line">env.configure(config);</span><br></pre></td></tr></table></figure><h4 id="FsStateBackend"><a href="#FsStateBackend" class="headerlink" title="FsStateBackend"></a>FsStateBackend</h4><p>FsStateBackend 对应了 HashMapStateBackend 和 FileSystemCheckpointStorage 的组合。</p><p>它的设置方法为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">state.backend:</span> <span class="string">hashmap</span></span><br><span class="line"><span class="attr">execution.checkpointing.dir:</span> <span class="string">file:///checkpoint-dir/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional, Flink will automatically default to FileSystemCheckpointStorage</span></span><br><span class="line"><span class="comment"># when a checkpoint directory is specified.</span></span><br><span class="line"><span class="attr">execution.checkpointing.storage:</span> <span class="string">filesystem</span></span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">config.set(StateBackendOptions.STATE_BACKEND, <span class="string">&quot;hashmap&quot;</span>);</span><br><span class="line">config.set(CheckpointingOptions.CHECKPOINT_STORAGE, <span class="string">&quot;filesystem&quot;</span>);</span><br><span class="line">config.set(CheckpointingOptions.CHECKPOINTS_DIRECTORY, <span class="string">&quot;file:///checkpoint-dir&quot;</span>);</span><br><span class="line">env.configure(config);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Advanced FsStateBackend configurations, such as write buffer size</span></span><br><span class="line"><span class="comment">// can be set manually by using CheckpointingOptions.</span></span><br><span class="line">config.set(CheckpointingOptions.FS_WRITE_BUFFER_SIZE, <span class="number">4</span> * <span class="number">1024</span>);</span><br><span class="line">env.configure(config);</span><br></pre></td></tr></table></figure><h4 id="RocksDBStateBackend"><a href="#RocksDBStateBackend" class="headerlink" title="RocksDBStateBackend"></a>RocksDBStateBackend</h4><p>RocksDBStateBackend 对应了 EmbeddedRocksDBStateBackend 和 FileSystemCheckpointStorage 的组合。</p><p>它的设置方法为</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="attr">execution.checkpointing.dir:</span> <span class="string">file:///checkpoint-dir/</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optional, Flink will automatically default to FileSystemCheckpointStorage</span></span><br><span class="line"><span class="comment"># when a checkpoint directory is specified.</span></span><br><span class="line"><span class="attr">execution.checkpointing.storage:</span> <span class="string">filesystem</span></span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">config.set(StateBackendOptions.STATE_BACKEND, <span class="string">&quot;rocksdb&quot;</span>);</span><br><span class="line">config.set(CheckpointingOptions.CHECKPOINT_STORAGE, <span class="string">&quot;filesystem&quot;</span>);</span><br><span class="line">config.set(CheckpointingOptions.CHECKPOINTS_DIRECTORY, <span class="string">&quot;file:///checkpoint-dir&quot;</span>);</span><br><span class="line">env.configure(config);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// If you manually passed FsStateBackend into the RocksDBStateBackend constructor</span></span><br><span class="line"><span class="comment">// to specify advanced checkpointing configurations such as write buffer size,</span></span><br><span class="line"><span class="comment">// you can achieve the same results by using CheckpointingOptions.</span></span><br><span class="line">config.set(CheckpointingOptions.FS_WRITE_BUFFER_SIZE, <span class="number">4</span> * <span class="number">1024</span>);</span><br><span class="line">env.configure(config);</span><br></pre></td></tr></table></figure><h3 id="State-序列化与反序列化"><a href="#State-序列化与反序列化" class="headerlink" title="State 序列化与反序列化"></a>State 序列化与反序列化</h3><p>我们前面在创建 State 的描述符时，指定了 State 的类型，这其实就是告诉 Flink 应该如何去序列化我们的 State。当然，也可以自定义 State 序列化器，自定义序列化器需要 TypeSerializer，然后在创建描述符时指定。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomTypeSerializer</span> <span class="keyword">extends</span> <span class="title class_">TypeSerializer</span>&lt;Tuple2&lt;String, Integer&gt;&gt; &#123;...&#125;;</span><br><span class="line"></span><br><span class="line">ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">ListStateDescriptor</span>&lt;&gt;(</span><br><span class="line">        <span class="string">&quot;state-name&quot;</span>,</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">CustomTypeSerializer</span>());</span><br><span class="line"></span><br><span class="line">checkpointedState = getRuntimeContext().getListState(descriptor);</span><br></pre></td></tr></table></figure><p>Flink 中状态分为两种类型，一种是基于 Heap，一种是不基于 Heap。</p><h4 id="Heap-state-backends"><a href="#Heap-state-backends" class="headerlink" title="Heap state backends"></a>Heap state backends</h4><p>首先看基于 Heap 的，HashMapStateBackend 是基于 Heap 的。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1756052394/Blog/flink/6/HeapStateBackend.png" alt="HeapStateBackend"></p><p>Heap state backend 存在本地的状态后端中的是非序列化的数据，当触发 Checkpoint / Savepoint 时，会用指定的序列化器将数据序列化，然后存储到指定的稳定存储中。</p><p>如果我们对程序进行了升级，这时要从 State 恢复的话，需要先将稳定存储中的数据进行反序列化，然后将结果加载到 TM 的内存中，供 user code 使用。</p><h4 id="Off-heap-state-backends"><a href="#Off-heap-state-backends" class="headerlink" title="Off-heap state backends"></a>Off-heap state backends</h4><p>EmbeddedRocksDBStateBackend 就是一种不基于 Heap 的状态。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1756053324/Blog/flink/6/OffHeapStateBackend.png" alt="Off-heap State Backend"></p><p>不基于 Heap 的状态在写入本地 State 时就会进行序列化，序列化后的数据会写入到堆外内存。在触发 Checkpoint 时，就只是把数据文件转存到稳定存储中。</p><p>当我们的任务完成升级后，会先将二进制文件恢复到 TM 的内存中，这里是一个文件加载的过程。当我们要使用 State 时，才会进行反序列化，注意这里只会对使用到的 State 进行反序列化读取以及后续的更新，没有使用到的还是保持旧版本的数据。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们重点介绍了状态后端的存储。State Backend 分为 HashMapStateBackend 和 EmbeddedRocksDBStateBackend，其存储类型又分为 JobManagerCheckpointStorage 和 FileSystemCheckpointStorage。最终我们会有三种不同的状态后端：MemoryStateBackend、FsStateBackend 和 RocksDBStateBackend。最后我们还介绍了 State 的两种不同的序列化。</p><p>相信通过本文的介绍，你已经可以回答开篇的问题了。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们继续来聊 Flink 容错相关的内容。前面在介绍 Checkpoint 和 Savepoint 时提到了 State 的稳定存储，那究竟如何存储以及存储在什么地方呢？相信通过读完本文之后，你会有答案。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：如何做容错</title>
    <link href="https://jackeyzhe.github.io/2025/08/17/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A6%82%E4%BD%95%E5%81%9A%E5%AE%B9%E9%94%99/"/>
    <id>https://jackeyzhe.github.io/2025/08/17/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A6%82%E4%BD%95%E5%81%9A%E5%AE%B9%E9%94%99/</id>
    <published>2025-08-17T03:29:28.000Z</published>
    <updated>2025-08-21T16:38:11.661Z</updated>
    
    <content type="html"><![CDATA[<p>现在我们已经了解了 Flink 的状态如何定义和使用，那 Flink 是如何做容错的呢？今天我们一起来了解一下。<span id="more"></span></p><p>先来回答问题， Flink 是通过状态快照来做容错的，在 Flink 中状态快照分为 Checkpoint 和 Savepoint 两种。</p><h3 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h3><p>Checkpoint 是一种自动执行的快照，其目的是让 Flink 任务可以从故障中恢复。它可以是增量的，并且为快速恢复进行了优化。</p><h4 id="如何开启-Checkpoint"><a href="#如何开启-Checkpoint" class="headerlink" title="如何开启 Checkpoint"></a>如何开启 Checkpoint</h4><p>Checkpoint 默认是关闭的，开启的方法很简单，只需要调用 enableCheckpointing() 方法即可。除了这个方法之外，Checkpoint 还有一些高级特性。我们来看几个比较常用的，更多的选项可以查看<a href="https://nightlies.apache.org/flink/flink-docs-master/zh/docs/dev/datastream/fault-tolerance/checkpointing/#%e7%9b%b8%e5%85%b3%e7%9a%84%e9%85%8d%e7%bd%ae%e9%80%89%e9%a1%b9">官方文档</a>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 每 1000ms 开始一次 checkpoint</span></span><br><span class="line">env.enableCheckpointing(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 高级选项：</span></span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setMinPauseBetweenCheckpoints(<span class="number">500</span>);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setTolerableCheckpointFailureNumber(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().setExternalizedCheckpointRetention(</span><br><span class="line">        ExternalizedCheckpointRetention.RETAIN_ON_CANCELLATION);</span><br><span class="line"></span><br><span class="line">env.getCheckpointConfig().enableUnalignedCheckpoints();</span><br></pre></td></tr></table></figure><ul><li><p>CheckpointingMode：支持 EXACTLY_ONCE 和 AT_LEAST_ONCE 两种，精确一次有更好的数据一致性，而至少一次可以提供更低的延迟。</p></li><li><p>MinPauseBetweenCheckpoints：Checkpoint 之间最小间隔时间，单位是毫秒，即前一次 Checkpoint 执行完成之后必须间隔 n 毫秒之后才会开启下一次 Checkpoint。</p></li><li><p>CheckpointTimeout：Checkpoint 超时时间，单位为毫秒，表示 Checkpoint 必须在 n 毫秒内完成，否则就会因超时失败。</p></li><li><p>TolerableCheckpointFailureNumber：可容忍连续失败次数，默认是0。超过这个阈值之后，整个 Flink 作业会触发 fail over。</p></li><li><p>MaxConcurrentCheckpoints：Checkpoint 并发数，默认情况下是1，在同一时间只允许一个 Checkpoint 执行。这个参数不能和最小间隔时间一起使用。</p></li><li><p>ExternalizedCheckpointRetention：周期存储 Checkpoint 到外部存储，这样在任务失败时 Checkpoint 也不会被删除。</p></li><li><p>enableUnalignedCheckpoints：使用非对齐的 Checkpoint，可以减少在产生背压时 Checkpoint 的创建时间。</p></li></ul><h4 id="Checkpoint-存储"><a href="#Checkpoint-存储" class="headerlink" title="Checkpoint 存储"></a>Checkpoint 存储</h4><p>Flink 提供了两种存储类型：JobManagerCheckpointStorage 和 FileSystemCheckpointStorage。默认是 JobManagerCheckpointStorage，即将 Checkpoint 快照存储在 JobManager 的堆内存中，也可以设置 Checkpoint 目录，将快照存储在外部存储系统中。</p><p>Checkpoint 目录通过 execution.checkpointing.dir 设置项设置。其目录结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/user-defined-checkpoint-dir</span><br><span class="line">    /&#123;job-id&#125;</span><br><span class="line">        |</span><br><span class="line">        + --shared/</span><br><span class="line">        + --taskowned/</span><br><span class="line">        + --chk-1/</span><br><span class="line">        + --chk-2/</span><br><span class="line">        + --chk-3/</span><br><span class="line">        ...   </span><br></pre></td></tr></table></figure><h4 id="Checkpoint-工作原理"><a href="#Checkpoint-工作原理" class="headerlink" title="Checkpoint 工作原理"></a>Checkpoint 工作原理</h4><p>在前文中，我们曾经提到过 Checkpoint Coordinator，它是 JobManager 的其中一个模块。它在 Checkpoint 过程中担任着重要的角色。</p><p>现在来看下 Checkpoint 的完整流程</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1755702080/Blog/flink/5/Checkpoint.png" alt="Checkpoint"></p><p>1、Checkpoint Coordinator 触发所有 Source 节点开始 Checkpoint，Source 收到触发命令后，会将自己的 State 进行持久化（图中三角形），并且向下游发送 barrier 事件（图中的小矩形）。当 Source 节点的 State 持久化完成之后，会数据存储的地址发送给 Checkpoint Coordinator。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1755706201/Blog/flink/5/CheckpointHandle.png" alt="CheckpointHandle"></p><p>2、barrier 事件随着事件流传输到下游节点，当下游节点收到所有的上游 barrier 事件后，也会将自己的 State 持久化，并继续向下传播 barrier 事件。持久化完成后，也同样将数据存储地址发送给 Checkpoint Coordinator。</p><p>3、当所有的算子都完成持久化过程后，Checkpoint Coordinator 会将一些元数据进行持久化。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1755706201/Blog/flink/5/CompleteCheckpoint.png" alt="CompleteCheckpoint"></p><p>至此，一次完整的 Checkpoint 流程就结束了。</p><h3 id="Savepoint"><a href="#Savepoint" class="headerlink" title="Savepoint"></a>Savepoint</h3><p>学习完 Checkpoint 之后，我们再来了解下另一种快照——Savepoint。</p><p>Savepoint 是依据 checkpoint 机制创建的一致性镜像。通常用来做 Flink 作业的重启或更新等运维操作。Savepoint 包含稳定存储上的二进制文件（作业状态的镜像）和元数据文件两部分。</p><h4 id="使用-Savepoint"><a href="#使用-Savepoint" class="headerlink" title="使用 Savepoint"></a>使用 Savepoint</h4><p>根据官方文档的提示，在我们的程序中，最好显式调用 uid() 方法来为算子指定一个 ID，这些 ID 被用来恢复每个算子的状态。如果不指定的话，Flink 任务会自动生成算子 ID，但是生成的 ID 与程序结构有关，也就是说，如果程序的结构改变了的话，就没有办法从 Savepoint 恢复对应算子的状态了。</p><p>有了这个前提条件之后，我们就可以使用命令来操作 Savepoint 了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">// 触发 savepoint</span><br><span class="line">$ bin/flink savepoint :jobId [:targetDirectory]</span><br><span class="line"></span><br><span class="line">// 触发 savepoint, 指定 <span class="built_in">type</span>，默认是 canonical</span><br><span class="line">$ bin/flink savepoint --<span class="built_in">type</span> [native/canonical] :jobId [:targetDirectory]</span><br><span class="line"></span><br><span class="line">// 触发 savepoint，客户端拿到 trigger <span class="built_in">id</span> 后立即返回</span><br><span class="line">$ bin/flink savepoint :jobId [:targetDirectory] -detached</span><br><span class="line"></span><br><span class="line">// 使用 savepoint 停止作业</span><br><span class="line">$ bin/flink stop --<span class="built_in">type</span> [native/canonical] --savepointPath [:targetDirectory] :jobId</span><br><span class="line"></span><br><span class="line">// 从 savepoint 恢复</span><br><span class="line">$ bin/flink run -s :savepointPath [:runArgs]</span><br><span class="line"></span><br><span class="line">// 删除 savepoint</span><br><span class="line">$ bin/flink savepoint -d :savepointPath</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在 触发 savepoint 时，我们可以指定格式，两种格式的区别是：</p><ul><li><p>canonical（标准格式）：在任何存储都保持统一格式，重在保证兼容性。</p></li><li><p>native（原生格式）：标准格式创建和恢复都很慢，原生格式是以特定的状态后端的格式生成，可以更快的创建和恢复。</p></li></ul><h3 id="Checkpoint-与-Savepoint-区别"><a href="#Checkpoint-与-Savepoint-区别" class="headerlink" title="Checkpoint 与 Savepoint 区别"></a>Checkpoint 与 Savepoint 区别</h3><p>这是面试最常见的问题之一，有了 checkpoint，为什么还需要 savepoint？或者说两者之间有什么区别？</p><p>从概念上来讲，Checkpoint 类似数据库的恢复日志，而 Savepoint 类似数据库的备份。Checkpoint 主要用于作业故障的恢复，它的管理和删除也都是 Flink 内部处理，用户不需要过多关注。Savepoint 主要用于有计划的手动运维，例如升级 Flink 版本。它的创建、删除操作都需要用户手动执行。</p><p>下面是官方文档给出的 Checkpoint 和 Savepoint 支持的操作。✓表示完全支持，x表示不支持，!表示目前有效，但没有正式保证支持，使用时存在一定风险。</p><table><thead><tr><th>操作</th><th>标准 Savepoint</th><th>原生 Savepoint</th><th>对齐 Checkpoint</th><th>非对齐 Checkpoint</th></tr></thead><tbody><tr><td>更换状态后端</td><td>✓</td><td>x</td><td>x</td><td>x</td></tr><tr><td>State Processor API (写)</td><td>✓</td><td>x</td><td>x</td><td>x</td></tr><tr><td>State Processor API (读)</td><td>✓</td><td>!</td><td>!</td><td>x</td></tr><tr><td>自包含和可移动</td><td>✓</td><td>✓</td><td>x</td><td>x</td></tr><tr><td>Schema 变更</td><td>✓</td><td>!</td><td>!</td><td>!</td></tr><tr><td>任意 job 升级</td><td>✓</td><td>✓</td><td>✓</td><td>x</td></tr><tr><td>非任意 job 升级</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>Flink 小版本升级</td><td>✓</td><td>✓</td><td>✓</td><td>x</td></tr><tr><td>Flink bug/patch 版本升级</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>扩缩容</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr></tbody></table><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们介绍了 Flink 是如何做容错的，分别介绍了 Checkpoint 和 Savepoint，以及它们之间的区别。本文多次提到了 Checkpoint 和 Savepoint 依赖的稳定存储，我会在下一篇文章进行详细的介绍。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;现在我们已经了解了 Flink 的状态如何定义和使用，那 Flink 是如何做容错的呢？今天我们一起来了解一下。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：状态类型和应用</title>
    <link href="https://jackeyzhe.github.io/2025/08/04/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8/"/>
    <id>https://jackeyzhe.github.io/2025/08/04/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%8A%B6%E6%80%81%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%94%E7%94%A8/</id>
    <published>2025-08-04T15:33:44.000Z</published>
    <updated>2025-08-14T14:43:30.348Z</updated>
    
    <content type="html"><![CDATA[<p>Flink 被广泛应用的原因，除了我们前面提到的对时间以及窗口的应用之外，另一点就是它强大的容错机制，以及对 Exactly Once 的支持。<span id="more"></span></p><p>今天就来了解一下 Flink 的状态以及应用，首先第一个问题是：什么是有状态计算？</p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>在数据流处理中，大部分操作都是每次只处理一个事件，比如对输入的数据进行结构化解析，这类操作我们称为无状态计算。而有些操作则需要记住多个事件并进行处理，比如前面我们在窗口中对数据做的求和操作，这类操作我们称之为有状态计算。</p><p>在 Flink 中，状态的另一个重要作用是用来做故障恢复，故障恢复主要依赖于 checkpoint 和 savepoint。当我们使用状态时，通常需要从 State Backend 读取。</p><p>通过介绍有状态计算的基本概念，我们又引出了 checkpoint、State Backend 等概念，下面我们再来一一解释。</p><h3 id="状态分类"><a href="#状态分类" class="headerlink" title="状态分类"></a>状态分类</h3><p>Flink 状态分类可以参考下图</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1754928263/Blog/flink/4/%E7%8A%B6%E6%80%81%E5%88%86%E7%B1%BB.png" alt="状态分类"></p><p>首先是分为 Raw State 和 Managed State 两大类，我们分别从管理方式、数据类型、适用场景这三个方面来看它们的区别</p><table><thead><tr><th></th><th>Raw State</th><th>Managed State</th></tr></thead><tbody><tr><td>管理方式</td><td>开发者自行管理，需要手动序列化和反序列化</td><td>由 Flink Runtime 管理，自动存储和恢复数据</td></tr><tr><td>数据类型</td><td>仅支持 byte 数组</td><td>支持 value, list, map</td></tr><tr><td>适用场景</td><td>需要自定义 Operator</td><td>支持大部分计算场景</td></tr></tbody></table><p>Managed State 又分为 Keyed State 和 Operator State 两类，下面我们详细介绍这两类状态。</p><h4 id="Keyed-State"><a href="#Keyed-State" class="headerlink" title="Keyed State"></a>Keyed State</h4><p>Keyed State 只能用在 KeyedStream 上，也就是在使用前，要先对数据流进行 keyBy 操作。Keyed State 支持以下几种状态类型：</p><ul><li><p>ValueState<T>：保存一个值，可以通过 update() 方法更新，通过 value() 方法获取保存的值。</p></li><li><p>ListState<T>：保存一个 list，可以通过 add() 或 addAll() 方法向 list 中添加元素，也可以通过 update() 直接覆盖。使用 get() 方法获取整个列表。</p></li><li><p>ReducingState<T>：保存一个值，表示添加到状态所有值的聚合，使用 add() 方法添加元素，使用 get() 方法获取保存的值。</p></li><li><p>AggregatingState&lt;IN, OUT&gt;：保存一个值，与 ReducingState 不同的是，输入和输出的元素类型可以不同。</p></li><li><p>MapState&lt;UK, UV&gt;：保存一个 map，可以使用 put() 或 putAll() 添加键值对，使用 get() 获取值。</p></li></ul><p>在知道了各个类型的 Keyed State 怎么用之后，我们再来看如何创建一个 Keyed State。以 ValueState 为例。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ValueStateDescriptor&lt;Tuple2&lt;Long, Long&gt;&gt; descriptor =</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">ValueStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                <span class="string">&quot;average&quot;</span>,</span><br><span class="line">                TypeInformation.of(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;Long, Long&gt;&gt;() &#123;&#125;));</span><br><span class="line">ValueState&lt;Tuple2&lt;Long, Long&gt;&gt; sum = getRuntimeContext().getState(descriptor);</span><br></pre></td></tr></table></figure><p>要想创建一个 State，必须先创建一个 StateDescriptor，然后通过 RuntimeContext 来获取 State。每个 State 都对应一种 StateDescriptor。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ValueState&lt;T&gt; <span class="title function_">getState</span><span class="params">(ValueStateDescriptor&lt;T&gt;)</span></span><br><span class="line">ReducingState&lt;T&gt; <span class="title function_">getReducingState</span><span class="params">(ReducingStateDescriptor&lt;T&gt;)</span></span><br><span class="line">ListState&lt;T&gt; <span class="title function_">getListState</span><span class="params">(ListStateDescriptor&lt;T&gt;)</span></span><br><span class="line">AggregatingState&lt;IN, OUT&gt; <span class="title function_">getAggregatingState</span><span class="params">(AggregatingStateDescriptor&lt;IN, ACC, OUT&gt;)</span></span><br><span class="line">MapState&lt;UK, UV&gt; <span class="title function_">getMapState</span><span class="params">(MapStateDescriptor&lt;UK, UV&gt;)</span></span><br></pre></td></tr></table></figure><h4 id="Operator-State"><a href="#Operator-State" class="headerlink" title="Operator State"></a>Operator State</h4><p>算子状态也称为非 keyed 状态，是绑定到一个并行算子实例的状态。State 需要支持重新分布。 最典型的是 Kafka Connector 中，维护了一个 topic partitions 和 offset 的 map 作为一个算子状态。</p><p>和 Keyed State 类似，想要创建一个 Operator State，同样也需要一个 StateDescriptor，同时，需要实现 CheckpointedFunction，它提供了两个方法，分别是在 checkpoint 时 调用的 snapshotState() 和 自定义函数初始化时调用的 initializeState()。</p><p>Talk is cheap, show me your code!</p><p>我们来看 Flink 官方文档提供的 Demo</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BufferingSink</span></span><br><span class="line">        <span class="keyword">implements</span> <span class="title class_">SinkFunction</span>&lt;Tuple2&lt;String, Integer&gt;&gt;,</span><br><span class="line">                   CheckpointedFunction &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> threshold;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">transient</span> ListState&lt;Tuple2&lt;String, Integer&gt;&gt; checkpointedState;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;Tuple2&lt;String, Integer&gt;&gt; bufferedElements;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BufferingSink</span><span class="params">(<span class="type">int</span> threshold)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.threshold = threshold;</span><br><span class="line">        <span class="built_in">this</span>.bufferedElements = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">invoke</span><span class="params">(Tuple2&lt;String, Integer&gt; value, Context context)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        bufferedElements.add(value);</span><br><span class="line">        <span class="keyword">if</span> (bufferedElements.size() &gt;= threshold) &#123;</span><br><span class="line">            <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element: bufferedElements) &#123;</span><br><span class="line">                <span class="comment">// send it to the sink</span></span><br><span class="line">            &#125;</span><br><span class="line">            bufferedElements.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">snapshotState</span><span class="params">(FunctionSnapshotContext context)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        checkpointedState.update(bufferedElements);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">initializeState</span><span class="params">(FunctionInitializationContext context)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        ListStateDescriptor&lt;Tuple2&lt;String, Integer&gt;&gt; descriptor =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ListStateDescriptor</span>&lt;&gt;(</span><br><span class="line">                <span class="string">&quot;buffered-elements&quot;</span>,</span><br><span class="line">                TypeInformation.of(<span class="keyword">new</span> <span class="title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;&#125;));</span><br><span class="line"></span><br><span class="line">        checkpointedState = context.getOperatorStateStore().getListState(descriptor);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (context.isRestored()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (Tuple2&lt;String, Integer&gt; element : checkpointedState.get()) &#123;</span><br><span class="line">                bufferedElements.add(element);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们在 initializeState 方法中使用 getOperatorStateStore().getListState() 创建了一个 ListState，然后将数据缓存到这个 list 中，当缓存数据大小超过一个阈值时，再统一发送到下游。</p><p>这里还有一个方法值得注意，就是 isRestored()，它是用来判断当前任务是否是从故障中恢复的，如果是，我们需要执行故障恢复相关的逻辑。在这个例子中就是把 state 的数据恢复到本地的变量中。</p><h5 id="Broadcast-State"><a href="#Broadcast-State" class="headerlink" title="Broadcast State"></a>Broadcast State</h5><p>了解了如何创建和使用 Operator State 之后，我们再来看一种特殊的 Operator State —— Broadcast State。</p><p>Broadcast State 本身是类似于 Map 类型的格式，使用时需要指定 key 和 value 的类型。它的作用是将一条数据流的数据广播到下游算子的各个节点。</p><p>Broadcast State 的一个比较常见的作用就是大流关联小流。例如，我们有一个订单流，需要关联商品详情，这时可以把商品详情的流作为 broadcast 流进行广播，这样在每个 TaskManager 中会有一份商品详情数据，订单流就可以直接查询 broadcast 的数据，不需要再访问 MySQL 数据库来做查询操作。</p><p>那么具体要怎么实现呢？其实也很简单，可以看下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">MapStateDescriptor&lt;String, Product&gt; productStateDescriptor =</span><br><span class="line">        <span class="keyword">new</span> <span class="title class_">MapStateDescriptor</span>&lt;&gt;(<span class="string">&quot;productBroadcastState&quot;</span>, String.class, Product.class);</span><br><span class="line"></span><br><span class="line">BroadcastStream&lt;Product&gt; broadcastProductStream = productStream.broadcast(productStateDescriptor);</span><br><span class="line"></span><br><span class="line">BroadcastConnectedStream&lt;Order, Product&gt; connectedStreams = orderStream.connect(broadcastProductStream);</span><br></pre></td></tr></table></figure><p>拿到 BroadcastConnectedStream 之后，我们就可以调用 process 方法进行处理了。完整的代码我放到 <a href="https://github.com/Jackeyzhe/flink-training/blob/feature/wz-demo/common/src/main/java/org/apache/flink/training/examples/state/BroadcastStateDemo.java">GitHub</a> 上了。感兴趣的可以查看。</p><p>在使用 Broadcast State 的时需要注意，目前 RocksDB 不支持保存 Broadcast State，因此，广播流吞吐量必须要小，并且 Flink 任务要预留足够的内存。</p><p>聊完了 Broadcast State，我们再来看看 Operator State 是如何进行重新分布的。正常 Operator State 支持两种重新分布的方式，按照不同的方式，我们可以划分为 ListState 和 UnionListState。</p><ul><li><p>ListState：所有的 element 均匀分布到 task 上</p></li><li><p>UnionListState：每个 element 都要在所有的 task 上</p></li></ul><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1755107607/Blog/flink/4/OperatorStateResize.png" alt="OperatorStateResize"></p><p>Broadcast State 由于本身就是广播状态，因此重新分布后仍然是需要进行广播的。</p><h4 id="状态有效期"><a href="#状态有效期" class="headerlink" title="状态有效期"></a>状态有效期</h4><p>最后再来扩展一个知识点，就是状态的有效期。在 Flink 中，只有 Keyed State 支持有效期。具体使用方法如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">StateTtlConfig</span> <span class="variable">ttlConfig</span> <span class="operator">=</span> StateTtlConfig</span><br><span class="line">    .newBuilder(Duration.ofSeconds(<span class="number">1</span>))</span><br><span class="line">    .setUpdateType(StateTtlConfig.UpdateType.OnCreateAndWrite)</span><br><span class="line">    .setStateVisibility(StateTtlConfig.StateVisibility.NeverReturnExpired)</span><br><span class="line">    .build();</span><br><span class="line">    </span><br><span class="line">ValueStateDescriptor&lt;String&gt; stateDescriptor = <span class="keyword">new</span> <span class="title class_">ValueStateDescriptor</span>&lt;&gt;(<span class="string">&quot;text state&quot;</span>, String.class);</span><br><span class="line">stateDescriptor.enableTimeToLive(ttlConfig);</span><br></pre></td></tr></table></figure><p>这里有三个属性，我们分别来解释一下，首先第一个是过期时间，在调用 newBuilder 时就要传入。</p><p>第二个是 UpdateType，也就是更新策略，默认是 OnCreateAndWrite，表示在创建和写入时更新，也可以设置为 OnReadAndWrite，表示在读取和写入时更新。</p><p>第三个是可见性，默认是 NeverReturnExpired，即不返回过期数据，也可以设置为 ReturnExpiredIfNotCleanedUp，表示会返回过期但未被清理的数据。</p><p>状态数据清理策略也分为两种：一种是做全量快照时进行清理，创建 ttl 时调用 cleanupFullSnapshot() 方法即可。</p><p>另一种是增量数据清理，在访问或处理状态时，状态后端保留一个所有状态的惰性迭代器，每次清理时选择已经过期的数据进行清理。设置方法时在创建 ttl 时调用 cleanupIncrementally(10, true) ，可以看到它提供两个参数，第一个参数是设置每次检查的条数，默认是5。第二个参数是是否在处理每条记录时都触发清理，默认是 false。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后我们来总结一下，本文我们主要介绍了 Flink 的状态及应用，首先介绍有状态计算的概念。接着重点学习了 Keyed State 和 Operator State。我们通过一个表格来进行总结。</p><table><thead><tr><th></th><th>Keyed State</th><th>Operator State</th></tr></thead><tbody><tr><td>使用算子类型</td><td>只能被用于 KeyedStream 中的Operator 上</td><td>可以被用于所有 Operator</td></tr><tr><td>状态分配</td><td>每个 Key 对应一个状态，单个 Operator 中可以包含多个 Key</td><td>单个 Operator 对应一个状态</td></tr><tr><td>创建和访问方式</td><td>重写 RichFunction，通过访问 RuntimeContext 对象获取</td><td>实现 CheckpointedFunction 或 ListCheckpointed 接口</td></tr><tr><td>横向拓展</td><td>状态随着 Key 自动在多个算子 Task 上迁移</td><td>有多种重新分配的方式：均匀分布。将所有状态合并再分发到每个实例上</td></tr><tr><td>支持数据类型</td><td>ValueState, ListState, ReducingState, AggregatingState, MapState</td><td>ListState, UnionListState, Broadcast State</td></tr></tbody></table><p>最后，我们又介绍了状态有效期的定义和使用方法。有了状态之后，Flink 就可以为我们提供非常强大的容错能力了，具体怎么做的我们后面再聊。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Flink 被广泛应用的原因，除了我们前面提到的对时间以及窗口的应用之外，另一点就是它强大的容错机制，以及对 Exactly Once 的支持。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：多流 Join</title>
    <link href="https://jackeyzhe.github.io/2025/07/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A4%9A%E6%B5%81join/"/>
    <id>https://jackeyzhe.github.io/2025/07/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A4%9A%E6%B5%81join/</id>
    <published>2025-07-18T17:36:58.000Z</published>
    <updated>2025-08-02T17:22:41.499Z</updated>
    
    <content type="html"><![CDATA[<p>前面我们已经了解了 Flink 几个核心概念，分别是时间、Watermark 已经窗口。今天我们来一起了解下 Flink 是怎么进行多个流的 Join 的。<span id="more"></span></p><p>我们今天从两个流的 Join 来入手，扩展到多个流也是一样的道理。Flink 中的 Join 可以分为两种：Window Join 和 Interval Join。</p><h3 id="Window-Join"><a href="#Window-Join" class="headerlink" title="Window Join"></a>Window Join</h3><p>Window Join 是将两个流中在相同窗口中且有相同 key 的元素进行关联。关联后，可以使用 JoinFunction 和 FlatJoinFunction 进行处理。Window Join 可以根据窗口类型分为三种：Tumbling Window Join、Sliding Window Join 和 Session Window Join。</p><h4 id="Tumbling-Window-Join"><a href="#Tumbling-Window-Join" class="headerlink" title="Tumbling Window Join"></a>Tumbling Window Join</h4><p>首先来看Tumbling Window Join，其实就是对应的使用滚动窗口进行 Join。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1754148421/Blog/flink/3/TumblingWindowJoin.png" alt="TumblingWindowJoin"> </p><p>具体使用方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Double&gt;&gt; result = source1.join(source2)</span><br><span class="line">        .where(record -&gt; record.f0)</span><br><span class="line">        .equalTo(record -&gt; record.f0)</span><br><span class="line">        .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">2L</span>)))</span><br><span class="line">        .apply(<span class="keyword">new</span> <span class="title class_">JoinFunction</span>&lt;Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> Tuple2&lt;String, Double&gt; <span class="title function_">join</span><span class="params">(Tuple2&lt;String, Double&gt; record1, Tuple2&lt;String, Double&gt; record2)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                <span class="keyword">return</span> Tuple2.of(record1.f0, record1.f1);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><p>其中 source1 和 source2 分别代表两个流，where 为 source1 的 join key 提取方法，equalTo 为 source2 的 join key 提取方法，最后，join 好之后的数据通过 JoinFunction 来处理。</p><h4 id="Sliding-Window-Join"><a href="#Sliding-Window-Join" class="headerlink" title="Sliding Window Join"></a>Sliding Window Join</h4><p>Sliding Window Join 和 Tumbling Window Join 的用法基本一致，只是将窗口指定为滑动窗口。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1754148862/Blog/flink/3/SlidingWindowJoin.png" alt="SlidingWindowJoin"></p><h4 id="Session-Window-Join"><a href="#Session-Window-Join" class="headerlink" title="Session Window Join"></a>Session Window Join</h4><p>Session Window Join 也类似，只是指定的窗口不同，具体的处理流程都是一样的，这里也不过多解释。</p><h3 id="Interval-Join"><a href="#Interval-Join" class="headerlink" title="Interval Join"></a>Interval Join</h3><p>Interval Join 是将两个流中 key 相同，且一个流的 timestamp 处于另一个流的 timestamp 上下波动范围内。</p><p>假设我们有两个流 a 和 b，Interval Join可以表达为<code>b.timestamp ∈ [a.timestamp + lowerBound; a.timestamp + upperBound]</code> 或 <code>a.timestamp + lowerBound &lt;= b.timestamp &lt;= a.timestamp + upperBound</code>。</p><p>需要注意的是，目前 Interval Join 仅支持 event time。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1754153595/Blog/flink/3/IntervalJoin.png" alt="IntervalJoin"></p><p>它的使用方法也很简单，只需要定义上下偏移量以及处理函数即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Double&gt;&gt; intervalJoinResult = source1.keyBy(record -&gt; record.f0)</span><br><span class="line">        .intervalJoin(source2.keyBy(record -&gt; record.f0))</span><br><span class="line">        .between(Time.seconds(-<span class="number">2</span>), Time.seconds(<span class="number">2</span>))</span><br><span class="line">        .process(<span class="keyword">new</span> <span class="title class_">ProcessJoinFunction</span>&lt;Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(Tuple2&lt;String, Double&gt; record1, Tuple2&lt;String, Double&gt; record2, ProcessJoinFunction&lt;Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;&gt;.Context context, Collector&lt;Tuple2&lt;String, Double&gt;&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">                out.collect(Tuple2.of(record1.f0, record1.f1 + record2.f1));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><h3 id="CoGroup"><a href="#CoGroup" class="headerlink" title="CoGroup"></a>CoGroup</h3><p>前面介绍的两种 Join 都是 inner join，那么 Flink 有没有办法支持 left join 呢？答案是肯定的，我们可以使用 coGroup 来实现。</p><p>coGroup 的通用用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stream.coGroup(otherStream)</span><br><span class="line">.where(&lt;KeySelector&gt;)</span><br><span class="line">.equalTo(&lt;KeySelector&gt;)</span><br><span class="line">.window(&lt;WindowAssigner&gt;)</span><br><span class="line">.apply(&lt;CoGroupFunction&gt;);</span><br></pre></td></tr></table></figure><p>我们通过自定义 CoGroupFunction 来实现 left join。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">LeftJoinFunction</span> <span class="keyword">implements</span> <span class="title class_">CoGroupFunction</span>&lt;Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;, Tuple2&lt;String, Double&gt;&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">coGroup</span><span class="params">(Iterable&lt;Tuple2&lt;String, Double&gt;&gt; iterable1, Iterable&lt;Tuple2&lt;String, Double&gt;&gt; iterable2, Collector&lt;Tuple2&lt;String, Double&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">for</span> (Tuple2&lt;String, Double&gt; record1 : iterable1) &#123;</span><br><span class="line">            <span class="type">boolean</span> <span class="variable">match</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">for</span> (Tuple2&lt;String, Double&gt; record2 : iterable2) &#123;</span><br><span class="line">                match = <span class="literal">true</span>;</span><br><span class="line">                collector.collect(Tuple2.of(record1.f0, record1.f1 + record2.f1));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (!match) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;没有join的元素 key:&quot;</span> + record1.f0);</span><br><span class="line">                collector.collect(Tuple2.of(record1.f0, record1.f1));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 coGroupFunction 中，需要实现 coGroup 方法，方法的参数包括两个输入流的 Iterable 和输出的 collector。如果第二个流中没有匹配的元素，那么就直接输出第一个流的元素。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后来总结一下，Flink 中有两种 Join 方法，分别为 Window Join 和 Interval Join，Window Join 是依赖窗口来执行，对窗口内的元素进行 join，Interval Join 不依赖窗口，是根据 event time 的范围来进行 join。最后还介绍了 CoGroup，我们可以使用 CoGroup 来实现 left join 和 right join。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;前面我们已经了解了 Flink 几个核心概念，分别是时间、Watermark 已经窗口。今天我们来一起了解下 Flink 是怎么进行多个流的 Join 的。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：窗口</title>
    <link href="https://jackeyzhe.github.io/2025/07/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%AA%97%E5%8F%A3/"/>
    <id>https://jackeyzhe.github.io/2025/07/19/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E7%AA%97%E5%8F%A3/</id>
    <published>2025-07-18T17:23:29.000Z</published>
    <updated>2025-07-18T17:26:38.649Z</updated>
    
    <content type="html"><![CDATA[<p>在前文中，我们已经了解了 Flink 时间和 Watermark 两个概念，今天就来聊一下 Flink 实时数据处理的另一个核心概念：窗口。<span id="more"></span></p><p>所谓窗口，可以理解为是对数据流中的一段数据进行处理的方法。那我们为什么需要窗口呢？在生产环境中，数据流中的数据往往是源源不断的，如果我们想要获取一段时间内数据的一些统计指标（最大值/最小值/平均值），这时就需要利用窗口来将数据收集起来，然后再进行计算。</p><p>如果按照处理的数据流的类型来划分，Flink 中的窗口可以分为 Keyed Window 和 Non-Keyed Window，其中 Keyed Window 是用来处理按照 key 分片之后的数据流，也就是需要先调用 keyBy 方法，再调用 window 方法。而 Non-Keyed Window 处理的则是未按照 key 分片的数据流，在使用的时候直接调用 windowAll 方法。</p><p>在官方文档中，列举了两种窗口的使用方法。</p><p><strong>Keyed Window</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">       .keyBy(...)               &lt;-  仅 keyed 窗口需要</span><br><span class="line">       .window(...)              &lt;-  必填项：<span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  可选项：<span class="string">&quot;trigger&quot;</span> (省略则使用默认 trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  可选项：<span class="string">&quot;evictor&quot;</span> (省略则不使用 evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  可选项：<span class="string">&quot;lateness&quot;</span> (省略则为 <span class="number">0</span>)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  可选项：<span class="string">&quot;output tag&quot;</span> (省略则不对迟到数据使用 side output)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  必填项：<span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  可选项：<span class="string">&quot;output tag&quot;</span></span><br></pre></td></tr></table></figure><p><strong>Non-Keyed Window</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">stream</span><br><span class="line">       .windowAll(...)           &lt;-  必填项：<span class="string">&quot;assigner&quot;</span></span><br><span class="line">      [.trigger(...)]            &lt;-  可选项：<span class="string">&quot;trigger&quot;</span> (<span class="keyword">else</span> <span class="keyword">default</span> trigger)</span><br><span class="line">      [.evictor(...)]            &lt;-  可选项：<span class="string">&quot;evictor&quot;</span> (<span class="keyword">else</span> no evictor)</span><br><span class="line">      [.allowedLateness(...)]    &lt;-  可选项：<span class="string">&quot;lateness&quot;</span> (<span class="keyword">else</span> zero)</span><br><span class="line">      [.sideOutputLateData(...)] &lt;-  可选项：<span class="string">&quot;output tag&quot;</span> (<span class="keyword">else</span> no side output <span class="keyword">for</span> late data)</span><br><span class="line">       .reduce/aggregate/apply()      &lt;-  必填项：<span class="string">&quot;function&quot;</span></span><br><span class="line">      [.getSideOutput(...)]      &lt;-  可选项：<span class="string">&quot;output tag&quot;</span></span><br></pre></td></tr></table></figure><h3 id="窗口分类"><a href="#窗口分类" class="headerlink" title="窗口分类"></a>窗口分类</h3><p>在上面的示例中，调用 window 和 windowAll 方法时，需要传入 assigner 参数，Window Assigner 是用来定义如何将数据流中的元素划分到各个窗口中。</p><p>下面我们再对窗口进行一次分类，首先是根据划分依据，可以分为 time window 和 count window，time window 是根据处理数据的时间来划分，count window 则是根据处理数据的数量来划分。接着，我们再根据划分规则来分类，这里又可以将窗口分为滚动窗口（Tumbling Windows）、滑动窗口（Sliding Windows）、会话窗口（Session Windows）和全局窗口（Global Windows），需要注意的是，后面两种窗口不支持 count window。我们用一张图来表示窗口的分类会更加清晰。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1752334267/Blog/flink/2/windows_1.png" alt="窗口分类"></p><p>我们在日常数据处理中，最常用的就是时间窗口，接下来就来详细了解下时间窗口的四种类型。</p><h4 id="Sliding-Windows"><a href="#Sliding-Windows" class="headerlink" title="Sliding Windows"></a>Sliding Windows</h4><p>滑动窗口是以一个固定的步长不断向前滑动的窗口，滑动过程中，窗口的大小是保持不变的。在滑动窗口中，一个元素是可以被多个窗口计算的。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1752599153/Blog/flink/2/sliding_window.png" alt="sliding_window"></p><p>在代码中，可以通过 SlidingEventTimeWindows 类来定义滑动窗口，具体使用方法可以参考下面这个简单的 demo（这里多说一句，旧版本 Flink 传的是参数是 Time，新版本传的是 Duration）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滑动 event-time 窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingEventTimeWindows.of(Duration.ofSeconds(<span class="number">10</span>), Duration.ofSeconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滑动 processing-time 窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingProcessingTimeWindows.of(Duration.ofSeconds(<span class="number">10</span>), Duration.ofSeconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滑动 processing-time 窗口，偏移量为 -8 小时</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(SlidingProcessingTimeWindows.of(Duration.ofHours(<span class="number">12</span>), Duration.ofHours(<span class="number">1</span>), Duration.ofHours(-<span class="number">8</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure><p>上面代码中，如果不传 offset 参数的话，窗口开始时间会和 Linux 的 epoch 对齐，如果想要一些偏移量的话，就可以通过 offset 参数来控制（第二种方法）。在 demo 中，偏移量设置为 -8 小时，也就是使用东 8 区时间。</p><h4 id="Tumbling-Windows"><a href="#Tumbling-Windows" class="headerlink" title="Tumbling Windows"></a>Tumbling Windows</h4><p>了解了滑动窗口之后，我们再来看滚动窗口。滚动窗口可以认为是一种特殊的滑动窗口（Window Size = Window Slide）。滚动窗口之间是没有重叠的，也就是说，每个元素只能落到一个窗口中。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1752600673/Blog/flink/2/Tumbling_Window.png" alt="tumbling_window"></p><p>在代码中通过使用 TumblingEventTimeWindows 来定义。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滚动 event-time 窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Duration.ofSeconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滚动 processing-time 窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingProcessingTimeWindows.of(Duration.ofSeconds(<span class="number">5</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 长度为一天的滚动 event-time 窗口， 偏移量为 -8 小时。</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(TumblingEventTimeWindows.of(Duration.ofDays(<span class="number">1</span>), Duration.ofHours(-<span class="number">8</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure><h4 id="Session-Windows"><a href="#Session-Windows" class="headerlink" title="Session Windows"></a>Session Windows</h4><p>会话窗口和前两种不同，它的窗口大小是不固定的，也没有固定的开始和结束时间。当一个窗口超过 Seesion gap 没有收到数据之后，窗口就会关闭。Flink 也支持动态定义判断会话窗口不活跃的条件。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1752682681/Blog/flink/2/session_window.png" alt="session_window"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;T&gt; input = ...;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置了固定间隔的 event-time 会话窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withGap(Duration.ofMinutes(<span class="number">10</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置了动态间隔的 event-time 会话窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(EventTimeSessionWindows.withDynamicGap((element) -&gt; &#123;</span><br><span class="line">        <span class="comment">// 决定并返回会话间隔</span></span><br><span class="line">    &#125;))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置了固定间隔的 processing-time session 窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(ProcessingTimeSessionWindows.withGap(Duration.ofMinutes(<span class="number">10</span>)))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置了动态间隔的 processing-time 会话窗口</span></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(ProcessingTimeSessionWindows.withDynamicGap((element) -&gt; &#123;</span><br><span class="line">        <span class="comment">// 决定并返回会话间隔</span></span><br><span class="line">    &#125;))</span><br><span class="line">    .&lt;windowed transformation&gt;(&lt;window function&gt;);</span><br></pre></td></tr></table></figure><h4 id="Global-Windows"><a href="#Global-Windows" class="headerlink" title="Global Windows"></a>Global Windows</h4><p>最后是全局窗口，它将所有的key都写到一个窗口，并且必须要指定 trigger 才能触发窗口的计算。</p><h3 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h3><p>现在我们已经知道如何划分窗口，或者说如何把指定元素放入对应的窗口中了。接下来的问题就是窗口中的数据要怎么处理。这就是窗口函数的职责了。Flink 支持三种窗口函数，分别是：ReduceFunction、AggregateFunction 和 ProcessWindowFunction。</p><h4 id="ReduceFunction"><a href="#ReduceFunction" class="headerlink" title="ReduceFunction"></a>ReduceFunction</h4><p>ReduceFunction 定义了如何把两条数据合并为一条。例如最常见的对 key 进行求和。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(&lt;window assigner&gt;)</span><br><span class="line">    .reduce(<span class="keyword">new</span> <span class="title class_">ReduceFunction</span>&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">      <span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title function_">reduce</span><span class="params">(Tuple2&lt;String, Long&gt; v1, Tuple2&lt;String, Long&gt; v2)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(v1.f0, v1.f1 + v2.f1);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>窗口输出的数据就是将多条相同 key 的数据求和后的数据。</p><h4 id="AggregateFunction"><a href="#AggregateFunction" class="headerlink" title="AggregateFunction"></a>AggregateFunction</h4><p>ReduceFunction 其实是一种特殊的 AggregateFunction，AggregateFunction 的定义更加宽泛。它接收三个类型：IN（输入数据的类型）、ACC（累加器的类型）、OUT（输出数据的类型）。同时定义了四个方法：createAccumulator（创建一个累加器）、add（将一条数据加进累加器）、getResult（获取累加器结果）、merge（将两个累加器合并）</p><p>下面这个例子展示了如何对输入数据进行求平均值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">AverageAggregate</span></span><br><span class="line">    <span class="keyword">implements</span> <span class="title class_">AggregateFunction</span>&lt;Tuple2&lt;String, Long&gt;, Tuple2&lt;Long, Long&gt;, Double&gt; &#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">createAccumulator</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(<span class="number">0L</span>, <span class="number">0L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">add</span><span class="params">(Tuple2&lt;String, Long&gt; value, Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(accumulator.f0 + value.f1, accumulator.f1 + <span class="number">1L</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Double <span class="title function_">getResult</span><span class="params">(Tuple2&lt;Long, Long&gt; accumulator)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> ((<span class="type">double</span>) accumulator.f0) / accumulator.f1;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> Tuple2&lt;Long, Long&gt; <span class="title function_">merge</span><span class="params">(Tuple2&lt;Long, Long&gt; a, Tuple2&lt;Long, Long&gt; b)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(a.f0 + b.f0, a.f1 + b.f1);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DataStream&lt;Tuple2&lt;String, Long&gt;&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">    .keyBy(&lt;key selector&gt;)</span><br><span class="line">    .window(&lt;window assigner&gt;)</span><br><span class="line">    .aggregate(<span class="keyword">new</span> <span class="title class_">AverageAggregate</span>());</span><br></pre></td></tr></table></figure><h4 id="ProcessWindowFunction"><a href="#ProcessWindowFunction" class="headerlink" title="ProcessWindowFunction"></a>ProcessWindowFunction</h4><p>ProcessWindowFunction 执行效率不如前两者，因为它要获取窗口内所有的数据进行计算。但它也有另外两个窗口没有的能力，那就是在 ProcessWindowFunction 中可以通过 Context 获取到时间和状态信息。这样的能力带来的代价是大量的资源消耗，因此，为了减少不必要的资源消耗，我们通常将 ProcessWindowFunction 与 ReduceFunction 或 AggregateFunction 配合使用。我们来看一个例子。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;SensorReading&gt; input = ...;</span><br><span class="line"></span><br><span class="line">input</span><br><span class="line">  .keyBy(&lt;key selector&gt;)</span><br><span class="line">  .window(&lt;window assigner&gt;)</span><br><span class="line">  .reduce(<span class="keyword">new</span> <span class="title class_">MyReduceFunction</span>(), <span class="keyword">new</span> <span class="title class_">MyProcessWindowFunction</span>());</span><br><span class="line"></span><br><span class="line"><span class="comment">// Function definitions</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyReduceFunction</span> <span class="keyword">implements</span> <span class="title class_">ReduceFunction</span>&lt;SensorReading&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> SensorReading <span class="title function_">reduce</span><span class="params">(SensorReading r1, SensorReading r2)</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> r1.value() &gt; r2.value() ? r2 : r1;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">MyProcessWindowFunction</span></span><br><span class="line">    <span class="keyword">extends</span> <span class="title class_">ProcessWindowFunction</span>&lt;SensorReading, Tuple2&lt;Long, SensorReading&gt;, String, TimeWindow&gt; &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(String key,</span></span><br><span class="line"><span class="params">                    Context context,</span></span><br><span class="line"><span class="params">                    Iterable&lt;SensorReading&gt; minReadings,</span></span><br><span class="line"><span class="params">                    Collector&lt;Tuple2&lt;Long, SensorReading&gt;&gt; out)</span> &#123;</span><br><span class="line">      <span class="type">SensorReading</span> <span class="variable">min</span> <span class="operator">=</span> minReadings.iterator().next();</span><br><span class="line">      out.collect(<span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Long, SensorReading&gt;(context.window().getStart(), min));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中，我们返回了窗口中最小的元素和窗口的开始时间。因为我们先做了聚合，所以在 ProcessFunction 中就不用把所有的数据都存储在 State 中，而是只存储聚合后的数据即可。</p><h3 id="Triggers"><a href="#Triggers" class="headerlink" title="Triggers"></a>Triggers</h3><p>Trigger 决定何时触发窗口计算，每个 Window Assigner 都有一个默认的 trigger。当然，Flink 也提供自定义 trigger，自定义 trigger 只需要实现 Trigger 接口，并且在 .trigger() 方法中调用即可（在文章开头的示例中提到过）。</p><p>Trigger 接口提供了 5 个方法，分别是：</p><ul><li><p>onElement() 方法在接收到元素时调用</p></li><li><p>onProcessingTime() 方法是在一个基于 ProcessTime 的 timer 触发时调用</p></li><li><p>onEventTime() 方法是在一个基于 EventTime 的 timer 触发时调用</p></li><li><p>onMerge() 方法在多个窗口合并时调用</p></li><li><p>clear() 方法是在窗口被移除时调用</p></li></ul><p>前三个方法都会返回一个 TriggerResult，而这个 TriggerResult 的值就决定了窗口是否触发。TriggerResult 的值有以下四种：</p><ul><li><p>CONTINUE：什么也不做</p></li><li><p>FIRE_AND_PURGE：触发计算并清空窗口内的元素</p></li><li><p>FIRE：只触发计算，不清空窗口内元素</p></li><li><p>PURGE：清空窗口内元素</p></li></ul><p>Flink 内置了多个 trigger，常见的有 EventTimeTrigger、ProcessingTimeTrigger、CountTrigger 和 PurgingTrigger。</p><h3 id="Evictors"><a href="#Evictors" class="headerlink" title="Evictors"></a>Evictors</h3><p>Evictor 可以用于在 trigger 触发后、调用窗口函数之前或之后删除窗口内的元素。Evictor 接口提供了两个方法：</p><ul><li><p>evictBefore() 方法是在调用窗口函数之前调用</p></li><li><p>evictAfter() 方法是在调用窗口函数之后调用</p></li></ul><p>Flink 内置了三种 Evictor：</p><ul><li><p>CountEvictor：记录用户设置的最大元素数量，当窗口内元素数量大于最大元素数量时，删除开头的元素</p></li><li><p>DeltaEvictor：用户需要设置计算差值的方法，evictor 会计算最后一个元素与窗口内每个元素的差值差值，并将大于用户设置的 threshold 的元素删除</p></li><li><p>TimeEvictor：用户需要指定窗口大小 windowSize，evictor 会计算窗口内元素最大的时间戳 maxTimestamp，将时间戳小于等于 maxTimestamp - windowSize 的元素清除</p></li></ul><p>关于 Trigger 和 Evictor，只看概念可能还比较迷惑。我们来看一个具体的例子：假设我们需要一个实时监控系统，当连续收到 5 个大于阈值的数据时，发送告警。最终窗口中只保留 10 条数据。</p><p>trigger 的实现应该是</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> TriggerResult <span class="title function_">onElement</span><span class="params">(Tuple2&lt;String, Double&gt; item, <span class="type">long</span> l, TimeWindow timeWindow, TriggerContext triggerContext)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">    ValueState&lt;Integer&gt; state = triggerContext.getPartitionedState(<span class="keyword">new</span> <span class="title class_">ValueStateDescriptor</span>&lt;&gt;(stateName, Integer.class, <span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (item.f1 &gt; threshold) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> state.value() + <span class="number">1</span>;</span><br><span class="line">        state.update(count);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (count &gt;= countThreshold) &#123;</span><br><span class="line">            state.clear();</span><br><span class="line">            <span class="keyword">return</span> TriggerResult.FIRE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        state.clear();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> TriggerResult.CONTINUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>evictor 的实现为</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">evictAfter</span><span class="params">(Iterable&lt;TimestampedValue&lt;Tuple2&lt;String, Double&gt;&gt;&gt; elements, <span class="type">int</span> size, TimeWindow timeWindow, EvictorContext evictorContext)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (size &lt;= maxSize) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;TimestampedValue&lt;Tuple2&lt;String, Double&gt;&gt;&gt; elementList = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;();</span><br><span class="line">    elements.forEach(elementList::add);</span><br><span class="line">    <span class="type">int</span> <span class="variable">toEvict</span> <span class="operator">=</span> size - maxSize;</span><br><span class="line">    List&lt;TimestampedValue&lt;Tuple2&lt;String, Double&gt;&gt;&gt; toRemove = elementList.subList(maxSize, size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 通过迭代器删除需要移除的元素（关键：遍历原始迭代器，匹配并删除）</span></span><br><span class="line">    Iterator&lt;TimestampedValue&lt;Tuple2&lt;String, Double&gt;&gt;&gt; iterator = elements.iterator();</span><br><span class="line">    <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">        TimestampedValue&lt;Tuple2&lt;String, Double&gt;&gt; element = iterator.next();</span><br><span class="line">        <span class="keyword">if</span> (toRemove.contains(element)) &#123; <span class="comment">// 匹配需要删除的元素</span></span><br><span class="line">            iterator.remove(); <span class="comment">// 实际删除</span></span><br><span class="line">            toEvict--;</span><br><span class="line">            <span class="keyword">if</span> (toEvict &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;Evictor finished: 保留了 &quot;</span> + maxSize + <span class="string">&quot; 个元素&quot;</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完整代码我放到 <a href="https://github.com/Jackeyzhe/flink-training/blob/feature/wz-demo/common/src/main/java/org/apache/flink/training/examples/trigger/TriggerAndEvictorDemo.java">GitHub</a> 了，感兴趣的可以看一下。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后总结一下，今天我们了解了 Flink 中窗口相关的概念，首先是窗口分类，然后是 Window Assginer（分别介绍了滑动窗口、滚动窗口、会话窗口和全局窗口）。接着又了解窗口处理函数，即怎么计算窗口中的数据。最后学习的 trigger 和 evictor 的作用和用法。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在前文中，我们已经了解了 Flink 时间和 Watermark 两个概念，今天就来聊一下 Flink 实时数据处理的另一个核心概念：窗口。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：时间与Watermark</title>
    <link href="https://jackeyzhe.github.io/2025/06/30/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E4%B8%8EWatermark/"/>
    <id>https://jackeyzhe.github.io/2025/06/30/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%97%B6%E9%97%B4%E4%B8%8EWatermark/</id>
    <published>2025-06-30T14:58:16.000Z</published>
    <updated>2025-07-15T15:23:49.476Z</updated>
    
    <content type="html"><![CDATA[<p>在前文中，我学习 Flink 的整体架构，接下来的几篇文章，我将重点学习一下 Flink 的几个核心概念。包括时间属性、Watermark、窗口、状态以及容错机制。今天就来学习时间属性和 Watermark。<span id="more"></span></p><h3 id="时间属性"><a href="#时间属性" class="headerlink" title="时间属性"></a>时间属性</h3><p>首先来学习 Flink 的时间属性，作为流处理引擎，时间是实时数据处理的重要依赖，特别是在做时序分析或者特定时间段数据处理时，时间的概念更显得尤为重要。</p><p>Flink 中支持三种时间属性，分别是：</p><ul><li><p>EventTime：事件时间，即为事件产生的时间。</p></li><li><p>ProcessTime：处理时间，Flink 算子处理事件的时间。</p></li><li><p>IngestionTime：摄入时间，Flink 读取事件的时间。</p></li></ul><p>这样描述可能比较抽象，我们通过一张图来看一下。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1750094745/Blog/flink/1/flink_time.png" alt="FlinkTime"></p><p>从上图中可以看出，在时间产生/存储时，记录一个设备时间，就是 Event Time。当 Flink 的 DataSource 读取到事件时，这时再记录一个时间，这就是 Ingestion Time。在 Flink 程序中，每个算子处理事件时，又会记录一个时间，这个时间就是 Process Time。</p><h3 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h3><p>介绍完了时间概念，再来看下 Watermark 的概念。它是 Flink 处理迟到事件的妙招。</p><p>Watermark 本身也属于一种特殊的事件，它由 Source 生成，同时携带由 Timestamp，并且会跟随正常的事件一起在 Flink 算子之间流转。Watermark 的作用是定义何时停止等待较早的事件。这么介绍可能比较抽象，下面我们通过一些具体的例子来进行更进一步的说明。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1751033706/Blog/flink/1/watermark.png" alt="watermark"></p><p>上图代表的是一段乱序的事件数据流。假设我们定义 maxOutOfOrderness 为4，也就是容忍最大迟到时间为4（这里不带具体时间单位，可能是4秒也可能是4分钟）。当我们收到时间戳为7的事件时，就会生成一个时间为3的 Watermark。这代表着3之前的数据都已就绪。如果此时再有小于3的数据，我们认为它是迟到数据。</p><p>而对于迟到的数据，通常有三种处理方法：</p><ul><li><p>重新开启已经关闭的窗口，重新计算并修正结果</p></li><li><p>将迟到事件使用旁路输出收集起来单独处理</p></li><li><p>将迟到事件视为错误消息丢弃</p></li></ul><p>在 Flink 中 Watermark 本身是没有意义的，它的主要作用是作为窗口的触发条件。窗口可以认为是一个时间段，它有开始时间和结束时间。在窗口内可以计算一批事件的统计结果。关于窗口，我们后面再做详细介绍。</p><p>那么 Watermark 是如何触发窗口的呢？答案是必须要满足以下两个条件：</p><ol><li><p>Watermark 的时间戳 &gt;= 窗口的 end_time</p></li><li><p>窗口中有数据</p></li></ol><p>从概念上看还是比较抽象，我们还用上面的数据流作为例子，Watermark 设置为最大时间减 4，假设我们设置10秒一个窗口。关键代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">***</span><br><span class="line">SingleOutputStreamOperator&lt;Event&gt; withTimestampsAndWatermarks = source</span><br><span class="line">                .assignTimestampsAndWatermarks(</span><br><span class="line">                        WatermarkStrategy.forGenerator(ctx -&gt; <span class="keyword">new</span> <span class="title class_">CustomWatermarkGenerator</span>())</span><br><span class="line">                                .withTimestampAssigner(((event, l) -&gt; event.timestamp))</span><br><span class="line">                );</span><br><span class="line"></span><br><span class="line">OutputTag&lt;Event&gt; lateTag = <span class="keyword">new</span> <span class="title class_">OutputTag</span>&lt;Event&gt;(<span class="string">&quot;late-tag&quot;</span>) &#123;&#125;;</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;String&gt; windowResult = withTimestampsAndWatermarks</span><br><span class="line">        .keyBy(event -&gt; event.num)</span><br><span class="line">        .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">10</span>)))</span><br><span class="line">        .sideOutputLateData(lateTag)</span><br><span class="line">        .process(<span class="keyword">new</span> <span class="title class_">ProcessWindowFunction</span>&lt;Event, String, Long, TimeWindow&gt;() &#123;</span><br><span class="line">         <span class="meta">@Override</span></span><br><span class="line">         <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">process</span><span class="params">(Long key, Context context, Iterable&lt;Event&gt; elements, Collector&lt;String&gt; out)</span> &#123;</span><br><span class="line">             <span class="comment">// 一些逻辑处理</span></span><br><span class="line">             out.collect(result);</span><br><span class="line">         &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 处理迟到数据</span></span><br><span class="line">DataStream&lt;Event&gt; lateStream = windowResult.getSideOutput(lateTag);</span><br><span class="line">lateStream.process(<span class="keyword">new</span> <span class="title class_">ProcessFunction</span>&lt;Event, String&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">processElement</span><span class="params">(Event event, Context ctx, Collector&lt;String&gt; out)</span> &#123;</span><br><span class="line">        out.collect(<span class="string">&quot;迟到事件: &quot;</span> + event);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).print();</span><br><span class="line">***</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">***</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(Event event, <span class="type">long</span> l, WatermarkOutput watermarkOutput)</span> &#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">eventTime</span> <span class="operator">=</span> event.timestamp;</span><br><span class="line">    <span class="comment">// 使用CAS确保线程安全</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">current</span> <span class="operator">=</span> currentMaxTime.get();</span><br><span class="line">        <span class="keyword">if</span> (eventTime &lt;= current) <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">if</span> (currentMaxTime.compareAndSet(current, eventTime)) <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onPeriodicEmit</span><span class="params">(WatermarkOutput watermarkOutput)</span> &#123;</span><br><span class="line">    watermarkOutput.emitWatermark(<span class="keyword">new</span> <span class="title class_">Watermark</span>(currentMaxTime.get() - timeDiff));</span><br><span class="line">&#125;</span><br><span class="line">***</span><br></pre></td></tr></table></figure><p><a href="https://github.com/Jackeyzhe/flink-training/blob/feature/wz-demo/common/src/main/java/org/apache/flink/training/examples/watermark/WatermarkDemo.java">完整代码我放在 github 上了</a></p><p>当我们输入测试数据时</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4</span>,<span class="number">1750867204000</span></span><br><span class="line"><span class="number">2</span>,<span class="number">1750867202000</span></span><br><span class="line"><span class="number">7</span>,<span class="number">1750867207000</span></span><br><span class="line"><span class="number">10</span>,<span class="number">1750867210000</span></span><br><span class="line"><span class="number">9</span>,<span class="number">1750867209000</span></span><br><span class="line"><span class="number">15</span>,<span class="number">1750867215000</span></span><br><span class="line"><span class="number">12</span>,<span class="number">1750867212000</span></span><br><span class="line"><span class="number">13</span>,<span class="number">1750867213000</span></span><br><span class="line"><span class="number">25</span>,<span class="number">1750867225000</span></span><br><span class="line"><span class="number">14</span>,<span class="number">1750867214000</span></span><br><span class="line"><span class="number">35</span>,<span class="number">1750867235000</span></span><br></pre></td></tr></table></figure><p>可以看到如下输出：</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1751035105/Blog/flink/1/%E6%88%AA%E5%B1%8F2025-06-27_22.35.50.png" alt="print"></p><p>通过输出的日志，我们可以看出，当watermark推进到大于等于时间窗口的结束时间时，窗口就会完成计算并关闭。而对于迟到的数据，我们可以通过侧输出流单独处理，也可以通过设置<code>allowedLateness</code>，使窗口重新打开。</p><h3 id="生成-Watermark"><a href="#生成-Watermark" class="headerlink" title="生成 Watermark"></a>生成 Watermark</h3><p>了解了 Watermark 的原理之后，我们再来看一下如何生成 Watermark。在 Flink 中，需要使用 WatermarkStrategy 来定义如何生成时间戳和 watermark。WatermarkStrategy 继承了 TimestampAssignerSupplier 和 WatermarkGeneratorSupplier 两个接口，其中 TimestampAssignerSupplier 定义了抽取 EventTime 的方法，而 WatermarkGeneratorSupplier 则是定义了如何生成 Watermark 的方法。</p><h4 id="Flink-内置的-Watermark-生成器"><a href="#Flink-内置的-Watermark-生成器" class="headerlink" title="Flink 内置的 Watermark 生成器"></a>Flink 内置的 Watermark 生成器</h4><p>Flink 中内置了两个 watermark 生成器。分别是 AscendingTimestampsWatermarks 和 BoundedOutOfOrdernessWatermarks。</p><p>我们先来看 BoundedOutOfOrdernessWatermarks，它定义了一个 watermark 滞后于最大事件时间一个固定值的 watermark 生成器。在使用时，可以给定一个时间，这样 Flink 就会 根据最大的 eventTime 来周期性的生成 watermark，例如，我们前面定义的 watermark 滞后4秒，就可以写成：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(<span class="number">4</span>));</span><br></pre></td></tr></table></figure><p>AscendingTimestampsWatermarks 是单调递增时间分配器，也就是只处理有序的数据，它继承了 BoundedOutOfOrdernessWatermarks，并且最大容忍时间为0。在使用时，可以直接通过以下方法生成：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WatermarkStrategy.forMonotonousTimestamps();</span><br></pre></td></tr></table></figure><h4 id="自定义-WatermarkGenerator"><a href="#自定义-WatermarkGenerator" class="headerlink" title="自定义 WatermarkGenerator"></a>自定义 WatermarkGenerator</h4><p>除了上面两个内置的 WatermarkGenerator 外，我们还可以自定义，实现起来也比较简单。只需要实现 WatermarkGenerator 接口并重写 onEvent 和 onPeriodicEmit 两个方法即可。onEvent 是每个事件到来时调用一次，可以用来记录最大事件时间。onPeriodicEmit 则是周期性调用，可以生成 watermark。在前面的例子中，我使用的 CustomWatermarkGenerator 就是自定义的 watermark，对应的实现也在前文中贴了。</p><h3 id="如何处理空闲数据源"><a href="#如何处理空闲数据源" class="headerlink" title="如何处理空闲数据源"></a>如何处理空闲数据源</h3><p>最后，再补充一个与 watermark 相关的比较重要的特性。在 Flink 中，会有一些算子有多个输入源。这时，这个算子的 watermark 是以它收到的数据源中最小的 eventTime 来计算的。直接看官网的例子：</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1752592909/Blog/flink/1/parallel_streams_watermarks.png" alt="parallel_streams_watermarks"></p><p>那么这里就存在一个问题：如果一个输入源数据量很少，很久才发一条消息，而另一个数据源发了很多消息，那么就会在下游算子中积累很多消息等待处理，这对于整个系统的稳定性造成了很大的风险。</p><p>那这种情况有办法处理吗？答案是肯定的，Flink 提供了 withIdleness 方法，它可以用来检测空闲数据源，如果超过一定时间没有数据到来，Flink 认为这个数据源属于空闲数据源，这时就不会再阻塞下游算子触发窗口。达到定期处理数据的目的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>今天我们先了解了 Flink 中时间的概念，EventTime 是事件产生的时间，通常由上游数据源生成，ProcessTime 是处理时间，通常由处理算子本身生成，IngestionTime是摄入时间，通常由 Flink 的 Source 生成。</p><p>接着我们由了解了 Flink 的 watermark，它是窗口触发的条件，在处理迟到数据时发挥着重要的作用。我们可以定义可以容忍的最大迟到时间，这样当遇到乱序数据时也可以得到正确的结果。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;在前文中，我学习 Flink 的整体架构，接下来的几篇文章，我将重点学习一下 Flink 的几个核心概念。包括时间属性、Watermark、窗口、状态以及容错机制。今天就来学习时间属性和 Watermark。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Flink学习笔记：整体架构</title>
    <link href="https://jackeyzhe.github.io/2025/06/09/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/"/>
    <id>https://jackeyzhe.github.io/2025/06/09/Flink%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/</id>
    <published>2025-06-09T03:31:31.000Z</published>
    <updated>2025-06-11T13:14:07.240Z</updated>
    
    <content type="html"><![CDATA[<p>开一个新坑，系统性的学习下 Flink，计划从整体架构到核心概念再到调优方法，最后是相关源码的阅读。<span id="more"></span></p><!-- more --><p>今天就来学习 Flink 整体架构，我们先看官网的架构图</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1647276646/Blog/flink/0/flink0_0.png" alt="Flink Architecture"></p><p>图中包含三部分，分别是 Client、JobManager 和 TaskManager。其中 Client 并不属于 Flink 集群，它主要用来把用户编写的程序翻译成 StreamGraph 然后优化成 JobGraph，再将 JobGraph 提交到 Flink 集群执行。</p><h3 id="JobManager"><a href="#JobManager" class="headerlink" title="JobManager"></a>JobManager</h3><p>Flink 集群的 JobManager 是用来接收 Client 提交的任务，并且分发给 TaskManager 去执行。此外，JobManager 还有一些其他的职责，例如任务调度，协调 checkpoint 和协调从失败中恢复。</p><p>每个 Flink 集群至少要有一个 JobManager，但在生产环境中通常是高可用模式部署，即部署多台 JobManager，其中一台作为 Leader，其他的作为 Standby 节点。当 Leader 挂掉时，其他的 Standby 节点会有一台被选举为新的 Leader 提供服务。这样就能避免 JobManager 单机故障影响到整个 Flink 集群的可用性。</p><p>JobManager 主要由以下几部分组成，下面我们分别来看每部分的作用。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1749308494/Blog/flink/0/JobManager.png" alt="JobManager"></p><h4 id="DataFlow-Graph"><a href="#DataFlow-Graph" class="headerlink" title="DataFlow Graph"></a>DataFlow Graph</h4><p>JobManager 收到 JobGraph 之后，根据并行度的设置，将各个算子任务拆分成并行的子任务，最终生成 ExecutionGraph。</p><h4 id="Checkpoint-coordinator"><a href="#Checkpoint-coordinator" class="headerlink" title="Checkpoint coordinator"></a>Checkpoint coordinator</h4><p>Checkpoint 是 Flink 最核心的概念之一，Flink 的容错机制主要靠 checkpoint 来保障。而 checkpoint 的生成会恢复则由 checkpoint coordinator 来负责。</p><h4 id="Job-Dispatch"><a href="#Job-Dispatch" class="headerlink" title="Job Dispatch"></a>Job Dispatch</h4><p>Job Dispatch 提供了 REST 接口用于提交 Flink 任务，并为每个任务启动一个 JobMaster。JobMaster 负责管理单个 JobGraph 的执行。</p><h4 id="Task-Scheduling"><a href="#Task-Scheduling" class="headerlink" title="Task Scheduling"></a>Task Scheduling</h4><p>Task Scheduling 负责 Task 部署和调度，值得一提的是，JobManager 和 TaskManager 以及 Client 之间的通信都是通过一个叫 Actor System 的 RPC 系统实现的。</p><h4 id="Resource-Manager"><a href="#Resource-Manager" class="headerlink" title="Resource Manager"></a>Resource Manager</h4><p>Resource Manager 负责集群中的资源的分配回收，它管理的资源单元叫做 task slot，对于不同的部署环境，Resource Manager 有不同的实现，</p><h4 id="Actor-System"><a href="#Actor-System" class="headerlink" title="Actor System"></a>Actor System</h4><p>Actor System 是 Flink 集群中的一种 RPC 通信的组件，JobManager 和 TaskManager 以及 Client 之间的通信都是基于 Actor System 的。而 TaskManager 之间的数据传递是基于 Netty 的。</p><h3 id="TaskManager"><a href="#TaskManager" class="headerlink" title="TaskManager"></a>TaskManager</h3><p>聊完了 JobManager，我们再来看下 TaskManager 的结构。TaskManager 主要负责执行作业的 task，并缓存和交换数据流。TaskManager 中最小的资源调度单位是 task slot，这点在前面介绍 Resource Manager 时也提到过。它表示并发处理 task 的数量。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1749399164/Blog/flink/0/TaskManager.png" alt="TaskManager"></p><h4 id="Task-Execution"><a href="#Task-Execution" class="headerlink" title="Task Execution"></a>Task Execution</h4><p>TaskManager 在接到 JobManager 部署的任务后，就会申请相应的 task slot 去执行任务。</p><h4 id="Data-Exchange"><a href="#Data-Exchange" class="headerlink" title="Data Exchange"></a>Data Exchange</h4><p>Data Execution 主要负责 TaskManager 之间的数据交互的一些操作，这里主要关注逻辑层面，例如一些 shuffle 操作。而网络传输则主要是由 Network Manager 来实现。</p><h4 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h4><p>Memory Management 负责 TaskManager 的内存管理，在执行任务过程中，接收到的一些数据是需要放在内存中进行处理的。相应的内存管理操作依赖于 Memory Management 模块。</p><h4 id="Actor-System-1"><a href="#Actor-System-1" class="headerlink" title="Actor System"></a>Actor System</h4><p>Actor System 我们在前面提到过，TaskManager 和 JobManager 之间的通信全靠它。</p><h4 id="Network-Manager"><a href="#Network-Manager" class="headerlink" title="Network Manager"></a>Network Manager</h4><p>Network Manager 主要负责 TaskManager 之间的数据交互，它是基于 Netty 实现的。</p><p>最后多提一个 Graph 的概念，前面我们已经了解到了 JobManager 会将 JobGraph 根据并行度的配置转换成 ExecutionGraph。在这之后，JobManager 会对作业进行调度，将 task 部署到各个 TaskManager 上，最终就形成了物理执行图，也就是 PhysicalGraph。</p><p>这里小结一下，Flink 中四种图的生成顺序是：用户编写的代码生成 StreamGraph，Client 将其进行优化，主要是将多个符合条件的节点 chain 在一起，生成了 JobGraph，然后将 JobGraph 提交到 JobManager，再由 JobManager 生成并行版本的 ExecutionGraph，待JobManager 将 task 调度后，生成的图被称为 PhysicalGraph。</p><h3 id="Flink-的几种部署模式"><a href="#Flink-的几种部署模式" class="headerlink" title="Flink 的几种部署模式"></a>Flink 的几种部署模式</h3><p>根据集群的生命周期、资源隔离以及 main() 方法的执行，通常将 Flink 的部署模式分为三种：Session Mode、Per-Job Mode 和 Application Mode。下面我们分别介绍这三种部署模式。</p><h4 id="Session-Mode"><a href="#Session-Mode" class="headerlink" title="Session Mode"></a>Session Mode</h4><p>Session Mode 下，所有的任务共享 JobManager 和 TaskManager，JobManager 的生命周期不受提交的 Job 影响，会长期运行。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1749406344/Blog/flink/0/SessionMode.png" alt="SessionMode"></p><h4 id="Per-Job-Mode"><a href="#Per-Job-Mode" class="headerlink" title="Per-Job Mode"></a>Per-Job Mode</h4><p>Per-Job Mode 下，每个任务独享 JobManager 和 TaskManager，资源充分隔离。JobManager 的生命周期和 Job 的生命周期绑定。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1749406344/Blog/flink/0/Per-job.png" alt="Per-JobMode"></p><h4 id="Application-Mode"><a href="#Application-Mode" class="headerlink" title="Application Mode"></a>Application Mode</h4><p>Application Mode 下，每个 Application 对应一个 JobManager，且可以运行多个作业。客户端无需将依赖包上传到 JobManager，只负责提交作业，减轻了客户端的压力。提交作业后，JobManager 主动从 HDFS 拉取依赖包。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1749406344/Blog/flink/0/Application.png" alt="ApplicationMode"></p><h4 id="三种模式的对比"><a href="#三种模式的对比" class="headerlink" title="三种模式的对比"></a>三种模式的对比</h4><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Session</th><th style="text-align:center">Per-Job</th><th style="text-align:center">Application</th></tr></thead><tbody><tr><td style="text-align:center">优点</td><td style="text-align:center">1、资源充分共享，提升资源利用率<br/>2、作业集中管理，运维简单</td><td style="text-align:center">1、资源充分隔离<br/>2、每个作业的 TM Slots 可以不同</td><td style="text-align:center">1、有效降低带宽和客户端负载<br/>2、Application 之间实现资源隔离，Application 中的资源共享</td></tr><tr><td style="text-align:center">缺点</td><td style="text-align:center">1、资源隔离差<br/>2、TM 不易扩展，伸缩性差</td><td style="text-align:center">1、资源浪费</td><td style="text-align:center">1、仅支持 Yarn 和 Kubunetes （个人感觉够用了）</td></tr></tbody></table><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后来总结一下，今天主要学习了 Flink 的整体架构和三种部署模式。</p><p>1、Flink 的集群架构上主要包含 JobManager 和 TaskManager，其中 JobManager 主要负责一些作业调度和资源协调的工作，TaskManager 则主要负责执行任务。</p><p>2、Flink 的部署模式分为 Session、Per-Job 和 Application 三种，Session 模式是所有 Job 共享 JobManager 和 TaskManager，Per-Job 则是作业独享的，而 Application 模式则是在 Application 中共享 JobManager。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;开一个新坑，系统性的学习下 Flink，计划从整体架构到核心概念再到调优方法，最后是相关源码的阅读。</summary>
    
    
    
    
    <category term="Flink" scheme="https://jackeyzhe.github.io/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>Rust入坑指南：最后一舞</title>
    <link href="https://jackeyzhe.github.io/2020/04/19/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E6%9C%80%E5%90%8E%E4%B8%80%E8%88%9E/"/>
    <id>https://jackeyzhe.github.io/2020/04/19/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E6%9C%80%E5%90%8E%E4%B8%80%E8%88%9E/</id>
    <published>2020-04-19T13:15:29.000Z</published>
    <updated>2024-12-06T17:02:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>Rust入坑指南系列我觉得应该告一段落了，最后来做一个总结吧。<span id="more"></span></p><p>在我看来，Rust语言本身设计得算是非常好了。Ownership和borrow帮助我们保证了程序了安全性。同时也提供了Unsafe，给开发者更多玩一些骚操作的空间。唯一的缺点就是入门比较困难了吧，我现在的水平感觉自己也就是刚刚入门。而《Rust入坑指南》也是希望帮助更多想要学习Rust的同学快速入门。</p><p>这里简单回顾一下学习过程吧。</p><p>最开始接触一门语言一定绕不开Hello，World</p><p>Rust也是一样，所以我们的第一篇文章就是关于Rust的安装、Hello，World程序的。</p><p><a href="https://jackeyzhe.github.io/2019/09/21/Rust入坑指南：坑主驾到/">Rust入坑指南：坑主驾到</a></p><p>接着就是介绍一些基础的语法、Rust的所有权、数据结构这些概念。关于这部分知识我用了四篇文章来做介绍。其中最重要的应该是Rust所有权了，这也是Rust语言的亮点之一。</p><p><a href="https://jackeyzhe.github.io/2019/10/08/Rust入坑指南：常规套路/">Rust入坑指南：常规套路</a></p><p><a href="https://jackeyzhe.github.io/2019/10/13/Rust入坑指南：核心概念/">Rust入坑指南：核心概念</a></p><p><a href="https://jackeyzhe.github.io/2019/10/27/Rust入坑指南：千人千构/">Rust入坑指南：千人千构</a></p><p><a href="https://jackeyzhe.github.io/2019/11/27/Rust入坑指南：鳞次栉比/">Rust入坑指南：鳞次栉比</a></p><p>接着呢，我们介绍了Package和Crate，用来帮助我们组织代码的。同时Crate也是为了让我们可以直接使用别人的代码，避免重复造轮子。</p><p><a href="https://jackeyzhe.github.io/2019/11/03/Rust入坑指南：有条不紊/">Rust入坑指南：有条不紊</a></p><p>之后又是两个比较通用的概念，大多数编程语言时都要涉及到的：异常处理和泛型</p><p><a href="https://jackeyzhe.github.io/2019/12/30/Rust入坑指南：亡羊补牢/">Rust入坑指南：亡羊补牢</a></p><p><a href="https://jackeyzhe.github.io/2020/01/14/Rust入坑指南：海纳百川/">Rust入坑指南：海纳百川</a></p><p>如果你对代码的正确性不放心，那么一定要写下完备的单元测试，这是对自己的代码负责。</p><p><a href="https://jackeyzhe.github.io/2020/02/21/Rust入坑指南：步步为营/">Rust入坑指南：步步为营</a></p><p>除了OwnerShip和borrow之外，Rust的另外两个比较核心的概念也需要了解，分别是生命周期和智能指针。这两篇文章可以帮你快速了解这两个概念。</p><p><a href="https://jackeyzhe.github.io/2020/03/02/Rust入坑指南：朝生暮死/">Rust入坑指南：朝生暮死</a></p><p><a href="https://jackeyzhe.github.io/2020/03/09/Rust入坑指南：智能指针/">Rust入坑指南：智能指针</a></p><p>接着是并发编程，Rust声称的安全并发，究竟是怎么保证的？</p><p><a href="https://jackeyzhe.github.io/2020/03/15/Rust入坑指南：齐头并进（上）/">Rust入坑指南：齐头并进（上）</a></p><p><a href="https://jackeyzhe.github.io/2020/03/23/Rust入坑指南：齐头并进（下）/">Rust入坑指南：齐头并进（下）</a></p><p>Safe Rust有这样那样的限制，有的开发者可能会觉得束手束脚，难以发挥实力。这时就可以考虑看看Unsafe Rust了。</p><p><a href="https://jackeyzhe.github.io/2020/03/31/Rust入坑指南：居安思危/">Rust入坑指南：居安思危</a></p><p>最后是Rust的元编程，我们从最开始就在使用的<code>println!</code>宏，它是如何定义的呢？我们又怎么定义自己的宏？希望这篇文章对你有帮助。</p><p><a href="https://jackeyzhe.github.io/2020/04/08/Rust入坑指南：万物初始/">Rust入坑指南：万物初始</a></p><p>经过这几个月的学习，我对Rust也有了一个初步的了解，在这里要感谢对我的分享提出意见的同学。也希望我的分享能对大家有所帮助。</p><p>虽然标题叫最后一舞，但是后面我还是会继续保持学习，也会不定期分享一些入门的代码案例给大家。</p><p>Rust编程，我们后会有期。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Rust入坑指南系列我觉得应该告一段落了，最后来做一个总结吧。</summary>
    
    
    
    
    <category term="Rust" scheme="https://jackeyzhe.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Rust入坑指南：万物初始</title>
    <link href="https://jackeyzhe.github.io/2020/04/08/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E4%B8%87%E7%89%A9%E5%88%9D%E5%A7%8B/"/>
    <id>https://jackeyzhe.github.io/2020/04/08/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E4%B8%87%E7%89%A9%E5%88%9D%E5%A7%8B/</id>
    <published>2020-04-08T15:02:34.000Z</published>
    <updated>2024-12-06T17:02:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>有没有同学记得我们一起挖了多少个坑？嗯…其实我自己也不记得了，今天我们再来挖一个特殊的坑，这个坑可以说是挖到根源了——<strong>元编程</strong>。<span id="more"></span></p><p>元编程是编程领域的一个重要概念，它允许程序将代码作为数据，在运行时对代码进行修改或替换。如果你熟悉Java，此时是不是想到了Java的反射机制？没错，它就是属于元编程的一种。</p><h3 id="反射"><a href="#反射" class="headerlink" title="反射"></a>反射</h3><p>Rust也同样支持反射，Rust的反射是由标准库中的<code>std::any::Any</code>包支持的。</p><p>这个包中提供了以下几个方法</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1586171714/Blog/rust/15/rust15-1.png" alt="Any包的方法"></p><p>TypeId是Rust中的一种类型，它被用来表示某个类型的唯一标识。<code>type_id(&amp;self)</code>这个方法返回变量的TypeId。</p><p><code>is()</code>方法则用来判断某个函数的类型。</p><p>可以看一下它的源码实现</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">is</span>&lt;T: Any&gt;(&amp;<span class="keyword">self</span>) <span class="punctuation">-&gt;</span> <span class="type">bool</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> <span class="variable">t</span> = TypeId::of::&lt;T&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> <span class="variable">concrete</span> = <span class="keyword">self</span>.<span class="title function_ invoke__">type_id</span>();</span><br><span class="line"></span><br><span class="line">  t == concrete</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到它的实现非常简单，就是对比TypeId。</p><p><code>downcast_ref()</code>和<code>downcast_mut()</code>是一对用于将泛型T转换为具体类型的方法。其返回的类型是<code>Option&lt;&amp;T&gt;</code>和<code>Option&lt;&amp;mut T&gt;</code>，也就是说<code>downcast_ref()</code>将类型T转换为不可变引用，而<code>downcast_mut()</code>将T转换为可变引用。</p><p>最后我们通过一个例子来看一下这几个函数的具体使用方法。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> std::any::&#123;Any, TypeId&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">v1</span> = <span class="string">&quot;Jackey&quot;</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">a</span>: &amp;Any;</span><br><span class="line">    a = &amp;v1;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;&#123;:?&#125;&quot;</span>, a.<span class="title function_ invoke__">type_id</span>());</span><br><span class="line">    <span class="built_in">assert!</span>(a.is::&lt;&amp;<span class="type">str</span>&gt;());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="title function_ invoke__">print_any</span>(&amp;v1);</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">v2</span>: <span class="type">u32</span> = <span class="number">33</span>;</span><br><span class="line">    <span class="title function_ invoke__">print_any</span>(&amp;v2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">print_any</span>(any: &amp;Any) &#123;</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(v) = any.downcast_ref::&lt;<span class="type">u32</span>&gt;() &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;u32 &#123;:x&#125;&quot;</span>, v);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> <span class="keyword">let</span> <span class="variable">Some</span>(v) = any.downcast_ref::&lt;&amp;<span class="type">str</span>&gt;() &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;str &#123;:?&#125;&quot;</span>, v);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;else&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="宏"><a href="#宏" class="headerlink" title="宏"></a>宏</h3><p>Rust的反射机制提供的功能比较有限，但是Rust还提供了宏来支持元编程。</p><p>到目前为止，宏对我们来说是一个既熟悉又陌生的概念，熟悉是因为我们一直在使用<code>println!</code>宏，陌生则是因为我们从没有详细介绍过它。</p><p>对于<code>println!</code>宏，我们直观上的使用感受是它和函数差不多。但两者之间还是有一定的区别的。</p><p>我们知道对于函数，它接收参数的个数是固定的，并且在函数定义时就已经固定了。而宏接收的参数个数则是不固定的。</p><p>这里我们说的宏都是类似函数的宏，此外，Rust还有一种宏是类似于属性的宏。它有点类似于Java中的注解，通常作为一种标记写在函数名上方。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[route(GET, <span class="string">&quot;/&quot;</span>)]</span></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">index</span>() &#123;</span><br></pre></td></tr></table></figure><p>route在这里是用来指定接口方法的，对于这个服务来讲，根路径的<code>GET</code>请求都被路由到这个index函数上。这样的宏是通过属于<strong>过程宏</strong>，它的定义使用了<code>#[proc_macro_attribute]</code>注解。而函数类似的过程宏在定义时使用的注解是<code>#[proc_macro]</code>。</p><p>除了过程宏以外，宏的另一大分类叫做<strong>声明宏</strong>。声明宏是通过<code>macro_rules!</code>来声明定义的宏，它比过程宏的应用要更加广泛。我们曾经接触过的<code>vec!</code>就是声明宏的一种。它的定义如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[macro_export]</span></span><br><span class="line"><span class="built_in">macro_rules!</span> vec &#123;</span><br><span class="line">    ( $( $x:expr ),* ) =&gt; &#123;</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">            $(</span><br><span class="line">                temp_vec.<span class="title function_ invoke__">push</span>($x);</span><br><span class="line">            )*</span><br><span class="line">            temp_vec</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>下面我们来定义一个属于自己的宏。</p><p>自定义宏需要使用<code>derive</code>注解。（例子来自the book）</p><p>我们先来创建一个叫做hello_macro的lib库，只定义一个trait。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">trait</span> <span class="title class_">HelloMacro</span> &#123;</span><br><span class="line">    <span class="keyword">fn</span> <span class="title function_">hello_macro</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着再创建一个子目录hello_macro_derive，在hello_macro_derive/Cargo.toml文件中添加依赖</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[lib]</span><br><span class="line">proc-<span class="keyword">macro</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[dependencies]</span><br><span class="line">syn = <span class="string">&quot;0.14.4&quot;</span></span><br><span class="line">quote = <span class="string">&quot;0.6.3&quot;</span></span><br></pre></td></tr></table></figure><p>然后就可以在hello_macro_derive/lib.rs文件中定义我们自定义宏的功能实现了。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">crate</span> proc_macro;</span><br><span class="line"></span><br><span class="line"><span class="keyword">use</span> crate::proc_macro::TokenStream;</span><br><span class="line"><span class="keyword">use</span> quote::quote;</span><br><span class="line"><span class="keyword">use</span> syn;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[proc_macro_derive(HelloMacro)]</span></span><br><span class="line"><span class="keyword">pub</span> <span class="keyword">fn</span> <span class="title function_">hello_macro_derive</span>(input: TokenStream) <span class="punctuation">-&gt;</span> TokenStream &#123;</span><br><span class="line">    <span class="comment">// Construct a representation of Rust code as a syntax tree</span></span><br><span class="line">    <span class="comment">// that we can manipulate</span></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">ast</span> = syn::<span class="title function_ invoke__">parse</span>(input).<span class="title function_ invoke__">unwrap</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Build the trait implementation</span></span><br><span class="line">    <span class="title function_ invoke__">impl_hello_macro</span>(&amp;ast)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">impl_hello_macro</span>(ast: &amp;syn::DeriveInput) <span class="punctuation">-&gt;</span> TokenStream &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">name</span> = &amp;ast.ident;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">gen</span> = quote! &#123;</span><br><span class="line">        <span class="keyword">impl</span> <span class="title class_">HelloMacro</span> <span class="keyword">for</span> #name &#123;</span><br><span class="line">            <span class="keyword">fn</span> <span class="title function_">hello_macro</span>() &#123;</span><br><span class="line">                <span class="built_in">println!</span>(<span class="string">&quot;Hello, Macro! My name is &#123;&#125;&quot;</span>, <span class="built_in">stringify!</span>(#name));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    gen.<span class="title function_ invoke__">into</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里使用了两个crate：syn和quote，其中syn是把Rust代码转换成一种特殊的可操作的数据结构，而quote的作用则与它刚好相反。</p><p>可以看到，我们自定义宏使用的注解是<code>#[proc_macro_derive(HelloMacro)]</code>，其中HelloMacro是宏的名称，在使用时，我们只需要使用注解<code>#[derive(HelloMacro)]</code>即可。</p><p>在使用时我们应该先引入这两个依赖</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hello_macro = &#123; path = <span class="string">&quot;../hello_macro&quot;</span> &#125;</span><br><span class="line">hello_macro_derive = &#123; path = <span class="string">&quot;../hello_macro/hello_macro_derive&quot;</span> &#125;</span><br></pre></td></tr></table></figure><p>然后再来使用</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">use</span> hello_macro::HelloMacro;</span><br><span class="line"><span class="keyword">use</span> hello_macro_derive::HelloMacro;</span><br><span class="line"></span><br><span class="line"><span class="meta">#[derive(HelloMacro)]</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Pancakes</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    Pancakes::<span class="title function_ invoke__">hello_macro</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行结果显示，我们能够成功在实现中捕获到结构体的名字。</p><p><img src="https://res.cloudinary.com/dxydgihag/image/upload/v1586190192/Blog/rust/15/rust15-2.png" alt="result"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们在本文中先后介绍了Rust的两种元编程：反射和宏。其中反射提供的功能能力较弱，但是宏提供的功能非常强大。我们所介绍的宏的相关知识其实只是皮毛，要想真正理解宏，还需要花更多的时间学习。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;有没有同学记得我们一起挖了多少个坑？嗯…其实我自己也不记得了，今天我们再来挖一个特殊的坑，这个坑可以说是挖到根源了——&lt;strong&gt;元编程&lt;/strong&gt;。</summary>
    
    
    
    
    <category term="Rust" scheme="https://jackeyzhe.github.io/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Rust入坑指南：居安思危</title>
    <link href="https://jackeyzhe.github.io/2020/03/31/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E5%B1%85%E5%AE%89%E6%80%9D%E5%8D%B1/"/>
    <id>https://jackeyzhe.github.io/2020/03/31/Rust%E5%85%A5%E5%9D%91%E6%8C%87%E5%8D%97%EF%BC%9A%E5%B1%85%E5%AE%89%E6%80%9D%E5%8D%B1/</id>
    <published>2020-03-31T10:17:48.000Z</published>
    <updated>2024-12-06T17:02:53.000Z</updated>
    
    <content type="html"><![CDATA[<p>任何事情都是相对的，就像Rust给我们的印象一直是安全、快速，但实际上，完全的安全是不可能实现的。因此，Rust中也是会有不安全的代码的。<span id="more"></span></p><p>严格来讲，Rust语言可以分为<strong>Safe Rust</strong>和<strong>Unsafe Rust</strong>。Unsafe Rust是Safe Rust的超集。在Unsafe Rust中并不会禁用任何的安全检查，Unsafe Rust出现的原因是为了让开发者可以做一些更加底层的操作。这些事情本身也是不安全的，如果仍然要进行Rust的安全检查，那么就无法进行这些操作。</p><p>在进行下面这5种操作时，Unsafe Rust不会进行安全检查。</p><ul><li>解引用原生指针</li><li>调用unsafe的函数或方法</li><li>访问或修改可变的静态变量</li><li>实现unsafe的trait</li><li>读写联合体中的字段</li></ul><h3 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h3><p>Unsafe Rust的关键字是unsafe，它可以用来修饰函数、方法和trait，也可以用来标记代码块。</p><p>标准库中也有不少函数是unsafe的。例如String中的<code>from_utf8_unchecked()</code>函数。它的定义如下：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pub</span> <span class="keyword">unsafe</span> <span class="keyword">fn</span> <span class="title function_">from_utf8_unchecked</span>(bytes: <span class="type">Vec</span>&lt;<span class="type">u8</span>&gt;) <span class="punctuation">-&gt;</span> <span class="type">String</span> &#123;</span><br><span class="line">  <span class="type">String</span> &#123; vec: bytes &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个函数被标记为unsafe的原因是函数并没有检查传入参数是否是合法的UTF-8序列。也就是提醒使用者注意，使用这个函数要自己保证参数的合法性。</p><p>用unsafe标记的trait也比较常见，在前面我们见过的Send和Sync都是unsafe的trait。它们被用来保证线程安全， 将其标记为unsafe是告诉开发者，如果自己实现这两个trait，那么代码就会有安全风险。</p><p>我们在调用unsafe函数或方法时，需要使用unsafe代码块。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">sparkle_heart</span> = <span class="built_in">vec!</span>[<span class="number">240</span>, <span class="number">159</span>, <span class="number">146</span>, <span class="number">150</span>];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">let</span> <span class="variable">sparkle_heart</span> = <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="type">String</span>::<span class="title function_ invoke__">from_utf8_unchecked</span>(sparkle_heart)</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">assert_eq!</span>(<span class="string">&quot;💖&quot;</span>, sparkle_heart);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在了解了unsafe的基础语法之后，我们再来具体看看前面提到的5种操作。</p><h3 id="解引用原生指针"><a href="#解引用原生指针" class="headerlink" title="解引用原生指针"></a>解引用原生指针</h3><p>Rust的原生指针分为两种：可变类型<code>*mut T</code>和不可变类型<code>*const T</code>。</p><p>与引用和智能指针不同，原生指针具有以下特性：</p><ul><li>可以不遵循借用规则，在同一代码块中可以同时出现可变和不可变指针，也可以同时有多个可变指针</li><li>不保证指向有效内存</li><li>允许是null</li><li>不会自动清理内存</li></ul><p>由这些特性可以看出，原生指针并不受Rust那一套安全规则的限制，因此，解引用原生指针是一种不安全的操作。换句话说，我们应该把这种操作放在unsafe代码块中。下面这段代码就展示了原生指针的第一条特性，以及如何解引用原生指针。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">num</span> = <span class="number">5</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="variable">r1</span> = &amp;num <span class="keyword">as</span> *<span class="keyword">const</span> <span class="type">i32</span>;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">r2</span> = &amp;<span class="keyword">mut</span> num <span class="keyword">as</span> *<span class="keyword">mut</span> <span class="type">i32</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;r1 is: &#123;&#125;&quot;</span>, *r1);</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;r2 is: &#123;&#125;&quot;</span>, *r2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Rust编程中，原生指针常被用作和C语言打交道，原生指针有一些特有的方法，例如可以用<code>is_null()</code>来判断原生指针是否是空指针，用<code>offset()</code>来获取指定偏移量的内存地址的内容，使用<code>read()/write()</code>方法来读写内存等。</p><h3 id="调用unsafe的函数或方法"><a href="#调用unsafe的函数或方法" class="headerlink" title="调用unsafe的函数或方法"></a>调用unsafe的函数或方法</h3><p>调用unsafe的函数或方法必须放到unsafe代码块中，这点我们在基础知识中已经介绍过。因为函数本身被标记为unsafe，也就意味着调用它可能存在风险。这点无需赘述。</p><h3 id="访问或修改可变的静态变量"><a href="#访问或修改可变的静态变量" class="headerlink" title="访问或修改可变的静态变量"></a>访问或修改可变的静态变量</h3><p>对于不可变的静态变量，我们访问它不会存在任何安全问题，但是对于可变的静态变量而言，如果我们在多线程中都访问同一个变量，那么就会造成数据竞争。这当然也是一种不安全的操作。所以要放到unsafe代码块中，此时线程安全应由开发者自己来保证。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">mut</span> COUNTER: <span class="type">u32</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">add_to_count</span>(inc: <span class="type">u32</span>) &#123;</span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        COUNTER += inc;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="title function_ invoke__">add_to_count</span>(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;COUNTER: &#123;&#125;&quot;</span>, COUNTER);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子中我们没有使用多线程，这里只是想展示一下如何访问和修改可变静态变量。</p><h3 id="实现unsafe的trait"><a href="#实现unsafe的trait" class="headerlink" title="实现unsafe的trait"></a>实现unsafe的trait</h3><p>当trait中包含一个或多个编译器无法验证其安全性的方法时，这个trait就必须被标记为unsafe。而想要实现unsafe的trait，首先在实现代码块的关键字<code>impl</code>前也要加上unsafe标记。其次，无法被编译器验证安全性的方法，其安全性必须由开发者自己来保证。</p><p>前面我们也提到了，常见的unsafe的trait有Send和Sync这两个。</p><h3 id="读写联合体中的字段"><a href="#读写联合体中的字段" class="headerlink" title="读写联合体中的字段"></a>读写联合体中的字段</h3><p>Rust中的Union联合体和Enum相似。我们可以使用union关键字来定义一个联合体。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">union</span> <span class="title class_">MyUnion</span> &#123;</span><br><span class="line">    i: <span class="type">i32</span>,</span><br><span class="line">    f: <span class="type">f32</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="keyword">let</span> <span class="variable">my_union</span> = MyUnion&#123;i: <span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">unsafe</span> &#123;</span><br><span class="line">        <span class="built_in">println!</span>(<span class="string">&quot;&#123;&#125;&quot;</span>, my_union.i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在初始化时，我们每次只能指定一个字段的值。这就造成我们在访问联合体中的字段时，有可能会访问到未定义的字段。因此，Rust让我们把访问操作放到unsafe代码块中，以此来警示我们必须自己保证程序的安全性。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本文我们聊了Unsafe Rust的一些使用场景和使用方法。你只需要记住Unsafe的5种操作就好，在遇到这些操作时，一定要使用unsafe代码块。unsafe代码块不光是为了“骗”过编译器，要时刻提醒自己，<strong>unsafe代码块中的程序要由开发者自己保证其正确性</strong>。</p><ul><li>解引用原生指针</li><li>调用unsafe的函数或方法</li><li>访问或修改可变的静态变量</li><li>实现unsafe的trait</li><li>读写联合体中的字段</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;任何事情都是相对的，就像Rust给我们的印象一直是安全、快速，但实际上，完全的安全是不可能实现的。因此，Rust中也是会有不安全的代码的。</summary>
    
    
    
    
    <category term="Rust" scheme="https://jackeyzhe.github.io/tags/Rust/"/>
    
  </entry>
  
</feed>
